{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"HW1.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b5b35a96a71be61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "The final score that you will receive for your programming assignment is generated in relation to the total points set in your programming assignment item—not the total point value in the autograder output.     \n",
    "Autograded quesions may have hidden tests and/or public tests. You can see the public test results when you run the notebook with otter grader. Usually public tests are for simple checks (such as variable types) and may not indicate that the answer is correct.     \n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** The autograder will not work properly if your change the variable or method signatures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3a0e60201d41e0cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#  I. EDA, Simple Linear Regression\n",
    "\n",
    "In this part, we will use a simplified data and create a simple linear regression model. The dataset can be downloaded from https://www.kaggle.com/harlfoxem/housesalesprediction/download.    \n",
    "This dataset contains house sale prices for Kings County, which includes Seattle. It includes homes sold between May 2014 and May 2015. There are several versions of the data. Some additional information about the columns is available here: https://geodacenter.github.io/data-and-lab/KingCounty-HouseSales2015/, some of which are copied below.\n",
    "\n",
    "|Variable |\tDescription|\n",
    "|:---------|:-------------|\n",
    "|id \t|Identification|\n",
    "|date |\tDate sold|\n",
    "|price |\tSale price|\n",
    "|bedrooms |\tNumber of bedrooms|\n",
    "|bathrooms |\tNumber of bathrooms|\n",
    "|sqft_liv |\tSize of living area in square feet|\n",
    "|sqft_lot| \tSize of the lot in square feet|\n",
    "|floors |\tNumber of floors|\n",
    "|waterfront |\t‘1’ if the property has a waterfront, ‘0’ if not.|\n",
    "|view |\tAn index from 0 to 4 of how good the view of the property was|\n",
    "|condition |\tCondition of the house, ranked from 1 to 5|\n",
    "|grade |\tClassification by construction quality which refers to the types of materials used and the quality of workmanship. Buildings of better quality (higher grade) cost more to build per unit of measure and command higher value.|\n",
    "|sqft_above |\tSquare feet above ground|\n",
    "|sqft_basmt |\tSquare feet below ground|\n",
    "|yr_built \t|Year built|\n",
    "|yr_renov |\tYear renovated. ‘0’ if never renovated|\n",
    "|zipcode |\t5 digit zip code|\n",
    "|lat \t|Latitude|\n",
    "|long \t|Longitude|\n",
    "|squft_liv15 |\tAverage size of interior housing living space for the closest 15 houses, in square feet|\n",
    "|squft_lot15 |\tAverage size of land lost for the closest 15 houses, in square feet|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4164737ecf84807d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "# Set color map to have light blue background\n",
    "sns.set()\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab53fad4700fc069",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/house_data_washington.csv.gz', compression = 'gzip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec3f216a5e3d4612",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b9c982194d2d0f40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Munging data [20 pts]\n",
    "### 1a) Date string to numbers [5 pts]\n",
    "Inspect the data frame and data type of each column. The column 'date' is the date sold, and has string value. We will extract year and month information from the string. \n",
    "In the data frame df, create new features 'sales_year' and 'sales_month', which values are integer.\n",
    "\n",
    "Hint: Consider using .apply(lambda ...) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-def60c6a987f3af9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract year and month info from the string\n",
    "# create new features 'sales_year' and 'sales_month' in df\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['sales_year'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-83ea2e38626f7298",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1b) Now, let's count how many sales happened each year and each month.\n",
    "#### 1b-i) Use .groupby and .count methods to calculate how many sales per year, and how many sales per month. \n",
    "Display the results by printing the groupby object with one relevant column. \n",
    "For example, a result for sales_month may look like    \n",
    "\n",
    "|     |sales_month|\n",
    "|:---|:----------|\n",
    "|1 |     978|     \n",
    "|2 |    1250  |  \n",
    "|3 |    1875   |  \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5baff6c853351efb",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-270ddcab2bd221ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1b-ii) Which month has the most number of sales? Answer the month as an integer number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-447e548e063eb680",
     "locked": false,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "# uncomment and update the value.\n",
    "# most_sales = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab45a9249c1c8285",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1b-iii) Which months has the least number of sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05ff2ec904565f4c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "# uncomment and update the value.\n",
    "# least_sales = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6107c495a67fc96b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1c) Variable types [5 pts]\n",
    "Inspect each feature's data type and variable type. What is the best description for the variable type of following features? Update the string to 'numeric' or 'categorical'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d1457a08b8feb7e4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# uncomment the feaures below and update the strings with 'numeric' or 'categorical'\n",
    "# price = ''\n",
    "# bathrooms = ''\n",
    "# waterfront = ''\n",
    "# grade = ''\n",
    "# zipcode = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee0110eb32b0b7ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1d) Drop features [5 pts]\n",
    "Let's drop features that are unnecessary. `id` is not a meaningful feature. `date` string has been coded to `sales_month` and `sales_year`, so we can remove `date`. `zipcode` can be also removed as it's hard to include in a linear regressio model and the location info is included in the `lat` and `long`.\n",
    "Drop the features `id`, `date`, and `zipcode` and replace the df.\n",
    "\n",
    "Hint: Use .drop() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fba7fcd19732194e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop unnecessary features, replace df\n",
    "...\n",
    "\n",
    "df.info() #a quick check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c28ed0de4ca75d60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. More EDA; Correlation and pair plot [15 pts]\n",
    "### 2a) Get correlation matrix on the data frame. [5 pts]\n",
    "Which feature may be the best predictor of price based on the correlation? Answer as a string value (e.g. best_guess_predictor = 'yr_built')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0e9bdc9ee6161b7e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "# uncomment and update best_guess_predictor with a string value\n",
    "# best_guess_predictor = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7120f691348f8907",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2b) Display the correlation matrix as heat map [5 pts]\n",
    "[`seaborn.heatmap()`](https://seaborn.pydata.org/generated/seaborn.heatmap.html) can visualize a matrix as a heatmap. Visualize the correlation matrix using seaborn.heatmap(). Play with color map, text font size, decimals, text orientation etc. If you find how to make a pretty visualization, please share in the discussion board. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2e19c30b0454fabd",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b376b65ab6badfa0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2c) Pair plot [5 pts]\n",
    "Pair plot is a fast way to inspect relationships between features. Use seaborn's .pairplot() function to draw a pairplot if the first 10 columns (including price) and inspect their relationships. Set the diagonal elements to be KDE plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-630895ed926e33b7",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# practice inspecting relationships between features using a pair plot. \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a472da53d90eea44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 3. Simple linear regression [15 pts]\n",
    "\n",
    "### 3a) Data preparation [5 pts]\n",
    "We will split the data to train and test datasets such that the test dataset is 20% of original data.\n",
    "Use `sklearn.model_selection.train_test_split` function to split the data frame to X_train and X_test. X_train is 80% of observation randomly chosen. X_test is the rest 20%. Both X_train and X_test are `pd.DataFrame` object and include 'price' in the table. Note that the train_test_split can handle data frame as well as array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-039f3a4314195737",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "# use sklearn.model_selecttion.train_test_split to split the data frame \n",
    "# X_train is 80% of the observations; X_test is 20% of the observations\n",
    "# print length of X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4c22fe96e318333",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3b) Train a simple linear regression model [5pts]\n",
    "Use the best_guess_predictor as a single predictor and build a simple linear regression model using `statsmodels.formula.api.ols` function (https://www.statsmodels.org/dev/example_formulas.html)\n",
    "Print out the result summary. Train on the X_train portion. What is the adjusted R-squared value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f5291d1c1d6ebee5",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use best_guess_predictor as a single predictor\n",
    "# build a simple linear regression model, train on the X_train portion\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a69012fe381b2827",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3c) Best predictor [5 pts]\n",
    "In question 2a, we picked a best guess predictor for price based on the correlation matrix. Now we will consider whether the best_guess_predictor that we used is still the best.<br>\n",
    "Print out a list ranking all of the predictors. Then print out a list of the top three predictors in order.<br>      \n",
    "Hint: Linear regression uses adjusted R squared as fit performance. <br>\n",
    "\n",
    "**Answer the following questions**: \n",
    "1. What were your top three predictors? \n",
    "2. How did you order your list of predictors to select those as the top ones? \n",
    "3. Is your top predictor for this section the same as the best guess predictor you selected in question 2a? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9ca80c1b78b9ccd7",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "# uncomment and update top_three\n",
    "# top_three = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-882bf4885b57172b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# II. Polynomial and Multilinear Regression\n",
    "In this part, we will improve our model using multiple features and higher powers of features.\n",
    "\n",
    "## 4. Polynomial Regression [20 pts]\n",
    "Using the best predictor found from 3c, let's add higher orders of the feature.    \n",
    "We will iteratively add higher order terms and plot train and test errors (MSE).    \n",
    "### 4a) Iteratively add higher order terms up to 5th power of the best predictor [5 pts]\n",
    "For example, compare models\n",
    "- $model1 = a_0 + a_1 X$\n",
    "- $model2 = a_0 + a_1 X + a_2 X^2$\n",
    "- $model3 = a_0 + a_1 X + a_2 X^2 + a_3 X^3$   \n",
    "...    \n",
    "Hint: Use for loop and use 'np.power()' in the formula of smf.ols method. e.g. formula = 'y~X+np.power(X,2)'.     \n",
    "Hint: Before you build models, should we rescale the X first? Why or why not? How would you rescale? How about rescaling y? Choose rescaling method that's more interpretable. For example, you can think about changing the unit of $X$ to sqft to 1000 sqft.\n",
    "\n",
    "### 4b) Visualize the model fit results [5 pts]\n",
    "Now we will add tools helpful for judging whether each model looks good.    \n",
    "Modify your for loop code from above and display a graph that shows train data ($X_\\textrm{tr}$, $y_\\textrm{tr}$) and train prediction result ($X_\\textrm{tr}$, model($X_\\textrm{tr}$)), and the model summary.\n",
    "As an example, the univariate linear model's train result looks like below (blue dots are the train data, and red dotted line is the prediction from the train data, the complexity $k=1$ is the heighest power of $X$ in the model).  \n",
    "![An examlpe plot for univariate linear model](linreg_result.png)\n",
    "\n",
    "### 4c) Compare train error and test error [5 pts]\n",
    "We will inspect train error and test error for each model complexity. To do that, let's save the train and test errors after we build each model. Modify your for loop above to save train error and test error from each model. Plot the final result showing train and test errors. You graph will have the complexity $k$ as x-axis and the train and test errors on the y-axis. Also, make legends for train and test errors.  \n",
    "\n",
    "Hint: You may use functions in sklearn.metrics to calculate errors.     \n",
    "Hint: train error refers the error between y_train and model prediction from X_train whereas test error refers the error between y_test and model prediction from X_test.    \n",
    "Hint: RMSE can be useful to inerpret the error of y than MSE. Or mean absolute percentage error can be useful metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fc7acd3e3b1a45ff",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9bcb19d0bec45ee8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 4d) Inspect the results from 4b) and 4c), describe your observation. Based on the observation, pick a final model. Justify your decision. [5 pts]\n",
    "Hint: Refer to Elobow plot and Occam's razor principle.    \n",
    "Hint: If the trent at k=10 is not enough, try changing the power limit (previously set to $k_\\textrm{max}=10$) to smaller and bigger numbers and see the general trend.    \n",
    "Hint: You can also consider AIC and BIC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 5. Multilinear Regression [20 pts]\n",
    "Let's include more features (linear) to our model instead of having single factor and its higher order terms. For the complexity sake, we will not consider higher orders of features.\n",
    "\n",
    "### 5a) Implement hybrid approach of forward and backward selection methods. [15 pts]\n",
    "Without using rescaling for y (price) and all features, implement the hybrid approach.\n",
    "What is the number of features in the final model (not inclusing intercept as feature)?\n",
    "\n",
    "Hint: Following logic might help.\n",
    "```\n",
    "while\n",
    "    for feature in [features that are not in the model already]\n",
    "        best_feature <- select a feature that gives the heighest adjusted R2\n",
    "        best_model <- add the best_feature in the model\n",
    "\n",
    "       for attribute in the all attributes of the best_model\n",
    "           inspect p-value of each attribute\n",
    "           remove any attribute(s) with high p-values from the best_model\n",
    "    break and return the best_model if the best_model (the set of its attributes) no longer changes.  \n",
    "```      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-63675899f5eb95fc",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7320f43af4c37793",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 5b) Record train and test error for each model complexity [5 pts]\n",
    "Modify codes in 5a) to record mean squared errors for train and test date.    \n",
    "Plot the elbow plot and determine the best model comlexity based on mean squared errors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6dc8484bbe16ffa0",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f533173d423c9864",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 6. Variance Inflation Factor [10 pts]\n",
    "VIF is a good tool to monitor if there is a multicollinearity among multiple features while correlation matrix only shows two-feature correlations. \n",
    "$$\\textrm{VIF}(\\hat{\\beta}_i) = \\frac{1}{1-R^2_{X_i|X_{-i}}}$$, where $R^2_{X_i|X_{-i}}$ is $R^2$ when $X_i$ is fitted using the rest of features.\n",
    "`statsmodels` library has a module `variance_inflation_factor` that can calculate VIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-17f49dc6e7d16d5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from patsy import dmatrices\n",
    "\n",
    "# VIF with all features\n",
    "features = list(df.drop(['price'],axis=1).columns)\n",
    "y, X = dmatrices('price ~' + '+'.join(features), df, return_type='dataframe')\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])] #note that the variance_inflation_factor uses sm.OLS which requires design matrix unlike smf\n",
    "vif[\"feature\"] = X.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6eaa856131768f52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 6a) Interpret the above result. [3 pts]\n",
    "Discuss your observation and how to interpret this result. Can you remove features with abnormal values of VIF? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2639f187951a5a8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 6b) Calculate VIF values of features that were selected from the hybrid approach in 5a). [3 pts]\n",
    "How do VIF values change? Are all highly correlted features gone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-060c08c78e0479ad",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ffb9a3887dfbe8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 6c) Eliminate features in order of feaure importance found in the hybrid approach and calculate VIFs. [4 pts]\n",
    "Discuss general observation in relation with model complexity.     \n",
    "Find the maximum number of features (excluding intercept) that gives all VIF values (except for intercept) smaller than 5.\n",
    "VIF = 5 is a rule of thumb threshold often used in practice. If VIF is smaller than 5, we can consider the model doesn't have features that are very highly correlated.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1c830c1927f7f1f4",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "These are some submission instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venvCSPB4622': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1bii": {
     "name": "q1bii",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1biii": {
     "name": "q1biii",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1d": {
     "name": "q1d",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert('id' not in df.columns), \"Check 1d. Did you drop 'id' from df?\"\n>>> assert('date' not in df.columns), \"Check 1d. Did you drop 'date' from df?\"\n>>> assert('zipcode' not in df.columns), \"Check 1d. Did you drop 'zipcode' from df?\"\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(len(X_train) == 17290), \"Check 3a, did you split properly so X_Train is 80% of the observations?\"\n>>> assert(len(X_test) == 4323), \"Check 3a, did you split properly so X_test is 20% of the observations?\"\n>>> assert(type(X_train)==type(pd.DataFrame())), \"Check 3a, what type of object should X_train be?\"\n>>> assert(type(X_test)==type(pd.DataFrame())), \"Check 3a, what type of object should X_test be?\"\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "c3b1026e9d60130376c75b3e7546e35506f1b211904f616c734890e40bc0500c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
