{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"HW2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QI5w3mueh_fC",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ed2d3c3c54ab0e5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "The final score that you will receive for your programming assignment is generated in relation to the total points set in your programming assignment itemâ€”not the total point value in the autograder output.     \n",
    "Autograded quesions may have hidden tests and/or public tests. You can see the public test results when you run the notebook with otter grader. Usually public tests are for simple checks (such as variable types) and may not indicate that the answer is correct.     \n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** The autograder will not work properly if your change the variable or method signatures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzpgW7rVh_fH",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-838202c6a7fa608e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ine1vfOvh_fI",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cfff5f5c602da934",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# importing all the required libraries\n",
    "\n",
    "from math import exp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-pGpglsh_fK",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fdc05c3ea8feddd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part A. Understanding Logistic Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCknKqwyh_fM",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-46b248cc48bd7a15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1. [5 points] \n",
    "Your first task is to complete the function `gen_logistic` in the following cell so as to be able to generate the logistic function for a given input. The logistic function is a type of <em>sigmoid</em> function which has an 'S'-shape and 'squashes' its inputs to a value lying in the range [0,1]. Other sigmoid functions include the hyperbolic-tangent funcition (`tanh(x)`) and the error function (`erf(x)`).[https://en.wikipedia.org/wiki/Sigmoid_function].     \n",
    "Hint: In the logistic function, the variable of the logistic function is the logit $z = w \\cdot x +b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMCuZlq6h_fO",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-29a60883217c420b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_logistic(x, w=1, b=0):\n",
    "    \"\"\"\n",
    "    outputing the logistic output for an input x\n",
    "    :param x: scalar or numpy array of shape (n_samples, n_features). If only one feature, it must have the shape of (n_samples,1).\n",
    "    :param w: weight(s); either scalar or numpy array of shape (1, n_features)\n",
    "    :param b: bias; either scalar or numpy array of shape (1,)\n",
    "    returns y of shape (n_samples,)\n",
    "    \"\"\"    \n",
    "    # TODO: Finish this function to return the output of applying the sigmoid\n",
    "    # function to the input x (Please do not use external libraries) store \n",
    "    # the output in y and return y. Do not change the default parameter values.\n",
    "    # Hint: This function will be used in any input shape scalar (0d), 1d vector, and 2d arrays. Please make sure it can handle all those. Following reshaping codes might help.\n",
    "    # Hint2: You may use design matrix using concatenation (e.g. np.concat), but it is not necesary.\n",
    "    \n",
    "    y =0 \n",
    "    if np.isscalar(x):\n",
    "        x = np.array(x).reshape((1,1))\n",
    "    if np.isscalar(w):\n",
    "        w = np.array(w).reshape((1,1))\n",
    "    if np.isscalar(b):\n",
    "        b = np.array(b).reshape((1,1))  \n",
    "    if b.shape==(1,):\n",
    "        b= b.reshape((1,1))  \n",
    "\n",
    "    ...\n",
    "    \n",
    "    return y.reshape(y.shape[0],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AZTczpbh_fR",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e6ae2128caebffea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Q2. Role of parameters in a logistic function [10 pts] \n",
    "**2-a) [5 points]:** Generate a vector x of length N with values lying between limits Xa and Xb (for this you will have to choose your own limits; play around with different values) and apply the `gen_logistic` function to this vector.  Proceed to plot the output and verify the shape of the output. If your decision boundary value is about the center of your x range, you will see an S-shape. Your final plot should show the S-curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "fLefLUBCh_fT",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6eb2c8a94fdaff49",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "b290dd20-c9e4-4287-c3ca-f9151a730317",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: change the values of N, a and b below to check how the output of your function works\n",
    "# Use a value for N greater than 1 and any limits a and b so that an S-shape graph is generated\n",
    "\n",
    "N = 1\n",
    "Xa = 0\n",
    "Xb = 1\n",
    "w = 1\n",
    "b = 0\n",
    "\n",
    "\n",
    "\n",
    "x = np.expand_dims(np.linspace(Xa,Xb,N), axis=1)\n",
    "y = gen_logistic(x, w, b)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1,ncols=1,figsize=(12,7))\n",
    "ax.plot(x,y, lw=2)\n",
    "ax.set_xlabel(\"x\", fontsize=16)\n",
    "ax.set_ylabel(\"y\", fontsize=16)\n",
    "ax.set_title(\"Logistic/Sigmoid Function\", fontsize=16)\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xa68isiUh_fU",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1851e5f2ab22640f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "###  Answer following questions\n",
    "#### 2-b) Increasing w will make the curve transition sharply: [2 pts, True/False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnimQBqJh_fV",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cba612162fd69391",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uncomment sharp_transition and answer qustion 1. above \n",
    "# replace string with 'True' or 'False' \n",
    "# sharp_transition = ''\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocQ0Bqe9h_fY",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-453dfedf075259ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2-c) If b increases by 1, then the decision boundary x decreases by 1: [1 pts, True/False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0OxXrIzh_fZ",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b6f28ec800691431",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uncomment x_decreases_by_1 and answer question 2. above\n",
    "# replace string with 'True' or 'False' \n",
    "# x_decreases_by_1 = ''\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-d) If $w$'s sign flips (and no change in the non-zero-valued $b$), the logistic curve flips vertically without changing the boundary threshold's position. [2 pts, True/False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uncomment vertical_flip and answer question 3. above\n",
    "# replace string with 'True' or 'False' \n",
    "# vertical_flip = ''\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvMUPENoh_fb",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-122d827f00590fd2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part B. Logistic regression using Scikit-learn\n",
    "\n",
    "### Q3.  [10 pts]\n",
    "Performing binary classification using logistic regression on the breast-cancer dataset. In this part you will be exposed to different methods within the scikit-learn LogisticRegression class so you can build a classifier. In this part, we will use breast cancer data from sklean dataset library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-D3FCQkzh_fc",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c47b2d74c67faa6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 3-a)  Complete below codes to split train and test data  [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5rA60GFh_fe",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-10976d76d3a81f36",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the breast-cancer dataset from sklearn datasets\n",
    "\n",
    "class BC_data:\n",
    "    \"\"\"\n",
    "    class to import the breast cancer dataset from sklearn\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        x, y = load_breast_cancer(return_X_y= True)\n",
    "        self.x_train = None \n",
    "        self.x_test = None \n",
    "        self.y_train = None \n",
    "        self.y_test = None\n",
    "        \n",
    "        #TODO: Split the data into training and test data (use train_test_split sklearn) \n",
    "        # such that the test data size is 25% of total number of observations\n",
    "        # No need to rescale the data. Use the data as is.\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        \n",
    "data = BC_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9KZBu4lh_fg",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-391383e2ba5d5778",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 3-b) Build and Fit Logistic Regression Model [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0Svx1tBh_fg",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7c7287ce51bbec9b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "c65a2592-4cac-4f7e-b32e-5aadb541e52b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Use the data object and then train the logistic regression model. \n",
    "# 1. Change the code below to build your model called LogReg\n",
    "# 2. Fit the model to the train data\n",
    "\n",
    "#LogReg = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### 3-c. Print out prediction probability and prediction labels from the above model (from the sklearn library) using test data. [5 pts]\n",
    "Explain 1) why there are two columns in the prediction probability output, and 2) how you can manually optain prediction label from the predictio probability output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGsaK5Ish_fi",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2b87faad9230049f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# Part C. Understanding classification performance metrics\n",
    "\n",
    "### Q4. ROC curve  [10 pts] \n",
    "In the next cell, compute the ROC curve and the area under the curve and plot the ROC curve. Your ROC curve plot also should display area under the curve.       \n",
    "Hint: Use relevant functions in sklearn.metrics. Feel free to refer to the sklearn documentation's examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "XnjZY4f_h_fj",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5002bb7d0edf9fc7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "319a0a6d-c0c1-4bdc-fc73-380241946896",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: compute the area under the curve and plot ROC curve\n",
    "# Plot the ROC curve ( True positive rate v/s False positive rate) and indicate the AUC on the plot\n",
    "\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMkUU_-wh_fj",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af3b032af728ef45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Q5. Precision and Recall [10 pts]\n",
    "Here we will use the trained model coefficients and generate the `classification probabilities` using the `gen_logistic` function we built. The goal of this section is to make you understand how logistic regression classifies data points during and after training. Using the predictions from the generated probabilities, you will compute the precision and recall metrics (defined below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5a. Complete the code below to implement precision function. [5 pts]\n",
    "Assume positive label is 1 and negative label is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zwhGiksfh_fj",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2332ba460f281cde",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_precision(y_true, y_pred):\n",
    "    '''\n",
    "    This function accepts the labels and the predictions, then\n",
    "    calculates precision for a binary classifier.\n",
    "    \n",
    "    Args\n",
    "        y_true: np.ndarray\n",
    "        y_pred: np.ndarray\n",
    "    \n",
    "    Returns precision as a floating point number between 0.0 and 1.0\n",
    "    '''\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5b. Complete the code below to implement recall function. [5 pts]\n",
    " Assume positive label is 1 and negative label is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_recall(y_true, y_pred):\n",
    "    '''\n",
    "    This function accepts the labels and the predictions, then\n",
    "    calculates recall for a binary classifier.\n",
    "    \n",
    "    Args\n",
    "        y_true: np.ndarray\n",
    "        y_pred: np.ndarray\n",
    "        \n",
    "    \n",
    "    Returns precision as a floating point number between 0.0 and 1.0\n",
    "    '''\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEhFEFA4h_fl",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-118ff7dea1e21636",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Q6. Putting things together [10 pts]\n",
    "\n",
    "In the next cell you will generate the predictions for the test data `data.x_test` and compute prediction and recall metrics by calling the functions you built above. \n",
    "STEP1. Get weight and bias from your fitted model (sklearn model)     \n",
    "STEP2. Plug weight and bias and test data into your `gen_logistic` function to get prediction probability.    \n",
    "STEP3. From the predicion probability output from STEP2, calculate prediction label (y_pred).    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9t7z2Byh_fm",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-176f3759a371e25b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "b4b9fa82-3388-4eb7-cb57-edd6c3bc04ed",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TO-DO : Generate predicted y values using coefficients of the fit logistic regression model for data.x_test\n",
    "# Then compute and print the precision and recall metrics \n",
    "\n",
    "...\n",
    "\n",
    "# Checking your results. Do not modify codes below.\n",
    "print(y_pred.shape)\n",
    "precision = calculate_precision(data.y_test, y_pred)\n",
    "recall = calculate_recall(data.y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "print('Model Precision : %0.2f' % precision)\n",
    "print('Model Recall : %0.2f' % recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "These are some submission instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "name": "Module3_update.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "otter": {
   "tests": {
    "q2b": {
     "name": "q2b",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2c": {
     "name": "q2c",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2d": {
     "name": "q2d",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5a": {
     "name": "q5a",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ut_true = np.array([1.0, 1.0, 0.0, 0.0])\n>>> ut_pred = np.array([1.0, 1.0, 1.0, 1.0])\n>>> prec = calculate_precision(ut_true, ut_pred)\n>>> \n>>> assert prec == 0.5, \"Checks the prec value returned from your calculate_precision function.\"\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5b": {
     "name": "q5b",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ut_true = np.array([1.0, 1.0, 0.0, 0.0])\n>>> ut_pred = np.array([1.0, 1.0, 1.0, 1.0])\n>>> recall = calculate_recall(ut_true, ut_pred)\n>>> \n>>> assert recall == 1.0, \"Checks the recall value returned from your calculate_recall function.\"\n",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "qA": {
     "name": "qA",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
