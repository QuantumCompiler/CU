{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8dc5666374ee06578ae8c0132b757feb",
     "grade": false,
     "grade_id": "cell-05b7e07a206343a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "The final score that you will receive for your programming assignment is generated in relation to the total points set in your programming assignment itemâ€”not the total point value in the nbgrader notebook.<br>\n",
    "When calculating the final score shown to learners, the programming assignment takes the percentage of earned points vs. the total points provided by nbgrader and returns a score matching the equivalent percentage of the point value for the programming assignment.<br>\n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** The autograder will not work properly if your change the variable or method signatures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d718a0fff3c2225b67c106cc232eaa15",
     "grade": false,
     "grade_id": "cell-0a9bd55375e1d2fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Support Vector Machines \n",
    "***\n",
    "\n",
    "In this assignment we'll explore the details of the Soft-Margin SVM and look at how the choice of tuning parameters  affects the learned models.  We'll also look at kernel SVMs for non-linearly separable and methods for choosing and visualizing good hyperparameters.   \n",
    "\n",
    "**Note**: Below are some helper functions which are used throughout this notebook.  Execute these before continuing. Do not modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea89d2e91f48c5e32ccd30129f84ad34",
     "grade": false,
     "grade_id": "cell-7ca30e1703520b3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def linear_plot(X, y, w=None, b=None):\n",
    "    \n",
    "    mycolors = {\"blue\": \"steelblue\", \"red\": \"#a76c6e\", \"green\": \"#6a9373\"}\n",
    "    colors = [mycolors[\"red\"] if yi==1 else mycolors[\"blue\"] for yi in y]\n",
    "    \n",
    "    # Plot data \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,8))\n",
    "    ax.scatter(X[:,0], X[:,1], color=colors, s=150, alpha=0.95, zorder=2)\n",
    "    \n",
    "    # Plot boundaries \n",
    "    lower_left = np.min([np.min(X[:,0]), np.min(X[:,1])])\n",
    "    upper_right = np.max([np.max(X[:,0]), np.max(X[:,1])])\n",
    "    gap = .1*(upper_right-lower_left)\n",
    "    xplot = np.linspace(lower_left-gap, upper_right+gap, 20)\n",
    "    if w is not None and b is not None: \n",
    "        ax.plot(xplot, (-b - w[0]*xplot)/w[1], color=\"gray\", lw=2, zorder=1)\n",
    "        ax.plot(xplot, ( 1 -b - w[0]*xplot)/w[1], color=\"gray\", lw=2, ls=\"--\", zorder=1)\n",
    "        ax.plot(xplot, (-1 -b - w[0]*xplot)/w[1], color=\"gray\", lw=2, ls=\"--\", zorder=1)\n",
    "        \n",
    "    \n",
    "    ax.set_xlim([lower_left-gap, upper_right+gap])\n",
    "    ax.set_ylim([lower_left-gap, upper_right+gap])\n",
    "    \n",
    "    ax.grid(alpha=0.25)\n",
    "    \n",
    "def part2data():\n",
    "    \n",
    "    np.random.seed(1239)\n",
    "    \n",
    "    X = np.zeros((22,2))\n",
    "    X[0:10,0]  = 1.5*np.random.rand(10) \n",
    "    X[0:10,1]  = 1.5*np.random.rand(10)\n",
    "    X[10:20,0] = 1.5*np.random.rand(10) +  1.75\n",
    "    X[10:20,1] = 1.5*np.random.rand(10) +  1\n",
    "    X[20,0] = 1.5\n",
    "    X[20,1] = 2.25\n",
    "    X[21,0] = 1.6\n",
    "    X[21,1] = 0.25\n",
    "    \n",
    "    y = np.ones(22)\n",
    "    y[10:20] = -1 \n",
    "    y[20] = 1\n",
    "    y[21] = -1\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def part3data(N=100, seed=1235):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    X = np.random.uniform(-1,1,(N,2))\n",
    "    y = np.array([1 if y-x > 0 else -1 for (x,y) in zip(X[:,0]**2 * np.sin(2*np.pi*X[:,0]), X[:,1])])\n",
    "    X = X + np.random.normal(0,.1,(N,2))\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def nonlinear_plot(X, y, clf=None): \n",
    "    \n",
    "    mycolors = {\"blue\": \"steelblue\", \"red\": \"#a76c6e\", \"green\": \"#6a9373\"}\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,10))\n",
    "    \n",
    "    colors = [mycolors[\"red\"] if yi==1 else mycolors[\"blue\"] for yi in y]\n",
    "    ax.scatter(X[:,0],X[:,1], marker='o', color=colors, s=100, alpha=0.5)\n",
    "    \n",
    "    ax.arrow(-1.25,0,2.5,0, head_length=0.05, head_width=0.05, fc=\"gray\", ec=\"gray\", lw=2, alpha=0.25)\n",
    "    ax.arrow(0,-1.25,0,2.5, head_length=0.05, head_width=0.05, fc=\"gray\", ec=\"gray\", lw=2, alpha=0.25)\n",
    "    z = np.linspace(0.25,3.5,10)\n",
    "    \n",
    "    ax.set_xlim([-1.50,1.50])\n",
    "    ax.set_ylim([-1.50,1.50])\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    plt.xticks([], fontsize=16)\n",
    "    plt.yticks([], fontsize=16)\n",
    "    \n",
    "\n",
    "    if clf: \n",
    "        \n",
    "        clf.fit(X,y)\n",
    "\n",
    "        x_min = X[:, 0].min()+.00\n",
    "        x_max = X[:, 0].max()-.00\n",
    "        y_min = X[:, 1].min()+.00\n",
    "        y_max = X[:, 1].max()-.00\n",
    "\n",
    "        colors = [mycolors[\"red\"] if yi==1 else mycolors[\"blue\"] for yi in y]\n",
    "\n",
    "        XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "        Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(XX.shape)\n",
    "        plt.contour(XX, YY, Z, colors=[mycolors[\"blue\"], \"gray\", mycolors[\"red\"]], linestyles=['--', '-', '--'],\n",
    "                    levels=[-1.0, 0, 1.0], linewidths=[2,2,2], alpha=0.9)\n",
    "    \n",
    "\n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "    \n",
    "def plotSearchGrid(grid):\n",
    "    \n",
    "    scores = [x for x in grid.cv_results_[\"mean_test_score\"]]\n",
    "    scores = np.array(scores).reshape(len(grid.param_grid[\"C\"]), len(grid.param_grid[\"gamma\"]))\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot,\n",
    "               norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "    plt.xlabel('gamma')\n",
    "    plt.ylabel('C')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(len(grid.param_grid[\"gamma\"])), grid.param_grid[\"gamma\"], rotation=45)\n",
    "    plt.yticks(np.arange(len(grid.param_grid[\"C\"])), grid.param_grid[\"C\"])\n",
    "    plt.title('Validation accuracy')\n",
    "    plt.show()\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".MathJax nobr>span.math>span{border-left-width:0 !important};\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3db260cdfe2e3fd5bde7e51de784ed5",
     "grade": false,
     "grade_id": "cell-31a3b7024c25101e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 1: SVM [20 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c8a95d829160432c82042a8f83c3c9e",
     "grade": false,
     "grade_id": "cell-b209be9ccc230ed7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data and Labels \n",
    "X = np.array([[1,8],[7,2],[6,-1],[-5,0], [-5,1], [-5,2],[6,3],[6,1],[5,2]])\n",
    "y = np.array([1,-1,-1,1,-1,1,1,-1,-1])\n",
    "\n",
    "# Support vector parameters \n",
    "w, b = np.array([-1/4, 1/4]), -1/4\n",
    "\n",
    "# Plot the data and support vector boundaries \n",
    "linear_plot(X, y, w=w, b=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d8f23799c01bb3c5ecae836d791874a",
     "grade": false,
     "grade_id": "cell-4af1c2c8e25b86a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part A [5 pts]**: What is the margin of this particular SVM? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dc6a9d558f2f2a1d2d60f2359db8208",
     "grade": false,
     "grade_id": "cell-d2c22d2902abfd48",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "margin = 0 # update margin to be a correct number\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72fc2301be0bd68630be57817ab37dbb",
     "grade": true,
     "grade_id": "cell-3e98224eab83e882",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests that margin was updated correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0102cc99271d6636aa75b3b3af1c07d",
     "grade": false,
     "grade_id": "cell-32f1b6b1bd799f14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part B [5 pts]**: Which training examples are the support vectors? Assign the coordinate in the list. e.g. support_vectors = [(1,0),(0,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "859ab5c28daeb97dcd15cfb090c4905e",
     "grade": false,
     "grade_id": "cell-f101ca7047e7c8b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# uncomment and update support_vectors  \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# support_vectors=[(1,0),(0,0)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4707c2fcc1f319ee875a7a75310cabe8",
     "grade": true,
     "grade_id": "cell-96b9ab3c0b9c7f53",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests support_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "952451b7d96ef5ecc23018ac034898ba",
     "grade": false,
     "grade_id": "cell-cde429d10fa2efff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Explain your answer for which training examples are support vectors. For the support vectors that you have identified, which are the in-bound support vectors and which are the out-bound support vectors? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ad74f6b9786d843cdb84bbc257daae7",
     "grade": false,
     "grade_id": "cell-d03112737ef3e441",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# instructor testing cell \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d6fcb7467f123df5b12a2d695322dac1",
     "grade": false,
     "grade_id": "cell-e10927a9a10f48fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part C [5 pts]**: Which training examples have nonzero slack? List their coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5a81468215ef1b381172a7ff02df6b9",
     "grade": false,
     "grade_id": "cell-bf3d5b1c0594a8e3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# list of coordinates with nonzero slack \n",
    "nonzero_slack=[]\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8aef65b6c84b0b5e7a7f9ea728181014",
     "grade": true,
     "grade_id": "cell-a8b409e6b2393568",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests nonzero_slack list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73ca66ecb14ac7d7749b4cc0e56c6e16",
     "grade": false,
     "grade_id": "cell-9e73d3eed45f34ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "How did you know which training examples had nonzero slack? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cc37a19ea16478db467e5cee58b5e55",
     "grade": false,
     "grade_id": "cell-dcf87cd2624d3317",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# instructor testing cell\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3deb7f412d7595196dddcb72c682af8",
     "grade": false,
     "grade_id": "cell-070928c539e32d09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part D [5 pts]**: Compute the slack $\\xi_i$ associated with the misclassified points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "729978dc4dfe6eeb84a5f40e91ee7444",
     "grade": false,
     "grade_id": "cell-dc05aeda72d2ddec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# compute the slack associated with the misclassified points\n",
    "# return a list slacks with the slack computations\n",
    "# slacks = [slack1, slack2]\n",
    "# slack1 = \n",
    "# slack2 = \n",
    "print(slacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "830167fd3dc9cbf240a31b53755354da",
     "grade": true,
     "grade_id": "cell-884383beca3f9d0f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests slacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56634119776235dc59b9d3d99cc567e5",
     "grade": false,
     "grade_id": "cell-ce44c130afd902bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Do these slack values agree with the plot of the data and the support vector boundaries? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d0cfdf03e2954695b7b88d8104cd16d",
     "grade": false,
     "grade_id": "cell-4a15d10c45a74de4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 2: The Margin vs Slack [20 pts]\n",
    "***\n",
    "\n",
    "In this problem we'll figure out how to fit linear SVM models to data using sklearn.  Consider the data shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25453a4e89111025ee5001053ea983a8",
     "grade": false,
     "grade_id": "cell-f87ca993405428e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X, y = part2data()\n",
    "linear_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4522ccece7623219417e99ffb7401e34",
     "grade": false,
     "grade_id": "cell-1f081e45c268aaf3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part A [5 pts]**: Let's fit a linear Soft-Margin SVM to the data above. For SVMs with a linear kernel we'll use the [`LinearSVM`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) method from sklearn's `svm` module.  Go now and look at the documentation. \n",
    "\n",
    "Recall that the primal objective function for the linear kernel SVM is as follows \n",
    "\n",
    "\n",
    "$$\n",
    "\\min_{{\\bf w}, b, {\\bf \\xi}} \\frac{1}{2}\\|{\\bf w}\\|^2 + C \\sum_{i=1}^m \\xi_i^p.\n",
    "$$\n",
    "**Note that the C parameter definition in sklearn is different from the textbook.**\n",
    "\n",
    "The two optional parameters in `LinearSVM` that we'll be most concerned with are `C`, the hyperparameter weighting the slackness contribution to the primal objective function, and `loss`, which determines the exponent on the slack variables in the sum. When $p=1$ from above equation, the loss is hinge loss, whereas is $p=2$, it's $L2$ form, the loss is called squared-hinge.\n",
    "\n",
    "Write some code below to train a linear SVM with $C=1$ and $p=1$, get the computed weight vector and bias, and the plot the resulting model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21c4e9773e9b6785bda99445fe9300e7",
     "grade": false,
     "grade_id": "cell-a8b5a74b427e0a86",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# TODO: Build a LinearSVC model called lsvm. Train the model and get the parameters, pay attention to the loss parameter\n",
    "lsvm = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# use this code to plot the resulting model\n",
    "w = lsvm.coef_[0]\n",
    "b = lsvm.intercept_\n",
    "print(w,b)\n",
    "linear_plot(X, y, w=w, b=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25eb1c5dd0d4916de32c208d43fd54da",
     "grade": true,
     "grade_id": "cell-5df97e1fbfc866fc",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests w and b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6e3b13534c267d0d3ca5c2338e23036",
     "grade": false,
     "grade_id": "cell-42d9f20f45c886c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part B [5 pts]**: Experiment with different values of `C`. How does the choice of `C` affect the nature of the decision boundary and the associated margin? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27858a1123eecc536d8ab9e4bb44271b",
     "grade": false,
     "grade_id": "cell-cc0815301b636e29",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# TODO: Change the svm model parameter and plot the result.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36893fc04c1bba859a0380b20462a2ee",
     "grade": false,
     "grade_id": "cell-64ffe9e96f7d2afe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part C [5 pts]**: Set `C=3` and compare the results you get when using the `hinge` vs the `squared_hinge` values for the `loss` parameter. Explain your observations. Compare hinge loss vs. squared hinge loss.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f4f864284bb6de45eda3791460b40e6",
     "grade": false,
     "grade_id": "cell-7828d7a24ec0edc5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# TODO: Train the model and get the parameters, pay attention to the loss parameter\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51c017a1bade51c5bbac6133a9d64d3d",
     "grade": false,
     "grade_id": "cell-f116bc8b54602cbd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part D [5 pts]**: In general, how does the choice of `C` affect the bias and variance of the model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a45e4c0c176b060a064f3db687a946a",
     "grade": false,
     "grade_id": "cell-771d2b8c6b04fcd1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "298af4694bf6e24dcc5a3edca7ac7b98",
     "grade": false,
     "grade_id": "cell-f68a38a5526f246b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 3: Nonlinear SVM, Parameter Tuning, Accuracy, and Cross-Validation [25 pts]\n",
    "***\n",
    "\n",
    "Any support vector machine classifier will have at least one parameter that needs to be tuned based on the training data.  The guaranteed parameter is the $C$ associated with the slack variables in the primal objective function, i.e. \n",
    "\n",
    "$$\n",
    "\\min_{{\\bf w}, b, {\\bf \\xi}} \\frac{1}{2}\\|{\\bf w}\\|^2 + C \\sum_{i=1}^m \\xi_i\n",
    "$$\n",
    "\n",
    "If you use a kernel fancier than the linear kernel then you will likely have other parameters as well. For instance in the polynomial kernel $K({\\bf x}, {\\bf z}) = ({\\bf x}^T{\\bf z} + c)^d$ you have to select the shift $c$ and the polynomial degree $d$.  Similarly the rbf kernel\n",
    "\n",
    "$$\n",
    "K({\\bf x}, {\\bf z}) = \\exp\\left[-\\gamma\\|{\\bf x} - {\\bf z}\\|^2\\right]\n",
    "$$\n",
    "\n",
    "has one tuning parameter, namely $\\gamma$, which controls how fast the similarity measure drops off with distance between ${\\bf x}$ and ${\\bf z}$. \n",
    "\n",
    "For our examples we'll consider the rbf kernel, which gives us two parameters to tune, namely $C$ and $\\gamma$. \n",
    "\n",
    "Consider the following two dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "599fd4fc1e48d31c4de9ed1562998bef",
     "grade": false,
     "grade_id": "cell-3f41670b44133217",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X, y = part3data(N=300, seed=1235)\n",
    "nonlinear_plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8309b11c0d47071f770ffb2e5341b02e",
     "grade": false,
     "grade_id": "cell-7bca007fc3a38ff4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part A [5 pts]**: We can use the method [SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) from sklearn's `svm` module to fit an SVM with a nonlinear kernel to the data.  Go now and look at the documentation. Note that we pass the `kernel=\"rbr\"` parameter to use the RBF kernel.  The other two parameters we'll be concerned with are `C` and the RBF parameter `gamma`.   \n",
    "\n",
    "Write some code to fit an SVM with RBF kernel to the data and plot the results.  Use the parameter values `C=1` and `gamma=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d9bfe1e80130e7dfa55a826732537fe",
     "grade": false,
     "grade_id": "cell-adce42aa3d81a3eb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "nlsvm= None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "nonlinear_plot(X, y, nlsvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d2e2dd8c42361709a0920d4e276fd2ce",
     "grade": false,
     "grade_id": "cell-17c15ee165a24978",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part B [15 pts]**: In this part we'll use cross-validation to estimate the validation accuracy achieved by our model.  Experiment with the values of the hyperparameters to see if you can get a good validation accuracy. How do the choice of `C` and `gamma` affect the resulting decision boundary? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25aadb4a79f10ebff520f608c063a4c3",
     "grade": false,
     "grade_id": "cell-af361a2ddbbee073",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# uncomment and update nlsvm and scores\n",
    "# nlsvm =None\n",
    "# scores=0\n",
    "print(\"cross-val mean-accuracy: {:.3f}\".format(np.mean(scores)))\n",
    "nonlinear_plot(X, y, nlsvm)\n",
    "\n",
    "# C tuning\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# gamma tuning\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "335bcbe8040ca1b9662067684a6fd3bf",
     "grade": false,
     "grade_id": "cell-dce482f5c8eccff0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part C [5 pts]**: How does the choice of **kernel** function affect the bias/variance of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db418f1534d082f2fdccaceeecbe7ae1",
     "grade": false,
     "grade_id": "cell-ad484dfaa0cdab66",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# instructor testing cell \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be35c0edf61309ce58653113fa3b6fbf",
     "grade": false,
     "grade_id": "cell-57c1d6ad0baf30e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 4: Automating the Parameter Search [20 pts]\n",
    "***\n",
    "\n",
    "On the previous problem we were able to choose some OK parameters just by hand-tuning.  But in real life (where time is money) it would be better to do something a little more automated.  One common thing to do is a **grid-search** over a predefined range of the parameters.  In this case you will loop over all possible combinations of parameters, estimate the accuracy of your model using K-Folds cross-validation, and then choose the parameter combination that produces the highest validation accuracy. \n",
    "\n",
    "**Part A [5 pts]**: Below is an experiment where we search over a logarithmic range between $2^{-5}$ and $2^{5}$ for $C$ and a range between $2^{-5}$ and $2^{5}$ for $\\gamma$.  For the accuracy measure we use K-Folds CV with $K=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4882acb7994ad36959a9f6a2cf3c9724",
     "grade": false,
     "grade_id": "cell-d1c858a08a7e3b1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "grid=None # ToDo: replace it to proper GridSearchCV object and run the grid search with cross validation\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6395bcba13ac869e650494bcdb9200a4",
     "grade": false,
     "grade_id": "cell-e780d11252930bd5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part B [5 pts]**: The following function will plot a heat-map of the cross-validation accuracies for each combination of parameters.  Which combination looks the best? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99934202c7bcea5e6d22e50e644fa7f9",
     "grade": false,
     "grade_id": "cell-0c174922a30ab274",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plotSearchGrid(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44efe8edc72556045963e6d4877e16ab",
     "grade": false,
     "grade_id": "cell-3a0c8e12a4b5f54e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# instuctor testing cell \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2075afde9e35878704db390c5eda9c23",
     "grade": false,
     "grade_id": "cell-d97342015823c52e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part C [5 pts]**: The GridSearchCV object scores, among other things, the best combination of parameters as well as the cross-validation accuracy achieved with those parameters.  Print those quantities for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2410153f45725f383f512245d98fa78",
     "grade": false,
     "grade_id": "cell-796fb8e2baf408f5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# print best paramters and best accuracy \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9d060e35efdb69672f8428bce45e314",
     "grade": false,
     "grade_id": "cell-dfb29db96cbc8e92",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part D [5 pts]**: The GridSearchCV object also stores the classifier trained with the best hyperparameters.  Pass this best estimator into the `nonlinear_plot` function to view the best decision boundary. What can you tell about the best decision boundary? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e34404baab357934ff9a7f6e9d0d3b2d",
     "grade": false,
     "grade_id": "cell-2e1ff57c7efa556c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# pass GridSearchCV object best estimator into nonlinear_plot\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
