{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"HW3.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8ae6945a5595d011",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "The final score that you will receive for your programming assignment is generated in relation to the total points set in your programming assignment item‚Äînot the total point value in the autograder output.     \n",
    "Autograded quesions may have hidden tests and/or public tests. You can see the public test results when you run the notebook with otter grader. Usually public tests are for simple checks (such as variable types) and may not indicate that the answer is correct.     \n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** The autograder will not work properly if your change the variable or method signatures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dbd2d13ca117f619",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# K-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-19fba0d07cf433ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the cell below to ensure that the required packages are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e64ccd51e3e81b02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# importing all the required libraries\n",
    "\n",
    "from math import exp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-703de6192d07f99f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 1 : Building a K- Nearest neighbours classifier for handwritten digit recognition [30 pts]\n",
    "In this problem you will complete some code to build a k-nearest neighbour classifier to classify images of handwritten digits (0-9). For this purpose we will use a famous open-source dataset of handwritten digits called the MNIST that is ubiquitously used for testing a number of classification algorithms in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d0067365eb87b126",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell sets up the MNIST dataset \n",
    "\n",
    "class MNIST_import:\n",
    "    \"\"\"\n",
    "    sets up MNIST dataset from OpenML \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        df = pd.read_csv(\"data/mnist_784.csv.gz\", compression='gzip')\n",
    "        \n",
    "        # Create arrays for the features and the response variable\n",
    "        # store for use later \n",
    "        y = df['class'].values\n",
    "        X = df.drop('class', axis=1).values\n",
    "         \n",
    "        # Convert the labels to numeric labels\n",
    "        y = np.array(pd.to_numeric(y))\n",
    "        \n",
    "        # create training and validation sets \n",
    "        self.train_x, self.train_y = X[:5000,:], y[:5000]\n",
    "        self.val_x, self.val_y = X[5000:6000,:], y[5000:6000]\n",
    "        \n",
    "data = MNIST_import()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7552f1b93c13729b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def view_digit(x, label=None):\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    plt.imshow(x.reshape(28,28), cmap='gray');\n",
    "    plt.xticks([]); plt.yticks([]);\n",
    "    if label: plt.xlabel(\"true: {}\".format(label), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b5f5237b858c449d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Display a particular digit using the above function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3e3b1bbbe1467ca7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "training_index = 9\n",
    "\n",
    "view_digit(data.train_x[training_index], data.train_y[training_index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-87383daf2fbafe0a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part 1.A [5 points]**\n",
    "Fill in the code in the following cell to determine the following quantities:\n",
    "   - Number of pixels in each image\n",
    "   - Number of examples in the training set\n",
    "   - Number of examples in the test set\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-217762899b37f199",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here are the numbers you need to provide here:\n",
    "num_training_examples = 0\n",
    "num_test_examples = 0\n",
    "pixels_per_image = 0\n",
    "\n",
    "...\n",
    "\n",
    "print(num_training_examples)\n",
    "print(num_test_examples)\n",
    "print(pixels_per_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7b3967987775d7c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we have our MNIST data in the right form, let us move on to building our KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-757b46aa24e4f614",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part 1.B [10 points]**: Modify the class above to implement a KNN classifier.  There are three methods that you need to complete: \n",
    "\n",
    "- `predict`: Given an $m \\times p$ matrix of validation data with $m$ examples each with $p$ features, return a length-$m$ vector of predicted labels by calling the `classify` function on each example. \n",
    "- `classify`: Given a single query example with $p$ features, return its predicted class label as an integer using KNN by calling the `majority` function. \n",
    "- `majority`: Given an array of indices into the training set corresponding to the $K$ training examples that are nearest to the query point, return the majority label as an integer.  If there is a tie for the majority label using $K$ nearest neighbors, reduce $K$ by 1 and try again.  Continue reducing $K$ until there is a winning label. \n",
    "\n",
    "**Notes**: \n",
    "- Do not implement nearest-neighbor search or any distance metrics yourself. Instead, read the documentation for Scikit-Learn's [BallTree](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html) object.  You will find that its implemented [query](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html#sklearn.neighbors.BallTree.query) method can do most of the heavy lifting for you. \n",
    "- Do not use Scikit-Learn's KNeighborsClassifier in this problem.  We're implementing this ourselves using BallTree.\n",
    "- For more information about different algorithms under the K-nearest neighbors and which algorithms are being used by sklearn in different scenarios, please see User guide p.263."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-814a5ca0dfd2a437",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    \"\"\"\n",
    "    Class to store data for regression problems \n",
    "    \"\"\"\n",
    "    def __init__(self, x_train, y_train, K=5):\n",
    "        \"\"\"\n",
    "        Creates a kNN instance\n",
    "\n",
    "        :param x_train: numpy array with shape (n_rows,1)- e.g. [[1,2],[3,4]]\n",
    "        :param y_train: numpy array with shape (n_rows,)- e.g. [1,-1]\n",
    "        :param K: The number of nearest points to consider in classification\n",
    "        \"\"\"\n",
    "        \n",
    "        # Import and build the BallTree on training features \n",
    "        from sklearn.neighbors import BallTree\n",
    "        self.balltree = BallTree(x_train)\n",
    "        \n",
    "        # Cache training labels and parameter K \n",
    "        self.y_train = y_train\n",
    "        self.K = K \n",
    "        \n",
    "        \n",
    "    def majority(self, neighbor_indices, neighbor_distances=None):\n",
    "        \"\"\"\n",
    "        Given indices of nearest neighbors in training set, return the majority label. \n",
    "        Break ties by considering 1 fewer neighbor until a clear winner is found. \n",
    "\n",
    "        :param neighbor_indices: The indices of the K nearest neighbors in self.X_train \n",
    "        :param neighbor_distances: Corresponding distances from query point to K nearest neighbors. \n",
    "        \"\"\"\n",
    "        \n",
    "        ...\n",
    "            \n",
    "        \n",
    "    def classify(self, x):\n",
    "        \"\"\"\n",
    "        Given a query point, return the predicted label \n",
    "        \n",
    "        :param x: a query point stored as an ndarray  \n",
    "        \"\"\"\n",
    "        ...\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Given an ndarray of query points, return yhat, an ndarray of predictions \n",
    "\n",
    "        :param X: an (m x p) dimension ndarray of points to predict labels for \n",
    "        \"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce189b2957563a2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Part 1.C : Checking how well your classifier does [5 pts]**    \n",
    "Use your `KNN` class to perform KNN on the validation data with $K=3$ and do the following: \n",
    "\n",
    "1. Create a **confusion matrix** and display the results (Hont: Feel free to use the Scikit-Learn [confusion_matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function).\n",
    "\n",
    "2. Based on your confusion matrix, which digits seem to get confused with other digits the most? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-acaff11620e9a669",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use your KNN class to perform KNN on the validation data with K = 3\n",
    "# knn = \n",
    "# val_yhat = \n",
    "\n",
    "# create a confusion matrix \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d7a33a558ddc8690",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Part 1.D [10 pts] Accuracy Plot:** \n",
    "1. Create a plot of the accuracy of the KNN on the test set on the same set of axes for  ùêæ=1,2,‚Ä¶,20  (feel free to go out to ùêæ=30  if your implementation is efficient enough to allow it). <br>\n",
    "\n",
    "2. Based on the plot, which value of K results in highest accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-711e2eff0fa2c38e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = []\n",
    "wacc = []\n",
    "allks = range(1,30)\n",
    "\n",
    "...\n",
    "\n",
    "# you can use this code to create your plot    \n",
    "fig, ax = plt.subplots(nrows=1,ncols=1,figsize=(12,7))\n",
    "ax.plot(allks, acc, marker=\"o\", color=\"steelblue\", lw=3, label=\"unweighted\")\n",
    "ax.set_xlabel(\"number neighbors\", fontsize=16)\n",
    "ax.set_ylabel(\"accuracy\", fontsize=16)\n",
    "plt.xticks(range(1,31,2))\n",
    "ax.grid(alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c04a2c214c40b6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Problem 2: Decision Tree, post-pruning and cost complexity parameter using sklearn > 0.22 [50 points]\n",
    "\n",
    "We will use a pre-processed natural language dataset in the CSV file \"spamdata.csv\" to classify emails as spam or not. Each row contains the word frequency for 54 words plus statistics on the longest \"run\" of captial letters.\n",
    "\n",
    "Word frequency is given by:\n",
    "\n",
    "$$ f_i = m_i / N $$\n",
    "Where $f_i$ is the frequency for word $i$, $m_i$ is the number of times word $i$ appears in the email, and $N$ is the total number of words in the email.\n",
    "\n",
    "We will use decision trees to classify the emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9469ebbf05e61aa4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part 2.A [5 points]:** Complete the function `get_spam_dataset` to read in values from the dataset and split the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f3baeed090895e48",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_spam_dataset(filepath, test_split=0.1):\n",
    "    '''\n",
    "    get_spam_dataset\n",
    "    \n",
    "    Loads csv file located at \"filepath\". Shuffles the data and splits\n",
    "    it so that the you have (1-test_split)*100% training examples and \n",
    "    (test_split)*100% testing examples.\n",
    "    \n",
    "    Args:\n",
    "        filepath: location of the csv file\n",
    "        test_split: percentage/100 of the data should be the testing split\n",
    "        \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test, feature_names\n",
    "        \n",
    "        (in that order)\n",
    "        first four are  np.ndarray\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "test_split = 0.1 # default test_split; change it if you'd like; ensure that this variable is used as an argument to your function\n",
    "\n",
    "X_train, X_test, y_train, y_test, label_names = get_spam_dataset(filepath=\"data/spamdata.csv.gz\",test_split=test_split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ac7a846b7ca9e011",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part 2.B [5 points]** : Build a decision tree classifier using the sklearn toolbox. Then compute metrics for performance like precision and recall. This is a binary classification problem, therefore we can label all points as either positive (SPAM) or negative (NOT SPAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-146547fa0aaeaff9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dt(data_X, data_y, max_depth = None, max_leaf_nodes =None):\n",
    "    '''\n",
    "    This function builds the decision tree classifier and \n",
    "    fits it to the provided data.\n",
    "    \n",
    "    Arguments\n",
    "        data_X - a np.ndarray\n",
    "        data_y - np.ndarray\n",
    "        max_depth - None if unrestricted, otherwise an integer for the maximum\n",
    "                depth the tree can reach.\n",
    "    \n",
    "    Returns:\n",
    "        A trained DecisionTreeClassifier\n",
    "    '''\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-908ed30f5b48c007",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Part 2.C [10 pts]**: Here we are going to use `calculate_precision` and `calculate_recall` functions to see how these metrics change when parameters of the tree are changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e4e597da7a07ff30",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_precision(y_true, y_pred, pos_label_value=1.0):\n",
    "    '''\n",
    "    This function accepts the labels and the predictions, then\n",
    "    calculates precision for a binary classifier.\n",
    "    \n",
    "    Args\n",
    "        y_true: np.ndarray\n",
    "        y_pred: np.ndarray\n",
    "        \n",
    "        pos_label_value: (float) the number which represents the postiive\n",
    "        label in the y_true and y_pred arrays. Other numbers will be taken\n",
    "        to be the non-positive class for the binary classifier.\n",
    "    \n",
    "    Returns precision as a floating point number between 0.0 and 1.0\n",
    "    '''\n",
    "    ...\n",
    "    \n",
    "    pass\n",
    "\n",
    "def calculate_recall(y_true, y_pred, pos_label_value=1.0):\n",
    "    '''\n",
    "    This function accepts the labels and the predictions, then\n",
    "    calculates recall for a binary classifier.\n",
    "    \n",
    "    Args\n",
    "        y_true: np.ndarray\n",
    "        y_pred: np.ndarray\n",
    "        \n",
    "        pos_label_value: (float) the number which represents the postiive\n",
    "        label in the y_true and y_pred arrays. Other numbers will be taken\n",
    "        to be the non-positive class for the binary classifier.\n",
    "    \n",
    "    Returns precision as a floating point number between 0.0 and 1.0\n",
    "    '''\n",
    "    \n",
    "    ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9bcac958bcd924d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Part 2.D-1 [5 pts]:** Modifying `max_depth`: \n",
    "    - Create a model with a shallow `max_depth` of 2. Build the model on the training set.\n",
    "    - Report precision/recall on the test set.\n",
    "    - Report depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4da56f168aee9716",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO : Complete the first subtask for max_depth\n",
    "# precision = \n",
    "# recall = \n",
    "\n",
    "...\n",
    "\n",
    "print(\"Precision: {:0.2f} Recall: {:0.2f} Tree Depth: {}\".format(precision, recall, dt.get_depth()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef216e433b64fead",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Part 2.D-2 [5 pts]:**  Modifying `max_leaf_nodes`:\n",
    "    - Create a model with a shallow `max_leaf_nodes` of 4. Build the model on the training set.\n",
    "    - Report precision/recall on the test set.\n",
    "    - Report depth of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab9251af73821eb8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO : Complete the second subtask for max_depth\n",
    "# precision = \n",
    "# recall = \n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "print(\"Precision: {:0.2f} Recall: {:0.2f} No. of leaves: {}\".format(precision, recall, dt.get_n_leaves()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1eb1aaf40d8bd956",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Part 2.D-3 [10 pts]:** Answer the following question: <br>\n",
    "How do precision and recall compare when you modify the max depth compared to the max number of leaf nodes? \n",
    "(Make sure to run your models a few times to get an idea). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-870b3afd71a87d89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Part 2.E [10 pts]** : In class, we used gridsearchCV to do hyperparameter tuning to select the different parameters like `max_depth` to see how our tree grows and avoids overfitting. Here, we will use cost complexity pruning parameter $\\alpha$ sklearn 0.22.1[https://scikit-learn.org/stable/user_guide.html] (or a later version) to prune our tree after training so as to improve accuracy on unseen data. In this exercise you will iterate over different `ccp_alpha` values and identify how performance is modulated by this parameter. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-70caed0260dd7c0c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt = build_dt(X_train, y_train)\n",
    "\n",
    "path = dt.cost_complexity_pruning_path(X_train,y_train) #post pruning\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "clfs = [] # VECTOR CONTAINING CLASSIFIERS FOR DIFFERENT ALPHAS\n",
    "# TODO: iterate over ccp_alpha values \n",
    "...\n",
    "    \n",
    "print(\"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
    "      clfs[-1].tree_.node_count, ccp_alphas[-1]))\n",
    "\n",
    "# TODO: next, generate the train and test scores and plot the variation in these scores with increase in ccp_alpha\n",
    "# The code for plotting has been provided; edit the train_scores and test_scores variables for the right plot to be generated\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "...\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"accuracy vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n",
    "        drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "These are some submission instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
