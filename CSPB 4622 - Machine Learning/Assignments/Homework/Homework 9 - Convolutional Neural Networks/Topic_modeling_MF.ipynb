{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comparable-optics",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f275e7110ceddd6e18752141d680b59",
     "grade": false,
     "grade_id": "cell-68900ebe59253a81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# BBC News Classification\n",
    "In this assignment, we will use data from https://www.kaggle.com/c/learn-ai-bbc/overview, which is a Kaggle competition is about categorizing news articles. You will use matrix factorization to predict the category, submit your results to Kaggle for test evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import NMF\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-kinase",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9925d764d96ff6f075c0bf370c2a221",
     "grade": false,
     "grade_id": "cell-143925419609c138",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Loading train data\n",
    "articles = pd.read_csv(\"data/bbc/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-thomson",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e74ef20f4baf5191350f69739d105d5f",
     "grade": false,
     "grade_id": "cell-75721c43df8bd496",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Displaying what the data looks like\n",
    "# It has article id, article texts, and category. Here, category is the laabel.\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-relay",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6316605b4acb39564a2adc19df14f590",
     "grade": false,
     "grade_id": "cell-7deab6ad2514c41f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's print out a sample article text. You'll also see special characters.\n",
    "articles['Text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-relevance",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acea9c8d64667000fb2d36934d98724d",
     "grade": false,
     "grade_id": "cell-24176612609526b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# There are 5 unique categories (labels)\n",
    "articles['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-energy",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04f3c5cf4f746287b5c854101e5dcdd3",
     "grade": false,
     "grade_id": "cell-f83d24c2277e8d4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's see how many articles are in each category. It shows that the categories are reasonably balanced.\n",
    "plt.hist(articles['Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-spanish",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf9c031038ac98b56c5ed1e48f102231",
     "grade": false,
     "grade_id": "cell-1f0e38ada827728f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q1. Text preprocessing\n",
    "As we have done simple EDA, now, let's extract some feaures from the text.\n",
    "Read sklearn document for [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) and [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer). Search online about text preprocessing methods based on word count and TF-IDF. \n",
    "### [10 pts] Summarize/explain what those methods are. Why is TF-IDF better than simple word count?\n",
    "(optional: Search and explain other text preprocessing methods such as GloVe or Word2Vec. you can include python snippets on how to use them). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-peripheral",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f94a94c616e2b2a26ab1f25f7f2c110b",
     "grade": true,
     "grade_id": "cell-84f1bc3dc80fc870",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-hometown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e762d570499f6206a2226781c4125b11",
     "grade": false,
     "grade_id": "cell-899742352d81079b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the below example, we will show how to use feature extraction vectorizer. We will show CountVectorizer, but the usage of TfidfVectorizer is also similar. The vectorizer has many options, but `max_features` is most often used. A collection of all words in the all articles is called vocabulary. Since the vocabulary can include so many words, often we want to limit the number of vocabularies in our feature vector. `max_features` is a parameter that sets the limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 1490 articles in the train data\n",
    "data_samples = articles['Text']\n",
    "print(len(data_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take an example of CountVectorizer\n",
    "n_features = 200 # For example, we decided to include only 200 words in our vocabulary (but often it needs bigger number) \n",
    "count_vectorizer = CountVectorizer(max_features=n_features, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .fit_transform() transforms the text data to feature vectors. \n",
    "# Here, the feature matrix from CountVectorizer is a word count vector\n",
    "wordcount = count_vectorizer.fit_transform(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This feature matrix has a shape of (# of articles, # max features)\n",
    "# The matrix is a sparse matrix format for computation efficiency.\n",
    "wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although you can convert a sparse matrix to dense matrix to see the content, \n",
    "# usually we don't want to load a dense matrix of very big matrix (such as a matrix with multiple thousands or millions of rows and cols).\n",
    "# Here, just to show what's inside:\n",
    "wordcount.todense()\n",
    "# It shows a word count fewature matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example, the feature vector for the last third article is this:\n",
    "wordcount.todense()[-3]\n",
    "# It has 0 count the first vocabulary, 1 count for the second vocabulary, 1 count for the third vocabulary, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .vocabulary_ shows word count for each word in the selected vocabulary in the data\n",
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-tennessee",
   "metadata": {},
   "source": [
    "## Q2. Topic Modeling using NMF\n",
    "Below are the starter codes. We will build TopicModeling class which predicts article labels using NMF algorithm.\n",
    "You'll need to complete `factorize` and `predict` methods.\n",
    "\n",
    "### Q2.a Complete factorize function [15 pts]\n",
    "5 pts each for each STEP. You can do the similar fro mthe example above.    \n",
    "**Note:** `self.X` is the train and test data combined. In the STEP2 in `factorize` function, we fit all the data so that the feature matrix contains vocabularies from both trin and test data. You could fit with only texts from train data, but then there might be some vocabularies from test data that don't exist in train data. Since we're not showing the labels to the model, using the vectorizer feature extraction with combined data is ok.\n",
    "\n",
    "### Q2.b Complete STEP4 in predict function [10 pts]\n",
    "self.features is a feature matrix from the tf-idf vectorizer.\n",
    "You can retrieve the fitted feature matrix from train data portion by `self.features[:self.n_tr]`\n",
    "You can calculate `yp_tr` using this train part of the feature matrix. Use the matrix factorization formula (theory) for prediction. It involves some dot products and transpose of matrices. numpy operations require matrices to be numpy array format, which is why we reformatted `tfidf` to `self.features` using `numpy.array` at the end of the `factorize` function.\n",
    "\n",
    "### Q2.c Complete STEP 5 in predict function [15 pts]\n",
    "Map the numeric label values 0,1,2,3,4 from the prediction to category strings. Save the test prediction labels to `self.test['Category']`. For example, `self.test['Category']` may look like:    \n",
    "\n",
    "|     |              |\n",
    "|:----|:------------|     \n",
    "|0    |         sport|    \n",
    "|1    |           tech|     \n",
    "|2    |          sport|    \n",
    "|3    |       business|    \n",
    "|4    |          sport|\n",
    "|...|          |\n",
    "|730  |       business|\n",
    "|731  |  entertainment|\n",
    "|732  |           tech|\n",
    "|733  |       business|\n",
    "|734  |       politics|\n",
    "Name: Category, Length: 735, dtype: object\n",
    "\n",
    "How can you map the integers to the string labels? You can use train data: You can compare the train label string `yt[i]` and the predicted integers from train data `yp_tr[i]` for each sample. Since the model isn't going to predict on train data perfectly, sometimes the match may be wrong. But if you keep track of the matching predicted integer labels for each string label then you can find the majority of the integer index corresponding to the string label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-windsor",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3fe3af4030c1d7d4a754a7b74a8273b",
     "grade": true,
     "grade_id": "cell-419ebfff64eeee3c",
     "locked": false,
     "points": 40,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class TopicModeling():\n",
    "    def __init__(self):\n",
    "        self.getdata()\n",
    "        \n",
    "    def getdata(self):\n",
    "        self.train = pd.read_csv(\"data/bbc/train.csv\")\n",
    "        self.test = pd.read_csv(\"data/bbc/test.csv\")\n",
    "        self.X = list(self.train.Text)+list(self.test.Text) # To make the common vocabulary, we will have all texts from train and test data. Don't worry, as long as we don't show test labels, it's not showing the answer.\n",
    "        self.n_tr = len(self.train)\n",
    "        self.n_te = len(self.test)\n",
    "        \n",
    "    def factorize(self,n_features):\n",
    "        self.n_features = n_features\n",
    "        # STEP1. Construct tf-idf vectorizer that accepts max features of n_features. Use parameters max_df=0.95, min_df=2\n",
    "        # tfidf_vectorizer = \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        \n",
    "        # STEP2. Fit the tfidf_vectorizer using the all data X above. Assign the transformed result matrix as tfidf. [5 pts]\n",
    "        # tfidf = \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        \n",
    "        # STEP3. Fit the model using sklearn NMF and assign to self.model\n",
    "        # self.model = \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        self.tfidf = tfidf\n",
    "        self.features = np.array(tfidf.toarray()) #saves the feature matrix in numpy array format. You'll need when predict.\n",
    "        \n",
    "    def predict(self):\n",
    "        # STEP4. Predict labels for train and test data using matrix algebra.\n",
    "        # Refer to the usage in https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html\n",
    "        # The predicted labels are numeric; 0-4\n",
    "        # yp_tr = # predicion from train data\n",
    "        # yp_te = # prediction from test data\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        \n",
    "        # STEP5. Map the numeric values 0-4 from the prediction to string values of label category.\n",
    "        # You can compare the true labels from train data with yp_tr prediction labels from train data.\n",
    "        # Then you know which number label in yp_tr corresponds which string value. \n",
    "        # update self.test['Category'] to the string labels accordingly.\n",
    "        yt = list(self.train['Category'])\n",
    "        # self.test['Category'] =\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        \n",
    "    def save(self): # This function helps to create submission file\n",
    "        if not os.path.isdir('submission'):\n",
    "            os.mkdir('submission')\n",
    "        self.test[[\"ArticleId\",\"Category\"]].to_csv(\"submission/submission_f\"+str(self.n_features)+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-crime",
   "metadata": {},
   "source": [
    "## Q3. Tune hyper parameters [10 pts]\n",
    "Change your n_features (for example, between 1000 to 10000). \n",
    "Run prediction which will predict and save\n",
    "Print the train accuracy for each n feature. (You can add print statement for train accuracy in the predict function above)\n",
    "Save the test prediction using save function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-example",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2c8467a59fe71d6c0a4631c739137f1",
     "grade": true,
     "grade_id": "cell-1a56545a0c1a0f6e",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-boards",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a5e6862192e712c9222274e01828c1cb",
     "grade": false,
     "grade_id": "cell-c05ba034e17ec2d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q4. Best results [10 pts]\n",
    "Submit a few test prediction (judge based on train accuracy, although the best train accuracy doesn't mean the best test accuracy) and pick which n_features led to the best test acc. Record the result. Discuss your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-seeking",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22d746b91f19f4f077b4234e8b6a87f9",
     "grade": true,
     "grade_id": "cell-edcc80f5c5d7a2a6",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-jefferson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
