\clearpage

\renewcommand{\ChapTitle}{Week 2: (1/22 - 1/28)}
\renewcommand{\SectionTitle}{Representing and Manipulating Information}

\chapter{\ChapTitle}

\section{\SectionTitle}
\horizontalline{0}{0}

\subsection{Assigned Reading}

The reading assignment for this week is:

\begin{itemize}
    \item Computer Systems: Chapter 2.4
    \item Computer Systems: Chapter 3.1
    \item Computer Systems: Chapter 3.2
\end{itemize}

\subsection{Piazza}

Piazza discussions are optional this week. \assignment{1/30/24}{PiazzaWeek2}

\subsection{Lectures}

The lecture videos for this week are:

\begin{itemize}
    \item \lecture{https://www.youtube.com/watch?v=kcSEJUhmmvw}{IEEE Floating Point}{20}
    \item \lecture{https://www.youtube.com/watch?v=U-CKN6F-61U}{IEEE Floating Point: Examples}{24}
    \item \lecture{https://www.youtube.com/watch?v=NVzcjsKdi1s}{IEEE Floating Point: Rounding}{42}
    \item \lecture{https://www.youtube.com/watch?v=bXanYZvUSPY}{Historical Perspective}{22}
    \item \lecture{https://www.youtube.com/watch?v=6nkM996pvu8}{Program Encodings}{26}
    \item \lecture{https://www.youtube.com/watch?v=wfoBy5o2OOY}{GDB Tutorial: Part I - Basic Debugging}{17}
    \item \lecture{https://www.youtube.com/watch?v=Q2vBV1uydgE}{GDB Tutorial: Part II - Printing And Examining Data}{18}
\end{itemize}

\noindent The lecture notes for this week are:

\begin{itemize}
    \item \pdflink{\LecNoteDir Integer Mathematical Operations And Memory Representations Lecture Notes.pdf}{Integer Mathematical Operations And Memory Representations}
    \item \pdflink{\LecNoteDir Floating Point Lecture Notes.pdf}{Floating Point}
    \item \pdflink{\LecNoteDir Floating Point - Examples Lecture Notes.pdf}{Floating Point - Examples}
    \item \pdflink{\LecNoteDir Floating Point - Rounding And Operations Lecture Notes.pdf}{Floating Point - Rounding And Operations}
    \item \href{https://visualgdb.com/gdbreference/commands/}{GDB Reference}
\end{itemize}

\subsection{Assignments}

The assignment for this week is:

\begin{itemize}
    \item \href{https://github.com/cu-cspb-2400-spring-2024/lab1-datalab-QuantumCompiler}{Data Lab} \assignment{1/30/24}{Ass1DueDate}
    \item \href{https://applied.cs.colorado.edu/mod/assign/view.php?id=53179&action=view}{Data Lab Extra Credit} \assignment{1/30/24}{Ass1ECDueDate}
    \item \href{https://applied.cs.colorado.edu/mod/scheduler/view.php?id=53180}{Data Lab Interview} \assignment{1/30/24}{Ass1IntDueDate}
\end{itemize}

\subsection{Quiz}

The quizzes for this week are:

\begin{itemize}
    \item \link{https://applied.cs.colorado.edu/mod/quiz/view.php?id=53190}{Chapter 2.4 Quiz} \textbullet \pdflink{\QuizDir CSPB 2400 Quiz 2.pdf}{Chapter 2.4 Finalized Quiz} \assignment{1/30/24}{Quiz2DueDate}
\end{itemize}

\subsection{Chapter Summary}

The first chapter for this week is \textbf{Chapter 2: Representing And Manipulating Information}. The section that we are covering from this chapter is \textbf{Section 2.4: Floating Point}.

\begin{notes}{Section 2.4: Floating Point}
    \subsection*{Overview}

    Floating point is a method used to represent and manipulate real numbers in computers. It allows for the representation of a vast range of values, from very large to very small, by using a fixed 
    number of bits. A floating point number is typically represented by three components: the sign (indicating positive or negative), the exponent, and the fraction (or mantissa), which represents 
    the precision of the number. \vspace*{1em}

    \subsection*{IEEE 754 Standard}

    \begin{itemize}
        \item \textbf{Purpose}: The IEEE 754 standard is the most widely used standard for floating-point computation, and it defines the format for representing floating-point numbers and the rules 
        for arithmetic operations.
        \item \textbf{Formats}: It includes several formats, but the two most common are single precision (32 bits) and double precision (64 bits).
    \end{itemize}

    \subsection*{Floating Point Representation}

    \begin{itemize}
        \item \textbf{Single Precision (32-bit)}: Consists of 1 bit for the sign, 8 bits for the exponent, and 23 bits for the fraction.
        \item \textbf{Double Precision (64-bit)}: Consists of 1 bit for the sign, 11 bits for the exponent, and 52 bits for the fraction.
    \end{itemize}

    \subsection*{Normalization}

    \begin{itemize}
        \item \textbf{Purpose}: Normalization in floating-point representation ensures that the number is represented in the most efficient way, maximizing the precision.
        \item \textbf{Process}: It involves adjusting the exponent and fraction so that the fraction begins with a non-zero digit.
    \end{itemize}

    \subsection*{Special Values}

    \begin{itemize}
        \item \textbf{Zero}: Represented by an exponent of all 0s and a fraction of all 0s.
        \item \textbf{Infinity}: Represented by an exponent of all 1s and a fraction of all 0s.
        \item \textbf{NaN (Not a Number)}: Represented by an exponent of all 1s and a non-zero fraction.
    \end{itemize}

    \subsection*{Precision And Rounding}

    \begin{itemize}
        \item \textbf{Issues}: Precision in floating-point representation is limited, which can lead to rounding errors in computations.
        \item \textbf{Rounding Strategies}: Several strategies exist to minimize these errors, such as round-to-nearest or round-towards-zero.
    \end{itemize}

    \subsection*{Basics Of Fractional Binary Numbers}

    \begin{itemize}
        \item \textbf{Definition}: Fractional binary numbers are a way to represent numbers that are not whole numbers (i.e., fractions) in binary form.
        \item \textbf{Representation}: Just like whole numbers are represented in binary using powers of 2 ($2^0$, $2^1$, $2^2$, etc.), fractional binary numbers use negative powers of 2 ($2^{-1}$, $2^{-2}$, $2^{-3}$, etc.).
    \end{itemize}

    \subsection*{Binary Fractional Places}

    \begin{itemize}
        \item \textbf{Right of the Decimal Point}: Each place value to the right of the binary point (equivalent to the decimal point in base 10) represents a negative power of 2.
        \item \textbf{Example}: In the binary fractional number 0.101, the first digit after the binary point is $2^{-1} = (0.5)$, the second is $2^{-2} = (0.25)$, and so on.
    \end{itemize}

    \subsection*{Converting To Decimal}

    \begin{itemize}
        \item \textbf{Process}: To convert a binary fractional number to a decimal, multiply each digit by its corresponding power of 2 and sum the results.
        \item \textbf{Example}: The binary number 0.101 is calculated as $(1 \cdot 2^{-1}) + (0 \cdot 2^{-2}) + (1 \cdot 2^{-3})$, which equals 0.625 in decimal.
    \end{itemize}

    \subsection*{Precision And Limitations}

    \begin{itemize}
        \item \textbf{Finite Representation}: Just like decimal fractions, binary fractions may not always have a finite representation. For example, the decimal fraction 0.1 (one-tenth) does not have 
        a finite binary representation.
        \item \textbf{Precision Loss}: In computer systems, this can lead to precision loss, especially in calculations involving floating-point arithmetic.
    \end{itemize}

    \subsection*{Importance In Computing}

    \begin{itemize}
        \item \textbf{Usage}: Understanding fractional binary numbers is essential in fields like digital signal processing, computer graphics, and scientific computing.
        \item \textbf{Floating-Point Numbers}: This concept is also fundamental to the representation of real numbers in computers, as used in floating-point formats.
    \end{itemize}

    \subsection*{Basics Of Fractional Binary Numbers Summary}

    Fractional binary numbers are key to representing and manipulating non-integer numbers in computer systems. The process of converting between binary and decimal fractions is important for understanding 
    how computers process and store decimal numbers. Awareness of the limitations and precision issues with binary fractions is crucial in various computing applications. \vspace*{1em}

    \subsection*{IEEE Floating-Point Representation}

    \begin{itemize}
        \item \textbf{Overview}: IEEE Floating-Point Representation is a standard for representing and computing floating-point numbers, widely adopted in computer systems for numerical computations.
        \item \textbf{Standard}: The most common standard used is IEEE 754, which defines the format for floating-point numbers and the rules for floating-point arithmetic.
    \end{itemize}
    
    \subsection*{Components Of IEEE Floating-Point Format}
    
    \begin{itemize}
        \item \textbf{Sign Bit}: The first bit is the sign bit, with 0 for positive numbers and 1 for negative numbers.
        \item \textbf{Exponent}: Follows the sign bit, represents the exponent of the number. The exponent is in a 'biased' form.
        \item \textbf{Fraction (or Mantissa)}: Represents the precision of the floating-point number. It's a binary fraction.
    \end{itemize}
    
    \subsection*{IEEE 754 Formats}
    
    \begin{itemize}
        \item \textbf{Single Precision}: 32-bit format with 1 sign bit, 8 exponent bits, and 23 fraction bits.
        \item \textbf{Double Precision}: 64-bit format with 1 sign bit, 11 exponent bits, and 52 fraction bits.
    \end{itemize}
    
    \subsection*{Normalization In Floating-Point Representation}
    
    \begin{itemize}
        \item \textbf{Purpose}: Normalization maximizes the precision of the number and ensures that the floating-point representation is unique.
        \item \textbf{Process}: In normalized form, the fraction field represents a number greater than or equal to 1 and less than 2.
    \end{itemize}
    
    \subsection*{Special Values In IEEE 754}
    
    \begin{itemize}
        \item \textbf{Zero}: Represented by all bits zero in both the exponent and the fraction.
        \item \textbf{Infinity}: Represented by all bits one in the exponent and all bits zero in the fraction.
        \item \textbf{NaN (Not a Number)}: Represented by all bits one in the exponent and a non-zero fraction.
    \end{itemize}
    
    \subsection*{Precision And Rounding Issues}
    
    \begin{itemize}
        \item \textbf{Limited Precision}: The finite number of bits limits the precision of floating-point numbers, which can lead to rounding errors.
        \item \textbf{Rounding Strategies}: Various strategies, like round-to-nearest or round-towards-zero, are used to minimize these errors.
    \end{itemize}
    
    \subsection*{Importance Of IEEE Floating-Point Representation}
    
    \begin{itemize}
        \item \textbf{Significance}: The IEEE 754 standard is critical in ensuring consistency and accuracy in floating-point computations across different computing platforms.
        \item \textbf{Applications}: Used extensively in scientific computing, graphics, and other fields requiring precise numerical computations.
    \end{itemize}
    
    \subsection*{IEEE Floating-Point Representation Summary}
    
    IEEE Floating-Point Representation is essential for accurate and consistent numerical computation in computer systems. The IEEE 754 standard outlines specific formats and rules for floating-point 
    arithmetic, addressing issues of precision and rounding. Understanding this representation is crucial for fields that rely heavily on numerical computations. \vspace*{1em}

    \subsection*{Example Numbers In IEEE Floating-Point Representation}

    Below are some examples of floating point numbers in IEEE floating-point format to demonstrate the application of the standard.

    \begin{highlight}[Example 1 - Representation of a Positive Number]
        \begin{itemize}
            \item \textbf{Decimal Number}: Let's consider the decimal number 6.25.
            \item \textbf{Binary Equivalent}: In binary, 6.25 is represented as $110.01$.
            \item \textbf{Normalized Form}: The normalized form in IEEE format is $1.1001 \times 2^2$.
            \item \textbf{IEEE Representation}: Assuming single precision, the sign bit is 0, the exponent is $2 + 127 = 129$ (which is $10000001$ in binary), and the mantissa is the binary fraction 
            $1001000...$ (23 bits total).
        \end{itemize}
    \end{highlight}

    \begin{highlight}[Example 2 - Representation of a Negative Number]
        \begin{itemize}
            \item \textbf{Decimal Number}: Consider the decimal number -10.75.
            \item \textbf{Binary Equivalent}: In binary, -10.75 is $-1010.11$.
            \item \textbf{Normalized Form}: The normalized form in IEEE format is $-1.01011 \times 2^3$.
            \item \textbf{IEEE Representation}: In single precision, the sign bit is 1, the exponent is $3 + 127 = 130$ (which is $10000010$ in binary), and the mantissa is $0101100...$ (23 bits).
        \end{itemize}
    \end{highlight}

    \begin{highlight}[Example 3 - Special Values]
        \begin{itemize}
            \item \textbf{Positive Infinity}: Represented by a sign bit of 0, an exponent of all 1s, and a fraction of all 0s.
            \item \textbf{NaN (Not a Number)}: Represented by an exponent of all 1s and a non-zero fraction.
        \end{itemize}
    \end{highlight}
    
    \subsection*{Example Numbers Summary}
    
    These examples illustrate how different types of numbers, including special values, are represented in the IEEE floating-point format. Understanding these examples helps in comprehending the practical 
    application of IEEE 754 standard in computer systems for representing various numerical values accurately.

    \subsection*{Rounding In IEEE Floating-Point Representation}

    This subsection discusses the concept of rounding in the context of IEEE floating-point representation, highlighting its significance and methods.
    
    \subsection*{Significance of Rounding}

    \begin{itemize}
        \item \textbf{Purpose}: Rounding is crucial in floating-point arithmetic because it allows us to fit numbers into a finite number of bits.
        \item \textbf{Precision Limitation}: Due to the limited number of bits in the mantissa, not all decimal numbers can be represented exactly, necessitating rounding.
    \end{itemize}

    \subsection*{Rounding Methods}

    \begin{itemize}
        \item \textbf{Round to Nearest (Ties to Even)}: The most commonly used method. It rounds to the nearest value; if the number falls exactly in the middle, it is rounded to the nearest even number.
        \item \textbf{Round Toward Zero}: Rounds the number towards zero, effectively truncating the fractional part.
        \item \textbf{Round Up (Toward Positive Infinity)}: Always rounds numbers up.
        \item \textbf{Round Down (Toward Negative Infinity)}: Always rounds numbers down.
    \end{itemize}

    \subsection*{Implications of Rounding}

    \begin{itemize}
        \item \textbf{Rounding Errors}: Can introduce small errors in computations, which may accumulate in successive calculations.
        \item \textbf{Importance in Algorithms}: Understanding how rounding works is essential in algorithm design, particularly in numerical methods and computer graphics.
    \end{itemize}
    
    \subsection*{Rounding Summary}
    
    Rounding in IEEE floating-point representation is a necessary process due to the finite representation of numbers. Different rounding methods are used based on the context and requirements of the 
    computation. It is essential to be aware of rounding errors and their potential impact on the accuracy of numerical computations in computer systems.

    \subsection*{Floating Point in C}

    This subsection focuses on the representation and handling of floating-point numbers in the C programming language, emphasizing its adherence to the IEEE standard and specific characteristics.
    
    \subsection*{IEEE Standard Compliance}
    
    \begin{itemize}
        \item \textbf{Compatibility}: C language supports IEEE 754 standard for floating-point representation, ensuring portability and consistency across platforms.
        \item \textbf{Data Types}: The primary data types for floating-point numbers in C are \texttt{float}, \texttt{double}, and \texttt{long double}.
    \end{itemize}
    
    \subsection*{Data Types and Precision}
    
    \begin{itemize}
        \item \textbf{\texttt{float}}: Usually represents a single precision floating-point number (32 bits).
        \item \textbf{\texttt{double}}: Represents a double precision floating-point number (64 bits), offering higher precision.
        \item \textbf{\texttt{long double}}: Provides even higher precision than \texttt{double}, its size and precision can vary depending on the compiler and platform.
    \end{itemize}
    
    \subsection*{Arithmetic Operations}
    
    \begin{itemize}
        \item \textbf{Operations}: Includes addition, subtraction, multiplication, division, and remainder.
        \item \textbf{Accuracy}: Precision in calculations is limited by the data type used, with \texttt{double} and \texttt{long double} offering greater accuracy.
    \end{itemize}
    
    \subsection*{Handling Special Values}
    
    \begin{itemize}
        \item \textbf{Infinity and NaN}: C can represent special values like infinity and NaN (Not a Number) in accordance with IEEE 754.
        \item \textbf{Functions}: Functions like \texttt{isinf()} and \texttt{isnan()} are used to check for these special values.
    \end{itemize}
    
    \subsection*{Limitations and Considerations}
    
    \begin{itemize}
        \item \textbf{Precision Limits}: The finite representation of floating-point numbers in C can lead to rounding errors and limitations in numerical accuracy.
        \item \textbf{Best Practices}: Careful selection of data types and awareness of precision limitations are crucial in numerical computing with C.
    \end{itemize}
    
    \subsection*{Floating Point in C Summary}
    
    The C programming language provides comprehensive support for floating-point arithmetic in line with the IEEE 754 standard. Understanding the characteristics and limitations of different 
    floating-point data types (\texttt{float}, \texttt{double}, and \texttt{long double}) is essential for effective numerical programming in C. Special values like infinity and NaN are also supported, 
    with functions available for their detection and handling.
\end{notes}

The next chapter that we are covering this week is \textbf{Chapter 3: Machine-Level Representation Of Programs}. The first section that we are covering from this chapter is \textbf{Section 3.1: A Historical Perspective}.

\begin{notes}{Section 3.1: A Historical Perspective}
    \subsection*{A Historical Perspective}

    This section provides a historical overview of the machine-level representation of programs, tracing the evolution of programming from early machine languages to modern high-level languages.
    
    \subsection*{Early Machine Languages}
    
    \begin{itemize}
        \item \textbf{First Computers}: Early computers were programmed in machine language, a low-level programming language understood directly by the computer's hardware.
        \item \textbf{Binary Coding}: Programs were written in binary code, which was tedious and error-prone, requiring programmers to have deep knowledge of the hardware.
    \end{itemize}
    
    \subsection*{Assembly Languages and Assemblers}
    
    \begin{itemize}
        \item \textbf{Introduction of Assembly Language}: To simplify machine-level programming, assembly languages were developed. These languages use mnemonic codes and symbols to represent machine-level 
        instructions.
        \item \textbf{Assemblers}: Programs called assemblers were created to convert assembly language code into machine language automatically.
    \end{itemize}
    
    \subsection*{High-Level Languages}
    
    \begin{itemize}
        \item \textbf{Development}: With the increasing complexity of software, high-level languages like Fortran, C, and Java were developed, allowing programmers to write code in a more human-readable form.
        \item \textbf{Compilers}: Compilers translate high-level language code into machine language, bridging the gap between human logic and machine instructions.
    \end{itemize}
    
    \subsection*{Modern Programming}
    
    \begin{itemize}
        \item \textbf{Advancements}: Modern programming involves a mix of high-level languages for application development and low-level languages for system-level programming.
        \item \textbf{Integrated Development Environments (IDEs)}: These environments provide tools that aid in writing, testing, and debugging code, further simplifying the programming process.
    \end{itemize}
    
    \subsection*{A Historical Perspective Summary}
    
    The evolution from early machine languages to high-level programming languages represents a significant advancement in the field of computing. This progression has made programming more accessible 
    and efficient, enabling the development of complex software systems. It highlights the importance of understanding both high-level and low-level programming concepts in computer science.
\end{notes}

The next section that we are covering from this chapter is \textbf{Section 3.2: Program Encodings}.

\begin{notes}{Section 3.2: Program Encodings}
    \subsection*{Machine-Level Code}

    This topic delves into the specifics of machine-level code, discussing its nature, characteristics, and importance in the context of program encodings.
    
    \subsection*{Nature of Machine-Level Code}
    
    \begin{itemize}
        \item \textbf{Direct Hardware Interaction}: Machine-level code interacts directly with the computer's hardware, providing control over every operation executed by the processor.
        \item \textbf{Binary Format}: It is expressed in binary, making it the lowest level of code that is directly executed by the computer's CPU.
    \end{itemize}
    
    \subsection*{Characteristics of Machine-Level Code}
    
    \begin{itemize}
        \item \textbf{Efficiency}: Machine-level code is highly efficient as it is tailored to the specific architecture of the processor.
        \item \textbf{Complexity}: Due to its low-level nature, it is more complex and harder to read compared to high-level programming languages.
    \end{itemize}
    
    \subsection*{Role in Program Execution}
    
    \begin{itemize}
        \item \textbf{Execution by Processor}: The CPU executes machine-level code directly, translating the binary instructions into actions.
        \item \textbf{Foundation for Higher-Level Languages}: All high-level language programs are eventually converted to machine-level code for execution.
    \end{itemize}
    
    \subsection*{Importance in Computer Systems}
    
    \begin{itemize}
        \item \textbf{Performance Optimization}: Understanding machine-level code is crucial for optimizing the performance of software, especially in system-level programming.
        \item \textbf{Hardware-Specific Programming}: It is essential for programming that requires direct interaction with the hardware, such as device drivers and embedded systems.
    \end{itemize}
    
    \subsection*{Machine-Level Code Summary}
    
    Machine-level code represents the most fundamental form of program encoding, directly executable by the CPU. Its efficiency and direct hardware interaction make it indispensable for 
    performance-critical and hardware-specific applications. However, its complexity and low-level nature limit its use to specialized areas of programming.

    \subsection*{Code Examples}

    This topic focuses on providing practical examples of machine-level code, illustrating how various programming constructs are represented at this fundamental level.
    
    \subsection*{Basic Instructions}
    
    \begin{itemize}
        \item \textbf{Arithmetic Operations}: Examples include addition, subtraction, multiplication, and division, showing how these basic operations are encoded in machine-level language.
        \item \textbf{Data Movement}: Illustrates instructions for moving data between the CPU and memory locations, and within CPU registers.
    \end{itemize}
    
    \subsection*{Control Structures}
    
    \begin{itemize}
        \item \textbf{Conditional Execution}: Demonstrates how conditional statements like if-else are implemented in machine code.
        \item \textbf{Loops}: Shows the encoding of loop constructs like for and while, detailing how iteration is managed at the machine level.
    \end{itemize}
    
    \subsection*{Function Calls and Returns}
    
    \begin{itemize}
        \item \textbf{Calling Mechanism}: Explores how functions are called, including passing arguments and the setup of the call stack.
        \item \textbf{Return Process}: Describes how control is returned to the calling function, including stack unwinding and return value handling.
    \end{itemize}
    
    \subsection*{Complex Constructs}
    
    \begin{itemize}
        \item \textbf{Arrays and Structures}: Provides examples of how more complex data structures like arrays and structs are handled and accessed in machine code.
        \item \textbf{Pointer Operations}: Examines the representation and manipulation of pointers at the machine level, crucial for dynamic memory management.
    \end{itemize}
    
    \subsection*{Code Examples Summary}
    
    These code examples serve to bridge the gap between high-level programming concepts and their low-level machine-level representations. Understanding these examples is key to comprehending the 
    fundamentals of how high-level constructs are translated into executable machine code, providing insight into the workings of compilers and the efficiency of different coding practices.
\end{notes}