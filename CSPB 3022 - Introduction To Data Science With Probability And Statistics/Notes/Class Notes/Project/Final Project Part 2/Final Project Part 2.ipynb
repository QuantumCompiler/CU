{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01366df",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Final Project Part 2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889297b-c459-4d2e-bc22-bdd4dc0d7bc0",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0f9b2de18190d9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Project - Part 2: Predicting Housing Prices in Cook County\n",
    "\n",
    "## Due on Gradescope\n",
    "\n",
    "## NO LATE SUBMISSIONS will be accepted - you must plan accordingly.\n",
    "\n",
    "## Collaboration Policy\n",
    "\n",
    "Please see the **Course Syllabus for the Collaboration Policy**.\n",
    "\n",
    "On the other hand, the following are some **examples of things which would NOT usually be\n",
    "considered to be cheating**:\n",
    " - Working on a HW problem on your own first and then discussing with a classmate a particular part in the problem solution where you are stuck.  After clarifying any questions you should then continue to write your solution independently.\n",
    " - Asking someone (or searching online) how a particular construct in the language works.\n",
    " - Asking someone (or searching online) how to formulate a particular construct in the language.\n",
    " - Asking someone for help in finding an error in your program.  \n",
    " - Asking someone why a particular construct does not work as you expected in a given program.\n",
    "   \n",
    "\n",
    "To test whether you are truly doing your own work and retaining what you've learned you should be able to easily reproduce from scratch and explain a HW solution that was your own when asked in office hours by an Instructor or on a quiz/exam.   \n",
    "\n",
    "\n",
    "If you have difficulty in formulating the general solution to a problem on your own, or\n",
    "you have difficulty in translating that general solution into a program, it is advisable to see\n",
    "your instructor.\n",
    "\n",
    "We are here to help!  Visit OH Hours and/or post questions on Piazza!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe8bcb-ec8c-44fa-ae82-2d3fd3e8f4f9",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In Part 1 of this project, you performed some basic exploratory data analysis (EDA), laying out the thought process that leads to certain modeling decisions. Then, you added a few new features to the dataset, cleaning the data as well in the process.\n",
    "\n",
    "In Part 2 of the project, you will specify and fit a linear model to a few features of the housing data to predict housing prices. Next, we will analyze the error of the model and brainstorm ways to improve the model's performance. Finally, we'll delve deeper into the implications of predictive modeling within the Cook County Assessor's Office (CCAO) case study, especially because statistical modeling is how the CCAO valuates properties. Given the history of racial discrimination in housing policy and property taxation in Cook County, consider the impacts of your modeling results as you work through this assignment - and think about what fairness might mean to property owners in Cook County.\n",
    "\n",
    "After this part of the project, you should be comfortable with:\n",
    "- Implementing a data processing pipeline using `pandas`\n",
    "- Using `scikit-learn` to build and fit linear models\n",
    "\n",
    "## Score Breakdown\n",
    "\n",
    "Question | Manual | Points\n",
    "----|----|----\n",
    "1abd | Yes | 8\n",
    "1c | No | 1\n",
    "2a | Yes | 3\n",
    "2b | No | 1\n",
    "3 | No | 8\n",
    "4 | No | 11\n",
    "5 | Yes | 14\n",
    "6 | Yes | 4\n",
    "Total | | 50 | 32\n",
    "Extra Credit| Yes| Up to +10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c5cda-c5a0-4a4d-8c08-c61b323e825a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62cfd21463535cac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model as lm\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from ds100_utils import run_linear_regression_test\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2854e2e6-252b-4f1f-b488-dbad2738689c",
   "metadata": {},
   "source": [
    "Let's load the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a24eae-51fb-476a-a30c-d6a2dc70c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('cook_county_data.zip') as item:\n",
    "    item.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d455e3-8e46-4fc8-b1f1-3a110ee94bcc",
   "metadata": {},
   "source": [
    "This dataset is split into a training/validation set and a testing set. Importantly, the test set does not contain values for our target variable, `Sale Price`. In this project, you will train a model on the training/validation set then use this model to predict the `Sale Price`s of the test set. In the cell below, we load the training/validation set into the `DataFrame` `training_val_data` and the test set into the `DataFrame` `test_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866f09a-e957-4f34-a4a5-9123328768d2",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8fea30adc9d489b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_val_data = pd.read_csv(\"cook_county_train_val.csv\", index_col='Unnamed: 0')\n",
    "test_data = pd.read_csv(\"cook_county_contest_test.csv\", index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc7691-c277-49e6-85d8-58095387be94",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d6d509b6e854e10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "As a good sanity check, we should at least verify that the data shape matches the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd037cd-a127-4715-9692-83ed4df968ba",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c841a2de55691502",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 204792 observations and 62 features in training data\n",
    "assert training_val_data.shape == (204792, 62)\n",
    "# 55311 observations and 61 features in test data\n",
    "assert test_data.shape == (55311, 61)\n",
    "# Sale Price is provided in the training/validation data\n",
    "assert 'Sale Price' in training_val_data.columns.values\n",
    "# Sale Price is hidden in the test data\n",
    "assert 'Sale Price' not in test_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df15c1-ba1b-4cb2-8f12-ecfe8a5af841",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce9acc2f62c96e59",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's remind ourselves of the data available to us in the Cook County dataset. Remember, a more detailed description of each variable is included in `codebook.txt`, which is in the same directory as this notebook). **If you did not attempt Project Part 1,** you should take some time to familiarize yourself with the codebook before moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cecf768-8350-4b23-8d82-ff64d0aff66f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e60a7a0cda5eecf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_val_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde0a69-9c7d-497e-acfc-aa0d1e2d7e89",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 1: Human Context and Ethics\n",
    "\n",
    "In this part of the project, we will explore the human context of our housing dataset.\n",
    "\n",
    "**You should read the [Project_CaseStudy.pdf](https://canvas.colorado.edu/courses/95692/files/71805013?module_item_id=5035681) on Canvas explaining the context and history surrounding this dataset before attempting this section.**\n",
    "\n",
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 1a\n",
    "\"How much is a house worth?\" Who might be interested in an answer to this question? **Please list at least three different parties (people or organizations) and state whether each one has an interest in seeing the housing price to be high or low.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d0e95",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887156f2-4ffd-444d-939f-19f744de72e7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1b\n",
    "\n",
    "Which of the following scenarios strike you as unfair and why? You can choose more than one. There is no single right answer, but you must explain your reasoning. Would you consider some of these scenarios more (or less) fair than others? Why?\n",
    "\n",
    "A. A homeowner whose home is assessed at a higher price than it would sell for.  \n",
    "B. A homeowner whose home is assessed at a lower price than it would sell for.  \n",
    "C. An assessment process that systematically overvalues inexpensive properties and undervalues expensive properties.  \n",
    "D. An assessment process that systematically undervalues inexpensive properties and overvalues expensive properties.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a33cd0",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27732048-de45-46bf-b5e7-a6733cd323c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1c\n",
    "\n",
    "Consider a model that is fit to $n = 50$ training observations. We denote the response as $y$ (Log Sale Price), the prediction as $\\hat{y}$, and the corresponding residual to be $y - \\hat{y}$. Which residual plot corresponds to a model that might make property assessments that result in regressive taxation? (Refer to the [Project_CaseStudy.pdf](https://canvas.colorado.edu/courses/95692/files/71805013?module_item_id=5035681) for a reminder of the definition of regressive taxation).  Assume that all three plots use the same vertical scale and that the horizontal line marks $y - \\hat{y} = 0$. Assign `q1c` to the string letter corresponding to your plot choice.\n",
    "\n",
    "**Hint:** When a model overvalues a property (predicts a `Sale Price` greater than the actual `Sale Price`), what are the relative sizes of $y$ and $\\hat{y}$? What about when a model undervalues a property?\n",
    "\n",
    "<img src='res_plots.png' width=\"900px\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913057c-7bd8-4c28-9b4e-c41b2b47a834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1c = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2905b206",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8c5ac-4463-4b3c-87cc-0afafecb1353",
   "metadata": {},
   "source": [
    "## The CCAO Dataset\n",
    "\n",
    "You'll work with the dataset from the Cook County Assessor's Office (CCAO) in Illinois. This government institution determines property taxes across most of Chicago's metropolitan areas and nearby suburbs. In the United States, all property owners must pay property taxes, which are then used to fund public services, including education, road maintenance, and sanitation. These property tax assessments are based on property values estimated using statistical models considering multiple factors, such as real estate value and construction cost.\n",
    "\n",
    "This system, however, is not without flaws. In late 2017, a lawsuit was filed against the office of Cook County Assessor Joseph Berrios for producing \"[racially discriminatory assessments and taxes](https://www.chicagotribune.com/politics/ct-cook-county-board-assessor-berrios-met-20170718-story.html).\" The lawsuit included claims that the assessor's office undervalued high-priced homes and overvalued low-priced homes, creating a visible divide along racial lines: Wealthy homeowners, who were typically white, [paid less in property taxes](https://fix8media-chicago.squarespace.com/bpnc-v-berrios-resource-page), whereas [working-class, non-white homeowners paid more](https://www.chicagotribune.com/news/breaking/ct-cook-county-assessor-berrios-sued-met-20171214-story.html).\n",
    "\n",
    "The Chicago Tribune's four-part series, \"[The Tax Divide](https://www.chicagotribune.com/investigations/ct-tax-divide-investigation-20180425-storygallery.html)\", delves into how this was uncovered: After \"compiling and analyzing more than 100 million property tax records from the years 2003 through 2015, along with thousands of pages of documents, then vetting the findings with top experts in the field,\" they discovered that \"residential assessments had been so far off the mark for so many years.\" You can read more about their investigation [here](https://apps.chicagotribune.com/news/watchdog/cook-county-property-tax-divide/assessments.html).\n",
    "\n",
    "**You should read the [Project_CaseStudy.pdf](https://canvas.colorado.edu/courses/95692/files/71805013?module_item_id=5035681) explaining the history about this dataset before answering the following question.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418e46c1-ef8c-4d10-be2d-fc5f273cc00a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1d\n",
    "\n",
    "What were the central problems with the earlier property tax system in Cook County as reported by the Chicago Tribune ? And what were the primary causes of these problems? (Note: in addition to reading the paragraph above you will need to **read the [Project_CaseStudy.pdf](https://canvas.colorado.edu/courses/95692/files/71805013?module_item_id=5035681) explaining the context and history of this dataset  before answering this question).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d248c684",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c3209a-f05f-49f6-9acc-942340dbaf34",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 2a:  More EDA\n",
    "\n",
    "<br>\n",
    "\n",
    "In good news you have already done a lot of EDA with this dataset in Project 1. \n",
    "\n",
    "Before fitting any model, we should check for any missing data and/or unusual outliers.\n",
    "\n",
    "Since we're trying to predict `Sale Price`, we'll start with that field.\n",
    "\n",
    "Examine the `Sale Price` column in the `training_val_data` DataFrame and answer the following questions:\n",
    "\n",
    "\n",
    " - 2ai).  Does the `Sale Price` data have any missing, N/A, negative or 0 values for the data?  If so, propose a way to handle this.\n",
    "\n",
    " - 2aii).  Does the `Sale Price` data have any unusually large outlier values?  If so, propose a cutoff to use for throwing out large outliers, and justify your reasoning).  \n",
    "\n",
    " - 2aiii).  Does the `Sale Price` data have any unusually small outlier values?  If so, propose a cutoff to use for throwing out small outliers, and justify your reasoning.  \n",
    " \n",
    " \n",
    "Below are three cells.  The first is a Markdown cell for you to write up your responses to all 3 parts above.\n",
    "The second two are code cells that are available for you to write code to explore the outliers and/or visualize the Sale Price data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f12ca0a-a4b6-472e-8ce5-26bc89245825",
   "metadata": {},
   "source": [
    "### Question 2abc answer cell:**   *Put your answers in this cell...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e6bba-c52e-45c5-adec-d3ac2b615450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "# your code exploring Sale Price above this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d68918-1f04-43c4-a33b-64ddeb90a549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "# optional extra cell for exploring code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f4195f-0695-4c6d-a932-4bbd5f1f4710",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Pure Market Filter**\n",
    "\n",
    "As you (hopefully) noticed, there are quite a few small values for the Sale Price of a home that don't make sense.  This can happen when someone sells a house to a relative for $\\$1$ or some other price that is not reflective of the true market value.  There are also several extremely large outliers (houses that sold for more than $10 million) that don't accurately capture the true market value of a home.\n",
    "\n",
    "It turns out, there's actually an indicator feature already available in the dataset to help filter out any sale transactions that aren't considered \"Pure Market Transactions\"  (for example, when someone sells a house to a relative for $\\$1$, we don't consider that a transaction driven by the true market value of the house.\n",
    "\n",
    "We'll use this indicator feature in the next section to remove non-market transactions before fitting our models.\n",
    "\n",
    "\n",
    "### Question 2b\n",
    "\n",
    "What are the max and min Sale Price values for the subset of data in the training_val dataset with the indicator `Pure Market Filter` = 1?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb8506f-c082-4864-9046-e9b5c1bc67ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_Sale_Price_filtered = ...\n",
    "\n",
    "min_Sale_Price_filtered = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad77b1c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af9846-92fd-45c2-99c5-55ed0f18e62a",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 3: Fitting a Simple Linear Regression Model\n",
    "\n",
    "In Part 1 of the project, you plotted the log-transformed Sale Price vs the log-transformed total area covered by the building (in square feet)  and saw there was a positive linear association.  Let's start the modeling process by fitting a simple linear regression model using this predictor.  \n",
    "\n",
    "Our first model will take the form:\n",
    "\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Log Building Square Feet})\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 3a:  Training/Validation Split\n",
    "\n",
    "\n",
    "The data has already been split into a training_val set and a test set.  Let's further split the training_val set into a training set and a validation set. We will use the training set to fit our model's parameters and the validation set to evaluate how well our model will perform on unseen data drawn from the same distribution. If we used all the data to fit our model, we would not have a way to estimate model performance on **unseen data** such as the test set in `cook_county_contest_test.csv`.\n",
    "\n",
    "In the cell below, complete the function `train_val_split` that splits an input DataFrame `data` into two smaller `DataFrame`s named `train` and `validation`. Let `train` contain 80% of the data, and let `validation` contain the remaining 20%.  You should not be importing any additional libraries for this question. Your answer should use the variable `shuffled_indices` defined for you. Take a look at the `np.permutation` [documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.permutation.html). You should only be using `NumPy` functions to generate randomness!\n",
    "\n",
    "**Hint:** While there are multiple solutions, one way is to create two `NumPy` arrays named `train_indices` and `validation_indices` (or any variable names of your choice) that contain a *random* 80% and 20% of the indices, respectively. Then, use these arrays to index into `data` to create your final `train` and `validation` `DataFrame`s. To ensure that your code matches our solution, use the first 80% as the training set and the last 20% as the validation set. Remember, the values you use to partition `data` must be integers!\n",
    "\n",
    "*The provided tests use the same random seed to check that you not only answered correctly but ended up with the same train/validation split as our reference implementation. Later testing is easier this way.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2be8bd-8919-46f9-8139-eee026c61709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_val_split(data):\n",
    "    \"\"\" \n",
    "    Takes in a DataFrame `data` and randomly splits it into two smaller DataFrames \n",
    "    named `train` and `validation` with 80% and 20% of the data, respectively. \n",
    "    \"\"\"\n",
    "    data_len = data.shape[0]\n",
    "    shuffled_indices = np.random.permutation(data_len)\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    train = ...\n",
    "    validation = ...\n",
    "   \n",
    "    \n",
    "    return train, validation\n",
    "\n",
    " \n",
    "#This makes the train-test split in this section reproducible across different runs \n",
    "# of the notebook. DO NOT CHANGE THIS RANDOM SEED.\n",
    "np.random.seed(1337)\n",
    "\n",
    "train, valid = train_val_split(training_val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ec108",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc99c7-cda3-4a06-a9f1-8b0566d1616a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--- \n",
    "## Modeling Step 1:  Feature Transformation\n",
    "\n",
    "<br>\n",
    "\n",
    "## Create a pipeline to process the data\n",
    "\n",
    "It is time to prepare the training and validation data for the model we proposed above. \n",
    "\n",
    "In Project Part 1, you wrote a few functions that added features to the dataset. Instead of calling them manually one by one each time, it is best practice to encapsulate all of this feature engineering into one \"pipeline\" function. Defining and using a pipeline reduces all the feature engineering to just one function call and ensures that the same transformations are applied to all data.  \n",
    "\n",
    "\n",
    "\n",
    "For an example of how to work with pipelines, we have processed model 1 for you using `process_data_m1` in the below cell. \n",
    "\n",
    "\n",
    "\n",
    "In particular the cell below completes the following steps:\n",
    "\n",
    "  1. Creates a function `process_data_m1` to perform the following feature engineering:  \n",
    "     - Removes rows in the dataset that have the indicator `Pure Market Filter`= 0 (these are outliers that are not representative of sales driven by the true housing market).\n",
    "     - Applies log transformations to the `Sale Price` and the `Building Square Feet` columns to create two new columns, `Log Sale Price` and `Log Building Square Feet`.\n",
    "     - Selects the columns and `Log Sale Price` , `Log Building Square Feet`\n",
    "     - Outputs the transformed DataFrame\n",
    " \n",
    " 2. Run `process_data_m1` separately on the training data and then the validation data.  Then output the design matrix $\\mathbb{X}$ and the observed vector $\\mathbb{Y}$ for both the training data and the validation data (save them in the variable names `X_train_m1`, `Y_train_m1`, `X_valid_m1`, `Y_valid_m1`). Note that $\\mathbb{Y}$ refers to the transformed `Log Sale Price`, not the original `Sale Price`. **Your design matrix should be a `pandas` DataFrame and your observed vector should be a `pandas` Series.**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc41b8-08cc-43b6-90dd-2af7ee51c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just Run This Cell.   Make sure you understand what each part is doing - you will use this format when you expand the model\n",
    "\n",
    "\n",
    "def process_data_m1(data):\n",
    "    \"\"\" \n",
    "    Takes in a DataFrame `data` and performs data transformations and processing to use for Model 1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove outliers\n",
    "    data = data[data[\"Pure Market Filter\"]==1]\n",
    "    \n",
    "    # Create Log Sale Price column\n",
    "    data[\"Log Sale Price\"] = np.log(data[\"Sale Price\"])\n",
    "    \n",
    "    # Create Log Building Square Feet column\n",
    "    data[\"Log Building Square Feet\"] = np.log(data[\"Building Square Feet\"])\n",
    "    \n",
    "    # Select columns for the model\n",
    "    data = data[['Log Building Square Feet', 'Log Sale Price']]\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Process both the training and validation data \n",
    "processed_train_m1 = process_data_m1(train)\n",
    "\n",
    "processed_val_m1 = process_data_m1(valid)\n",
    "\n",
    "\n",
    "# Create X (dataframe) and Y (series) to input into model\n",
    "X_train_m1 = processed_train_m1.drop(columns = \"Log Sale Price\")\n",
    "Y_train_m1 = processed_train_m1[\"Log Sale Price\"]\n",
    "\n",
    "X_valid_m1 = processed_val_m1.drop(columns = \"Log Sale Price\")\n",
    "Y_valid_m1 = processed_val_m1[\"Log Sale Price\"]\n",
    "\n",
    "# Take a look at the result\n",
    "display(X_train_m1.head())\n",
    "display(Y_train_m1.head())\n",
    "\n",
    "display(X_valid_m1.head())\n",
    "display(Y_valid_m1.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0fce59-2917-4e15-b9f0-52c798505aec",
   "metadata": {},
   "source": [
    "## Modeling Step 2:  Create a linear model\n",
    "\n",
    "Next we'll use `sci-kit learn` to train the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2657bb-6755-4efc-a62d-d57cd524bae2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3b\n",
    "\n",
    "\n",
    "We first initialize a [`sklearn.linear_model.LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) object for our model. \n",
    "\n",
    "We set the `fit_intercept = True` to ensure that the linear model has a non-zero intercept.\n",
    "\n",
    "\n",
    "Fill in the rest of the code below to fit the model using the training set and then output predictions for both the training and validation set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b058fed-39c4-4320-a548-daa2bbe76576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linear_model_m1 = lm.LinearRegression(fit_intercept=True)\n",
    "\n",
    "# Fit the model using the processed training data\n",
    "...\n",
    "\n",
    "# Compute the predicted y values from linear model 1 (in units log sale price) using the training data and \n",
    "# again using the validation data:\n",
    "\n",
    "\n",
    "Y_predict_train_m1 = ...\n",
    "\n",
    "Y_predict_valid_m1 = ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd0288",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb1cc7-d7cb-4e5d-87de-caba4317d54f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "## Modeling Step 3:  Model Evaluation Using RMSE\n",
    "\n",
    "\n",
    "We'll compare the performance of our models using the Root Mean Squared Error (RMSE) function.\n",
    "\n",
    "$$RMSE = \\sqrt{\\dfrac{\\sum_{\\text{houses in the set}}(\\text{actual price for house} - \\text{predicted price for house})^2}{\\text{number of houses}}}$$\n",
    "\n",
    "\n",
    "### QUESTION 3c:\n",
    "\n",
    "Complete the code below for the funtion RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a37bb0-c38b-4602-a300-d04beaf4e6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmse(predicted, actual):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from actual and predicted values\n",
    "    Input:\n",
    "      predicted (1D array): vector of predicted/fitted values\n",
    "      actual (1D array): vector of actual values\n",
    "    Output:\n",
    "      a float, the root-mean square error\n",
    "    \"\"\"\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff7b73",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307071be-d358-4881-8954-2ee41a390c8c",
   "metadata": {},
   "source": [
    "### Keeping track of all the models.\n",
    "\n",
    "In this notebook (and in life) we will want to keep track of all our models. \n",
    "For this part of the project you will be creating 3 different versions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f634cf-70bf-4131-84af-f4a8a255dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell to create arrays to store the RMSE information from the models\n",
    "\n",
    "model_names=[\"M1: log(bsqft)\", \"M2\", \"M3\"]\n",
    "\n",
    "# Create arrays where we can keep track of training and validation RMSE for each model\n",
    "\n",
    "training_error_log = np.zeros(4)\n",
    "validation_error_log = np.zeros(4)\n",
    "\n",
    "training_error = np.zeros(4)\n",
    "validation_error = np.zeros(4)\n",
    "\n",
    "# Array to track cross validation errors average RMSE errors  \n",
    "\n",
    "cv_error = np.zeros(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d32039d-9ee0-4d35-b821-58f7e9db4465",
   "metadata": {},
   "source": [
    "## QUESTION 3d:\n",
    "\n",
    "\n",
    "\n",
    "In the cell below use your `rmse` function to calculate the training error and validation error for model 1.\n",
    "\n",
    "Assign the RMSE of the predicted log sale prices and the actual log sale prices to the following variables: \n",
    "\n",
    " `training_error_log[0]`  and    `validation_error_log[0]`\n",
    "\n",
    "\n",
    "Since the target variable we are working with is log-transformed, it can also be beneficial to transform it back to its original form so we will have more context on how our model is performing when compared to actual housing prices.  In other words we want the RMSE **with regard to `Sale Price`**. Remember to exponentiate your predictions and response vectors before computing the RMSE using the `rmse` function and assign it to the following:\n",
    "\n",
    "`training_error[0]` and    `validation_error[0]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8378d1-890d-4ed4-afb6-9ce74c6935e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training and validation RMSE for the model (in units log sale price)\n",
    "\n",
    "training_error_log[0] = ...\n",
    "validation_error_log[0]= ...\n",
    "\n",
    "\n",
    "# Training and validation RMSE for the model (in its original dollar values before the log transform)\n",
    "\n",
    "training_error[0] = ...\n",
    "validation_error[0] = ...\n",
    "\n",
    "\n",
    "print(\"1st Model\\nTraining RMSE (log): {}\\nValidation RMSE (log): {}\\n\".format(training_error_log[0], validation_error_log[0]))\n",
    "print(\"1st Model \\nTraining RMSE: {}\\nValidation RMSE: {}\\n\".format(training_error[0], validation_error[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bcd79c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f69e88-4dd5-4e43-be31-0293af2a3eb6",
   "metadata": {},
   "source": [
    "## Modeling Step 4: Cross Validation\n",
    "\n",
    "To check that the validation RMSE is representative of the dataset we'll also perform a 5-fold cross validation on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e346fdb-6809-485d-b17c-44fdaafcbd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell.  It uses 5-fold cross validation to check that our validation errors weren't a fluke.\n",
    "# Make sure you understand what this code is doing, you will need it again when you update the model.\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "def cross_validate_rmse(model, X, y):\n",
    "    model = clone(model)\n",
    "    five_fold = KFold(n_splits=5) \n",
    "    de_logged_rmse_values = []\n",
    "    for tr_ind, va_ind in five_fold.split(X):\n",
    "        model.fit(X.iloc[tr_ind,:], y.iloc[tr_ind])\n",
    "        de_logged_rmse_values.append(rmse(np.exp(y.iloc[va_ind]), np.exp(model.predict(X.iloc[va_ind,:]))))\n",
    "    return np.mean(de_logged_rmse_values)\n",
    "\n",
    "\n",
    "# Create a new model to fit on the whole training_val dataset\n",
    "linear_model_m1_cv = lm.LinearRegression(fit_intercept=True)\n",
    "\n",
    "\n",
    "# Process the entire training_val dataset using the pipeline\n",
    "processed_full_m1 = process_data_m1(training_val_data)\n",
    "\n",
    "\n",
    "# Split into X and Y:\n",
    "X_full_m1 = processed_full_m1.drop(columns = \"Log Sale Price\")\n",
    "Y_full_m1 = processed_full_m1[\"Log Sale Price\"]\n",
    "\n",
    "# DO NOT CHANGE THIS LINE - it ensures reproducibility \n",
    "np.random.seed(1330)\n",
    "\n",
    "# Run Cross Validation and Output RMSE (in units of Sale Price):\n",
    "cv_error[0] = cross_validate_rmse(linear_model_m1_cv, X_full_m1, Y_full_m1)\n",
    "print(\"1st Model Cross Validation RMSE: {}\".format(cv_error[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bd968-c08f-4047-8862-e63e844ac4d1",
   "metadata": {},
   "source": [
    "## Modeling Step 5: Visualizations\n",
    "\n",
    "## Visualizing RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43db7c3-9f02-4fc8-bb7b-dcb3ea49e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell.  It creates a visualization of the RMSE for Model 1\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure([\n",
    "go.Bar(x = model_names, y = training_error, name=\"Training RMSE\"),\n",
    "go.Bar(x = model_names, y = validation_error, name=\"Validation RMSE\"),\n",
    "go.Bar(x = model_names, y = cv_error, name=\"Cross Val RMSE\")\n",
    "])\n",
    "\n",
    "fig.update_yaxes(range=[180000,260000], title=\"RMSE\")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f1232-7341-46da-b417-830801fcb760",
   "metadata": {},
   "source": [
    "Notice that our RMSE is pretty high given that it's in the units of dollars and measures our error when predicting sale prices of a house.  We will want to improve this model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e71d64-0e3a-466f-b19e-52bb95b185f9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "--- \n",
    "\n",
    "## Visualizing Residual Plots\n",
    "\n",
    "Another way of understanding a model's performance (and appropriateness) is through a plot of the residuals versus the observations.  We will use the validation data to create these plots.\n",
    "\n",
    "In the cells below, use [`plt.scatter`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) to plot\n",
    "2 side-by-side residual plots:\n",
    "\n",
    " - The first plot should be of the residuals from predicting `Log Sale Price` using the model versus  the **predicted** `Log Sale Price` for the **validation data**. \n",
    " - The second plot should be the residuals from predicting `Log Sale Price` using the model versus the **actual** `Log Sale Price` for the **validation data**. \n",
    "\n",
    "We will keep the residuals in terms of units of log to make it easier to spot trends.\n",
    "\n",
    "With such a large dataset, it is difficult to avoid overplotting entirely. We set the dot size and opacity in the scatter plot to reduce the impact of overplotting as much as possible.\n",
    "\n",
    "## QUESTION 3e:  Complete the code below to plot the residual plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eae2597-7069-4557-a94d-b5ed7ce2501a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "\n",
    "\n",
    "x_plt1 = ...\n",
    "y_plt1 = ...\n",
    "\n",
    "x_plt2 = ...\n",
    "y_plt2 = ...\n",
    "\n",
    "\n",
    "\n",
    "ax[0].scatter(x_plt1, y_plt1, alpha=.25)\n",
    "ax[0].axhline(0, c='black', linewidth=1)\n",
    "ax[0].set_xlabel(r'Predicted Log(Sale Price)')\n",
    "ax[0].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[0].set_title(\"Model 1 Val Data: Residuals vs. Predicted Log(Sale Price)\")\n",
    "\n",
    "ax[1].scatter(x_plt2, y_plt2, alpha=.25)\n",
    "ax[1].axhline(0, c='black', linewidth=1)\n",
    "ax[1].set_xlabel(r'Log(Sale Price)')\n",
    "ax[1].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[1].set_title(\"Model 1 Val Data: Residuals vs. Log(Sale Price)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c57d6e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49278b94-33fb-4ee9-a318-2802bdd8609b",
   "metadata": {},
   "source": [
    "**NOTE** Notice in the first plot it appears that the lower part of the plot is cutoff along an angled line - this is due to us filtering the data by only considering \"Pure Market Filter\" = 1, it is not a \"pattern\" in the residuals that we should try to address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5253a3c9-fe7e-4fb7-a277-b2d8124f5871",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "### Question 3f\n",
    "\n",
    "Based on the structure you see in your residual plots, does this model seem like it will correspond to _regressive_, _fair_, or _progressive_ taxation?\n",
    "\n",
    "Assign the string \"regressive\", \"fair\" or \"progressive\" to `q3f` in the cell below accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5a607-a56a-4f37-90ac-addd2b91ab40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q3f = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f979a7d4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c96095-05c5-4e19-b29f-031df3d89731",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 4:  Adding a New Feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64e3895-34e7-47be-9f4b-3cb088d709c9",
   "metadata": {},
   "source": [
    "While our simple model explains some of the variability in price, there is certainly still a lot of room for improvement to be made -- one reason is we have been only utilizing 1 feature (out of a total of 60+) so far! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ef259-d8d1-4199-94ab-a11bf779afaf",
   "metadata": {},
   "source": [
    "### Choosing Candidate Predictors to Add to Model\n",
    "\n",
    "\n",
    "\n",
    "To see if additional variables might be helpful, we can plot the residuals from the fitted model against a variable that is not in the model. If we see patterns, that indicates we might want to include this additional feature or a transformation of it. \n",
    "\n",
    "In Project Part 1, you conducted feature transformation to create several other features related to the Sale Price including `Bedrooms` and `Roof Material`.\n",
    "Let's examine plots of the residuals from Model 1 vs each of these features.\n",
    "\n",
    "We have automatically imported staff implementations of the functions you wrote in Project 1 (these are stored in `feature_func.py`).  You are welcome to copy over your own implementations from Project 1 if you'd prefer. \n",
    "\n",
    "These functions are:\n",
    " - `remove_outliers`, \n",
    " - `add_total_bedrooms`, \n",
    " - `find_expensive_neighborhoods`, \n",
    " - `add_in_expensive_neighborhood`, and \n",
    " - `ohe_roof_material`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa93845f-1691-4363-8de4-312bf574ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell - it creates the columns of the 2 additional features we're interested in considering \n",
    "# and appends the residual data from Model 1, so we can easily visualize\n",
    "\n",
    "from feature_func import *\n",
    "\n",
    "\n",
    "def process_data_candidates(data):\n",
    "    \n",
    "    # Remove Non-Market Sales\n",
    "    data = data[data[\"Pure Market Filter\"]==1]\n",
    "    \n",
    "    data[\"Log Sale Price\"] = np.log(data[\"Sale Price\"])\n",
    "    \n",
    "    # Create Log Building Square Feet column\n",
    "    data[\"Log Building Square Feet\"] = np.log(data[\"Building Square Feet\"])\n",
    "    \n",
    "    \n",
    "    # Create Bedrooms\n",
    "    data = add_total_bedrooms(data)\n",
    "     \n",
    "   \n",
    "    # Update Roof Material feature with names\n",
    "    data = substitute_roof_material(data)\n",
    "    \n",
    "    # Select columns for comparing residuals\n",
    "    data = data[['Log Building Square Feet',  'Roof Material', 'Bedrooms', 'Log Sale Price']]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "#Since our residuals are using the validation data, we will just examine these new features on the validation dataset\n",
    "    \n",
    "valid_comp = process_data_candidates(valid)\n",
    "    \n",
    "valid_comp = valid_comp.assign(M1residuals_log=Y_valid_m1 - Y_predict_valid_m1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f206997-8542-4dc5-96ec-7c0019a96791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to compare residuals with Bedrooms\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "px.box(valid_comp, x='Bedrooms', y='M1residuals_log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c36fe62-a50e-4b42-888e-84d2c72de36c",
   "metadata": {},
   "source": [
    "Notice, the medians of each boxplot align pretty close to 0 on the y-axis (meaning there is no major trend in prediction errors by Number of Bedrooms).\n",
    "\n",
    "This means we do NOT expect adding the features Bedrooms will help improve our original model.\n",
    "\n",
    "What about Roof Material?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707f716-7575-43c3-be93-75b83a9da987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to compare residuals vs Roof Material\n",
    "\n",
    "px.box(valid_comp, x='Roof Material', y='M1residuals_log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7fb07f-ce50-416b-af97-3e9494295516",
   "metadata": {},
   "source": [
    "The plot above shows us that the distribution of errors appears to change slightly based on Roof Material. Ideally, the median of each  box plot lines up with 0 on the y-axis (meaning there was no difference in prediction by Roof Material type). Instead, we see some variation from 0 for all except Shingle/Asphalt.   These patterns suggest that we may want to try including Roof Material in the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b61b64-5a52-447f-b088-be206be00ff6",
   "metadata": {},
   "source": [
    "## Question 4a:  Model 2\n",
    "\n",
    "Let's add `Roof Material` as a predictor in our model.  We will transform the column to be in terms of the Room Material names (like you did in Project Part 1, instead of the number codes).   In other words, let's consider a model of the form:\n",
    "\n",
    "Model 2: \n",
    "$$\n",
    "\\text{Log Sale Price} =  \\theta_1 (\\text{Log Building Square Feet})  +\\theta_2 (\\text{Shingle/Asphalt})+ \\theta_3 (\\text{Tar&Gravel})+ \\theta_4  (\\text{Tile})+ \\theta_5 (\\text{Shake})+  \\theta_6(\\text{Other})+  \\theta_7(\\text{Slate})\n",
    "$$\n",
    "\n",
    "\n",
    "**Note:** This will require one-hot-encoding Roof Material.  Notice since we're one-hot-encoding we don't need to include an extra intercept term in the model. \n",
    "\n",
    "In the cells below fill in the code to create and analyze Model 2 (follow the Modeling steps outlined in Question 3):  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1b2eb-e965-4a9f-a7bc-6db9a4229ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling Step 1:  Process the Data\n",
    "\n",
    "# Hint: You can either use your implementation of the One Hot Encoding Function from Project Part 1, or use the staff's implementation\n",
    "\n",
    "from feature_func import *\n",
    "\n",
    "...\n",
    "# Optional:  Define any helper functions you need for one-hot encoding above this line\n",
    "\n",
    "\n",
    "def process_data_m2(data):\n",
    "    \n",
    "    # You should start by only keeping values with Pure Market Filter = 1\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return data\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Process the data for Model 2\n",
    "processed_train_m2 = ...\n",
    "\n",
    "processed_val_m2 = ...\n",
    "\n",
    "\n",
    "# Create X (dataframe) and Y (series) to use in the model\n",
    "X_train_m2 = ...\n",
    "Y_train_m2 = ...\n",
    "\n",
    "X_valid_m2 = ...\n",
    "Y_valid_m2 = ...\n",
    "\n",
    "\n",
    "# Take a look at the result\n",
    "display(X_train_m2.head())\n",
    "display(Y_train_m2.head())\n",
    "\n",
    "display(X_valid_m2.head())\n",
    "display(Y_valid_m2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca80365b-df1e-4ddf-92e7-a65d3262af58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling STEP 2:  Create a Multiple Linear Regression Model\n",
    "\n",
    "# Be sure to set fit_intercept to False, since we are incorporating one-hot-encoded data\n",
    "\n",
    "\n",
    "...\n",
    "# your code above this line to create regression model for Model 2\n",
    "\n",
    "Y_predict_train_m2 = ...\n",
    "\n",
    "Y_predict_valid_m2 = ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b807f6-2f74-4081-bf25-639a8b7db34a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 3:  Evaluate the RMSE for your model\n",
    "\n",
    "# Training and test errors for the model (in its units of Log Sale Price)\n",
    "\n",
    "training_error_log[1] = ...\n",
    "validation_error_log[1]= ...\n",
    "\n",
    "# Training and test errors for the model (in its original values before the log transform)\n",
    "training_error[1] = ...\n",
    "validation_error[1] = ...\n",
    "\n",
    "\n",
    "print(\"2nd Model\\nTraining RMSE (log): {}\\nValidation RMSE (log): {}\\n\".format(training_error_log[1], validation_error_log[1]))\n",
    "print(\"2nd Model \\nTraining RMSE: {}\\nValidation RMSE: {}\\n\".format(training_error[1], validation_error[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a994ab-22b7-45e2-bfec-9f02b879fe60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 4:  Conduct 5-fold cross validation for model and output RMSE\n",
    "\n",
    "...\n",
    "# your code above this line to use 5-fold cross-validation and output RMSE (in units of dollars)\n",
    "\n",
    "cv_error[1] = ...\n",
    "\n",
    "print(\"2nd Model Cross Validation RMSE: {}\".format(cv_error[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eab6eb-295a-4572-9f33-141a2fae6a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 5:  Just run this cell to Plot bar graph comparing RMSEs of Model 2 and Model 1 and side-by-side residuals\n",
    "\n",
    "model_names[1] = \"M2: log(bsqft)+Roof\"\n",
    "\n",
    "fig = go.Figure([\n",
    "go.Bar(x = model_names, y = training_error, name=\"Training RMSE\"),\n",
    "go.Bar(x = model_names, y = validation_error, name=\"Validation RMSE\"),\n",
    "go.Bar(x = model_names, y = cv_error, name=\"Cross Val RMSE\")\n",
    "])\n",
    "\n",
    "fig.update_yaxes(range=[180000,260000], title=\"RMSE\")\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e80df0-626c-4319-af2c-7c73baac4e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 5 cont'd:  Plot 2 side-by-side residual plots (similar to Question 3, for validation data)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "\n",
    "\n",
    "x_plt1 = ...\n",
    "y_plt1 = ...\n",
    "\n",
    "x_plt2 = ...\n",
    "y_plt2 = ...\n",
    "\n",
    "\n",
    "ax[0].scatter(x_plt1, y_plt1, alpha=.25)\n",
    "ax[0].axhline(0, c='black', linewidth=1)\n",
    "ax[0].set_xlabel(r'Predicted Log(Sale Price)')\n",
    "ax[0].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[0].set_title(\"Model 2 Val Data: Residuals vs. Predicted Log(Sale Price)\")\n",
    "\n",
    "ax[1].scatter(x_plt2, y_plt2, alpha=.25)\n",
    "ax[1].axhline(0, c='black', linewidth=1)\n",
    "ax[1].set_xlabel(r'Log(Sale Price)')\n",
    "ax[1].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[1].set_title(\"Model 2 Val Data: Residuals vs. Log(Sale Price)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ec68d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a904d87a-9fa9-4e6f-8499-d0d509f7a7a0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Question 4b\n",
    "\n",
    "\n",
    "We only see a slight decrease in the RMSE with this 2nd model, and our residuals look nearly the same as Model 1, even though the boxplots of Roof Material vs the residuals of Model 1 had indicated it might be a useful feature to add to the model.  \n",
    "\n",
    "What went wrong?\n",
    "  \n",
    "Although there was variation in the boxplots we didn't check the number of data points actually in each different Roof Material Category, which will affect how useful the feature will be in reducing the RMSE.  \n",
    "\n",
    "To see this, group the `valid_comp` data by Roof Material Type and calculate the proportion of data in each category.  \n",
    "\n",
    "Set the variable `val_data_prop_roof_type` equal to a `series` with indices given by Roof Material Name and values that are the proportion of validation data of that roof type.\n",
    "\n",
    "(for example `val_data_prop_roof_type[\"Shingle/Asphalt\"]` should return a float that is the proportion of data points with that type of roof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309fdf85-e7e9-4e43-9a70-ebcf615d04fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data_prop_roof_type = ...\n",
    "\n",
    "val_data_prop_roof_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06177f4d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9432c42e-e5df-458d-94a8-a3f3a49a031c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "\n",
    "<br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 5:  Improving the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b561eb-28eb-45ec-a5ee-49865642c224",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5a:  Choose an additional feature\n",
    "\n",
    "It's your turn to choose another feature to add to the model.  Choose one new **quantitative** (not qualitative) feature and create Model 3 incorporating this feature (along with the features we've already chosen in Model 2).    Try to choose a feature that will have a large impact on reducing the RMSE and/or will improve your residual plots.  This can be a raw feature available in the dataset, or a transformation of one of the features in the dataset, or a new feature that you create from the dataset (see Project 1 for ideas).    In the cell below, explain what additional feature you have chosen and why.  Justify your reasoning.  There are optional code cells provided below for you to use when exploring the dataset to determine which feature to add. \n",
    "\n",
    "Note:  There is not one single right answer as to which feature to add, however you should make sure the feature decreases the Cross Validation RMSE compared to Model 2 (i.e. we want to improve the model, not make it worse!)  \n",
    "This problem will be graded based on your reasoning and explanation of the feature you choose, and then on your implementation of incorporating the feature.   \n",
    "\n",
    "**NOTE** Please don't add additional coding cells below or the Autograder will have issues.  You do not need to use all the coding cells provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb888340-fe11-4098-b545-4efc968553eb",
   "metadata": {},
   "source": [
    "### Question 5a Answer Cell:   \n",
    "In this cell, explain what feature you chose to add and why. Then give the equation for your new model (use Model 2 from above and then add an additional term).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04c04e-a63d-42fd-96a6-6ebe7ac2e5ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Show work in this cell exploring data to determine which feature to add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50a27c-3828-4104-bbe1-ba14296898f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Optional code cell for additional work exploring data/ explaining which feature you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9b240-5966-469d-9969-a39e72aa3a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Optional code cell for additional work exploring data/ explaining which feature you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc573a-ec39-4b72-8e6d-ee0c16a57660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Optional code cell for additional work exploring data/ explaining which feature you chose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e983b-9132-4783-9eb1-9e7dbd44ef07",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 5b:  Create Model 3\n",
    "\n",
    "In the cells below fill in the code to create and analyze Model 3 (follow the Modeling steps outlined in Questions 3 and 4).\n",
    "\n",
    "PLEASE DO NOT ADD ANY ADDITIONAL CELLS IN THIS PROBLEM OR IT MIGHT MAKE THE AUTOGRADER FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e157b653-4fcc-4aef-8f00-6929ecda2c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling Step 1:  Process the Data\n",
    "\n",
    "# Hint: You can either use your implementation of the One Hot Encoding Function from Project Part 1, or use the staff's implementation\n",
    "\n",
    "from feature_func import *\n",
    "\n",
    "...\n",
    "# Optional:  Define any helper functions you need for one-hot encoding above this line\n",
    "\n",
    "\n",
    "def process_data_m3(data):\n",
    "    \n",
    "    # You should start by only keeping values with Pure Market Filter = 1\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return data\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Process the data for Model 3\n",
    "processed_train_m3 = ...\n",
    "\n",
    "processed_val_m3 = ...\n",
    "\n",
    "# Create X (Dataframe) and Y (series) to use to train the model\n",
    "X_train_m3 = ...\n",
    "Y_train_m3 = ...\n",
    "\n",
    "X_valid_m3 = ...\n",
    "Y_valid_m3 = ...\n",
    "\n",
    "\n",
    "# Take a look at the result\n",
    "display(X_train_m3.head())\n",
    "display(Y_train_m3.head())\n",
    "\n",
    "display(X_valid_m3.head())\n",
    "display(Y_valid_m3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d15190-7427-4b88-b522-97b7506eca0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling STEP 2:  Create a Multiple Linear Regression Model\n",
    "\n",
    "# Be sure to set fit_intercept to False, since we are incorporating one-hot-encoded data\n",
    "\n",
    "\n",
    "...\n",
    "# your code above this line to create regression model for Model 2\n",
    "\n",
    "Y_predict_train_m3 = ...\n",
    "\n",
    "Y_predict_valid_m3 = ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e82bbe-75b6-49f9-af01-f6bab090ab53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 3:  Evaluate the RMSE for your model\n",
    "\n",
    "# Training and test errors for the model (in its units of Log Sale Price)\n",
    "\n",
    "training_error_log[2] = ...\n",
    "validation_error_log[2]= ...\n",
    "\n",
    "# Training and test errors for the model (in its original values before the log transform)\n",
    "training_error[2] = ...\n",
    "validation_error[2] = ...\n",
    "\n",
    "\n",
    "print(\"3rd Model\\nTraining RMSE (log): {}\\nValidation RMSE (log): {}\\n\".format(training_error_log[2], validation_error_log[2]))\n",
    "print(\"3rd Model \\nTraining RMSE: {}\\nValidation RMSE: {}\\n\".format(training_error[2], validation_error[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336411c9-e7a6-4f1c-a5af-cb5f467067ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 4:  Conduct 5-fold cross validation for model and output RMSE\n",
    "\n",
    "...\n",
    "# your code above this line to use 5-fold cross-validation and output RMSE (in units of dollars)\n",
    "\n",
    "cv_error[2] = ...\n",
    "\n",
    "print(\"3rd Model Cross Validation RMSE: {}\".format(cv_error[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d987ff-6de0-48ec-a267-9465004b0691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 5:  Add a name for your 3rd model describing the features and run this cell to Plot bar graph all 3 models\n",
    "\n",
    "model_names[2] = ...\n",
    "\n",
    "\n",
    "fig = go.Figure([\n",
    "go.Bar(x = model_names, y = training_error, name=\"Training RMSE\"),\n",
    "go.Bar(x = model_names, y = validation_error, name=\"Validation RMSE\"),\n",
    "go.Bar(x = model_names, y = cv_error, name=\"Cross Val RMSE\")\n",
    "])\n",
    "\n",
    "fig.update_yaxes(range=[180000,260000], title=\"RMSE\")\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626111cb-3c63-45f8-86c0-3fd5d9408f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 5 cont'd:  Plot 2 side-by-side residual plots (similar to Question 3, for validation data)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "\n",
    "\n",
    "x_plt1 = ...\n",
    "y_plt1 = ...\n",
    "\n",
    "x_plt2 = ...\n",
    "y_plt2 = ...\n",
    "\n",
    "\n",
    "ax[0].scatter(x_plt1, y_plt1, alpha=.25)\n",
    "ax[0].axhline(0, c='black', linewidth=1)\n",
    "ax[0].set_xlabel(r'Predicted Log(Sale Price)')\n",
    "ax[0].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[0].set_title(\"Model 3 Val Data: Residuals vs. Predicted Log(Sale Price)\")\n",
    "\n",
    "ax[1].scatter(x_plt2, y_plt2, alpha=.25)\n",
    "ax[1].axhline(0, c='black', linewidth=1)\n",
    "ax[1].set_xlabel(r'Log(Sale Price)')\n",
    "ax[1].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[1].set_title(\"Model 3 Val Data: Residuals vs. Log(Sale Price)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986ee1e6-5e76-4011-8c3c-ac0a8d010a63",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 5c\n",
    "\n",
    "i).  Comment on your RMSE and residual plots from Model 3 compared to the first 2 models.  \n",
    "\n",
    "ii).  Are the residuals of your model still showing a trend that overestimates lower priced houses and underestimates higher priced houses?   If so, how could you try to address this in the next round of modeling?\n",
    "\n",
    "iii).  If you had more time to improve your model, what would your next steps be?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482d656",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce72ca-00d0-4e0e-a66c-cf9600af0fb6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 6: Evaluating the Model in Context\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "## Question 6a\n",
    "\n",
    "When evaluating your model, we used RMSE. In the context of estimating the value of houses, what does the residual mean for an individual homeowner? How does it affect them in terms of property taxes? Discuss the cases where residual is positive and negative separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab0131",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be950ff7-6580-4425-80f6-0b10d9337cbc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "In the case of the Cook County Assessor’s Office, Chief Data Officer Rob Ross states that fair property tax rates are contingent on whether property values are assessed accurately - that they’re valued at what they’re worth, relative to properties with similar characteristics. This implies that having a more accurate model results in fairer assessments. The goal of the property assessment process for the CCAO, then, is to be as accurate as possible. \n",
    "\n",
    "When the use of algorithms and statistical modeling has real-world consequences, we often refer to the idea of fairness as a measurement of how socially responsible our work is. Fairness is incredibly multifaceted: Is a fair model one that minimizes loss - one that generates accurate results? Is it one that utilizes \"unbiased\" data? Or is fairness a broader goal that takes historical contexts into account?\n",
    "\n",
    "These approaches to fairness are not mutually exclusive. If we look beyond error functions and technical measures of accuracy, we'd not only consider _individual_ cases of fairness, but also what fairness - and justice - means to marginalized communities on a broader scale. We'd ask: What does it mean when homes in predominantly Black and Hispanic communities in Cook County are consistently overvalued, resulting in proportionally higher property taxes? When the white neighborhoods in Cook County are consistently undervalued, resulting in proportionally lower property taxes? \n",
    "\n",
    "Having \"accurate\" predictions doesn't necessarily address larger historical trends and inequities, and fairness in property assessments in taxes works beyond the CCAO's valuation model. Disassociating accurate predictions from a fair system is vital to approaching justice at multiple levels. Take Evanston, IL - a suburb in Cook County - as an example of housing equity beyond just improving a property valuation model: Their City Council members [recently approved reparations for African American residents](https://www.usnews.com/news/health-news/articles/2021-03-23/chicago-suburb-approves-government-reparations-for-black-residents)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e730874-69ce-40b1-bfd6-1fa96540b277",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 6b\n",
    "\n",
    "Reflecting back on your exploration in Questions 5 and 6a, in your own words, what makes a model's predictions of property values for tax assessment purposes \"fair\"? \n",
    "\n",
    "This question is open-ended and part of your answer may depend upon your specific model; we are looking for thoughtfulness and engagement with the material, not correctness. \n",
    "\n",
    "**Hint:** Some guiding questions to reflect on as you answer the question above: What is the relationship between RMSE, accuracy, and fairness as you have defined it? Is a model with a low RMSE necessarily accurate? Is a model with a low RMSE necessarily \"fair\"? Is there any difference between your answers to the previous two questions? And if so, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77da9352",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb6307f-43d3-4c1d-b3c4-f847667db4c0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Extra Credit:  How Low Can You Go?   Create Your Own Model and Check RMSE on the Test Data\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f1d86-680a-4448-b806-db1ff1869c5e",
   "metadata": {},
   "source": [
    "\n",
    "For **extra credit**, you can create your own model to try to improve the RMSE and residual plots even further.    \n",
    "\n",
    "The tables below provide scoring guidelines for the extra credit opportunity in this problem. \n",
    "If your RMSE lies in a particular range, you will receive the number of points associated with that range.\n",
    "\n",
    "\n",
    "\n",
    "### Extra Credit Grading Scheme\n",
    "\n",
    "**Important**: while your Validation RMSE can be checked at any time in this notebook, your Test RMSE can only be checked once by submitting your model’s predictions to Gradescope. The thresholds are as follows:\n",
    "\n",
    "Extra Credit Points | +5 | +4 | +3  | +2 | + 1\n",
    "--- | --- | --- | --- | --- | ---\n",
    "Validation RMSE | Less than 200k | [200k, 210k) | [210k, 220k) | [220k, 230k)  | [230k, 235k)\n",
    "\n",
    "Extra Credit Points | +5 | +4 | +3  | +2 | + 1\n",
    "--- | --- | --- | --- | --- | ---\n",
    "Test RMSE | Less than 200k | [200k, 210k) | [210k, 220k) | [220k, 230k)| [230k, 235k)\n",
    "\n",
    "<br><br>\n",
    "\n",
    "To receive these points, you need to show your work in the cells below AND complete the EXPLANATION STEP at the end (explaining what you did to create your model).  \n",
    "\n",
    "You ALSO MUST UPLOAD your test prediction .csv to the **\"Project 2 Extra Credit Test Predictions\"** assignment in Gradescope to receive extra credit for your test predictions.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Some notes before you start\n",
    "\n",
    "- **If you are running into memory issues, restart the kernel and only run the cells you need to.**   If needed you can use the commented cell below (question cell) that contains most to all of the imports necessary to successfully complete this portion of the project, so it can be completed independently code-wise from the remainder of the project, and you do not need to rerun the cell at the top of this notebook. The autograder will have more than 4GB of memory, so you will not lose credit as long as your solution to this question is within the total memory (4GB) limits of DataHub. By default, we reset the memory and clear all variables using `%reset -f`. If you want to delete specific variables, you may also use `del` in place of `%reset -f%`. For example, the following code will free up memory from data used for older models: `del training_val_data, test_data, train, validation, X_train_m1, X_valid_m1, X_train_m2, X_valid_m1`. Our staff solution can be run independently from all other questions, so we encourage you to do the same to make debugging easier.\n",
    "- To avoid memory issues, you do not need to include cross validation for this step.  Your score will be based on the Validation Data set RMSE and the Test dataset RMSE.\n",
    "- **Note: If you need the data again after deleting the variables or resetting, you must reload them again.**\n",
    "- You will be predicting `Log Sale Price` on the data stored in `cook_county_contest_test.csv`. We will delog/exponentiate your prediction on Gradescope to compute RMSE and use this to score your model. Before submitting to Gradescope, make sure that your predicted values can all be delogged (i.e., if one of your `Log Sale Price` predictions is 60, it is too large; $e^{60}$ is too big!)\n",
    "- You MUST remove any additional new cells you add before submitting to Gradescope to avoid any autograder errors. \n",
    "\n",
    "\n",
    "**PLEASE READ THE ABOVE MESSAGE CAREFULLY!**\n",
    "\n",
    "**Hints:** \n",
    "- Some features may have missing values in the test set but not in the training set (especially if you're one-hot-encoding). Make sure `process_data_ec` handles missing values appropriately for each feature!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6e590f-5b0c-44f4-8d22-dded2e3b952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional code cell for additional work exploring data/ explaining which feature you chose.\n",
    "# You can add additional code cells directly below this if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52563760-3ea3-489d-8b0a-e74990391498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional code cell for additional work exploring data/ explaining which feature you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f02e98-a8c5-4580-98d6-1e2509e464ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional cell to try if you're having memory issues (i.e. if kernel keeps dying)\n",
    "\n",
    "\n",
    "# If you're having memory issues, uncomment the lines below to clean up memory from previous questions and reinitialize Otter!\n",
    "\n",
    "\n",
    "\n",
    "# MAKE SURE TO RECOMMENT THE NEXT 3 LINES OUT BEFORE SUBMITTING!\n",
    "\n",
    "#%reset -f\n",
    "#import otter\n",
    "#grader = otter.Notebook(\"ProjPart2.ipynb\")\n",
    "\n",
    "\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#from pandas.api.types import CategoricalDtype\n",
    "\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#from sklearn import linear_model as lm\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#import zipfile\n",
    "#import os\n",
    "\n",
    "#import plotly.graph_objects as go\n",
    "\n",
    "#from ds100_utils import *\n",
    "#from feature_func import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#training_val_data = pd.read_csv(\"cook_county_train_val.csv\", index_col='Unnamed: 0')\n",
    "#test_data = pd.read_csv(\"cook_county_contest_test.csv\", index_col='Unnamed: 0')\n",
    "\n",
    "# COPY THESE FUNCTIONS FROM ABOVE\n",
    "\n",
    "#def rmse(predicted, actual):\n",
    "    \n",
    "\n",
    "\n",
    "#def train_val_split(data):\n",
    "    \n",
    "    \n",
    "\n",
    "## This makes the train-test split in this section reproducible across different runs of the notebook. DO NOT CHANGE THIS RANDOM SEED.\n",
    "#np.random.seed(1337)\n",
    "\n",
    "#train, valid = train_val_split(training_val_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070bc6a5-98f6-433f-b1d7-cda8fb6330ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Extra Credit Step 1: Creating Your Model\n",
    "Complete the modeling steps (you can skip the cross validation step to save memory) in the cells below.\n",
    "\n",
    "DO NOT ADD ANY EXTRA CELLS BELOW (for this part of the problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f8769-b38c-4d95-b801-77256f524171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling Step 1:  Process the Data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hint: You can either use your implementation of the One Hot Encoding Function from Project Part 1, or use the staff's implementation\n",
    "#from feature_func import *\n",
    "\n",
    "\n",
    "...\n",
    "# Optional:  Define any helper functions you need for one-hot encoding above this line\n",
    "\n",
    "\n",
    "def process_data_ec(data):\n",
    "    \n",
    "    # You should start by only keeping values with Pure Market Filter = 1\n",
    "    ...\n",
    "    \n",
    "    return data\n",
    "\n",
    "    \n",
    "# Process the data \n",
    "processed_train_ec = ...\n",
    "\n",
    "processed_val_ec = ...\n",
    "\n",
    "\n",
    "X_train_ec = ...\n",
    "Y_train_ec = ...\n",
    "\n",
    "X_valid_ec = ...\n",
    "Y_valid_ec = ...\n",
    "\n",
    "\n",
    "# Take a look at the result\n",
    "#display(X_train_ec.head())\n",
    "#display(Y_train_ec.head())\n",
    "\n",
    "#display(X_valid_m3.head())\n",
    "#display(Y_valid_m3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9b7e0-d2c3-47bd-b26b-abfb35bb28ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling STEP 2:  Create a Multiple Linear Regression Model\n",
    "\n",
    "# If you are are incorporating one-hot-encoded data, set the fit_intercept to False\n",
    "\n",
    "...\n",
    "# your code above this line to create regression model for Model 2\n",
    "\n",
    "Y_predict_train_ec = ...\n",
    "\n",
    "Y_predict_valid_ec = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628c260-ec41-4465-bd2c-2110a3e9d626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 3:  Evaluate the RMSE for your model\n",
    "\n",
    "\n",
    "# Training and test errors for the model (in its original values before the log transform)\n",
    "training_error_ec = ...\n",
    "validation_error_ec = ...\n",
    "\n",
    "\n",
    "print(\"Extra Credit Model\\nTraining RMSE (log): {}\\nValidation RMSE (log): {}\\n\".format(training_error_ec, validation_error_ec))\n",
    "print(\"Extra Credit \\nTraining RMSE: {}\\nValidation RMSE: {}\\n\".format(training_error_ec, validation_error_ec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a0943-96b8-4de4-80b8-a1b72d269558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional: Run this cell to visualize\n",
    "\n",
    "fig = go.Figure([\n",
    "go.Bar(x = [\"Extra Credit Model\"], y = [training_error_ec], name=\"Training RMSE\"),\n",
    "go.Bar(x = [\"Extra Credit Model\"], y = [validation_error_ec], name=\"Validation RMSE\"),\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "fig\n",
    "fig.update_yaxes(range=[140000,260000], title=\"RMSE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529960bf-78ba-44b4-b9f2-83674b92cc76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELING STEP 5: Plot 2 side-by-side residual plots for validation data\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "\n",
    "\n",
    "x_plt1 = ...\n",
    "y_plt1 = ...\n",
    "\n",
    "x_plt2 = ...\n",
    "y_plt2 = ...\n",
    "\n",
    "\n",
    "ax[0].scatter(x_plt1, y_plt1, alpha=.25)\n",
    "ax[0].axhline(0, c='black', linewidth=1)\n",
    "ax[0].set_xlabel(r'Predicted Log(Sale Price)')\n",
    "ax[0].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[0].set_title(\"EC Val Data: Residuals vs. Predicted Log(Sale Price)\")\n",
    "\n",
    "ax[1].scatter(x_plt2, y_plt2, alpha=.25)\n",
    "ax[1].axhline(0, c='black', linewidth=1)\n",
    "ax[1].set_xlabel(r'Log(Sale Price)')\n",
    "ax[1].set_ylabel(r'Residuals: Log(Sale Price) - Predicted Log(Sale Price)');\n",
    "ax[1].set_title(\"EC Val Data: Residuals vs. Log(Sale Price)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908f0a63-e962-4af6-b6e2-2776a1e0196c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Extra Credit Step 2:  Explanation (Required for points on model above):\n",
    "\n",
    "Explain what you did to create your model.  What versions did you try?  What worked and what didn't? \n",
    "\n",
    "Comment on the RMSE and residual plots from your model.   Are the residuals of your model still showing a trend that overestimates lower priced houses and underestimates higher priced houses? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59288123",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f5d7fc-f90a-4531-80f9-f1147b91129c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Extra Credit Step 3: Create and Submit Test Set Predictions to Gradescope\n",
    "\n",
    "Now it's time to test your model on the actual test set.  You are only allowed to submit to Gradescope once, so wait until you have the best version of your model.    \n",
    "\n",
    "The test data is in the dataframe `test_data`.  \n",
    "\n",
    "Process the test data and run it through your model. Store your predictions from the test_data in the variable `Y_test_pred`.  These should be in units Log Sale Price (you do not need to exponentiate them).  \n",
    "\n",
    "Then run the cell provided below to create a .csv file to store your predictions on the test set and submit this .csv to the Gradescope Assignment: **\"Project 2 Extra Credit Test Predictions\"**. \n",
    "Note that **you will not receive credit for the test set predictions (i.e. up to 10 points) unless you submit your.csv to the Gradescope assignment**!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8474037-f12b-4b92-aa14-342180ac6942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cells to process test_data and run the model on it.  You CAN add any additional cells below\n",
    "# Note: You can't remove any test_data cells.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62eefc-b626-4e0e-afe7-8363ebeb6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store your predictions for the test set in Y_test_pred (these should be in units of Log Sale Price)\n",
    "Y_test_pred = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae11c9c5-7edf-4aad-a460-aa0ae4e8e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this file to create the .csv of your predictions for the test set to upload to the assignment in Gradescope labeled Project 2 Extra Credit Test Predictions to have it checked.\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#Store your predictions for the test set in Y_test_pred (these should be in units of Log Sale Price)\n",
    "\n",
    "\n",
    "# Construct and save the submission:\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Id\": pd.read_csv('cook_county_contest_test.csv')['Unnamed: 0'], \n",
    "    \"Value\": Y_test_pred,\n",
    "}, columns=['Id', 'Value'])\n",
    "timestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\n",
    "submission_df.to_csv(\"submission_{}.csv\".format(timestamp), index=False)\n",
    "\n",
    "print('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\n",
    "print('You MUST now upload this CSV file to the Gradescope assignment \"Project 2 Extra Credit Test Predictions\" for scoring.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a76fb8-a6be-4bf7-b81a-6a65b341a21a",
   "metadata": {},
   "source": [
    "## Congratulations! You have finished the Project - Part 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec082596-e29c-4224-bf42-73fb00ce58ea",
   "metadata": {},
   "source": [
    "If you discussed this assignment with any other students in the class (in a manner that is acceptable as described by the Collaboration policy above) please **include their names** here:\n",
    "\n",
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5cb90d-5ca5-4a83-8f95-79caa419daaa",
   "metadata": {},
   "source": [
    "### Submission Instructions\n",
    "\n",
    "Before proceeding any further, **save this notebook.**\n",
    "\n",
    "After running the `grader.export()` cell provided below, **2 files will be created**: a zip file and pdf file.  You can download them using the links provided below OR by finding them in the same folder where this juptyer notebook resides in your JuptyerHub.\n",
    "\n",
    "To receive credit on this assignment, **you must submit BOTH of these files\n",
    "to their respective Gradescope portals:** \n",
    "\n",
    "* **Project Part 2 Autograded**: Submit the zip file that is output by the `grader.export()` cell below to the Autograded assignment in Gradescope.\n",
    "\n",
    "* **Project Part 2 Manually Graded**: Submit your ProjectPart2.PDF to the  Manually Graded assignment in Gradescope.  **YOU MUST SELECT THE PAGES CORRESPONDING TO EACH QUESTION WHEN YOU UPLOAD TO GRADESCOPE.  IF NOT, YOU WILL LOSE POINTS**   Also, **check** that all of your plots **and** all lines of your code are showing up in your PDF before submitting.  If not, you will not receive credit for your plots/code.  \n",
    "\n",
    "* **Extra Credit Submission**:  If you completed the extra credit, to receive credit for the Test Case prediction you must submit your Test Case prediction.csv (generated in the last cell of the extra credit section) to the Gradescope assignment titled \"Project 2 Extra Credit Test Predictions\"\n",
    "\n",
    "**You are responsible for ensuring your submission follows our requirements. We will not be granting regrade requests nor extensions to submissions that don't follow instructions.** If you encounter any difficulties with submission, please don't hesitate to reach out to staff prior to the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d410c88d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "AFTER running the cell below, click on <a href='ProjPart2.pdf' download>this link to download the PDF </a> to upload to Gradescope.  There will be a separate link that appears after running the cell below with a link to download the zip file to upload to Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544148e6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629597a4",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1c": {
     "name": "q1c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q1c.lower() in ['a', 'b', 'c']\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2d": {
     "name": "q2d",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # TEST\n>>> \n>>> assert type(max_Sale_Price_filtered)  == int\n>>> \n>>> assert type(min_Sale_Price_filtered)  == int\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": [
      0,
      0,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert train.shape == (163833, 62) # train should contain 80% of the data\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> \n>>> assert valid.shape == (40959, 62) # test should contain 20% of the data\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(train[\"Sale Price\"].mean(), 244939.22668204817, atol=0.1) # If this doesn't match, you might have still answered the question, but please adjust your code so that your split matches ours by following the implementation instructions about using shuffled_indices to split the data.\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> \n>>> assert np.isclose(valid[\"Sale Price\"].mean(), 246066.1821089382, atol=0.1) # If this doesn't match, you might have still answered the question, but please adjust your code so that your split matches ours by following the implementation instructions about using shuffled_indices to split the data.\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(Y_predict_train_m1.sum(), 1632928.31054)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(Y_predict_valid_m1.sum(), 409143.88113)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c": {
     "name": "q3c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> a=np.array([2.5, 3.4])\n>>> b=np.array([4.1, -2.9])\n>>> \n>>> assert np.isclose(rmse(a,b), 4.5961940)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> c=np.array([2.5, 3.4, 15, -21.3])\n>>> d=np.array([4.1, -2.9, 17, 24.2])\n>>> \n>>> assert np.isclose(rmse(c,d), 23.0027172)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3d": {
     "name": "q3d",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(training_error_log[0], 0.75097909)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(validation_error_log[0], 0.750899865861)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(validation_error[0], 255533.84041505)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(training_error[0], 249895.90791758915)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3e": {
     "name": "q3e",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(x_plt1.sum(), 409143.881139)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(y_plt1.sum(), 102.89668104)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(x_plt2.sum(), 409246.777820)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(y_plt2.sum(), 102.89668104)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3f": {
     "name": "q3f",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (q3f.lower() in [\"regressive\", \"fair\", \"progressive\"])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(X_train_m2.loc[130829].sum(), 8.870165946469845)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(Y_valid_m2[7028], 12.254862809699606)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(Y_predict_train_m2[100], 11.920800692563162)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(Y_predict_valid_m2[4], 11.9570595)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(training_error_log[1], 0.7483802621)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(validation_error_log[1], 0.7480199)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(validation_error[1], 247381.61240)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(training_error[1], 242236.367440)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(x_plt1.sum(), 409142.821382)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(y_plt1.sum(), 103.95643793)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(x_plt2.sum(), 409246.7778207023)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(y_plt2.sum(), 103.95643793)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(val_data_prop_roof_type[\"Other\"] , 0.0047114954)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
