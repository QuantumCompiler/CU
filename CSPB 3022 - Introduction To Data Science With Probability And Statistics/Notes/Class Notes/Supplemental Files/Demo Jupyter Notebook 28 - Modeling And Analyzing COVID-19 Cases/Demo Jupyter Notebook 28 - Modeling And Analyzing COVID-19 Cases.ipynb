{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef8c8ae6",
   "metadata": {},
   "source": [
    "# Notebook 12: Modeling and Analyzing COVID-19 Cases\n",
    "## Probability and Estimators\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38c5ac",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we will investigate a dataset that contains information about COVID-19 cases in the United States, vaccination rates, and various other metadata that can assist in modeling various aspects of COVID-19.\n",
    "\n",
    "Through this homework assignment, you will demonstrate your experience with:\n",
    "* Bootstrap sampling\n",
    "* Multicollinearity in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f94a69-a80b-4128-8182-2b738a602abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae55c9",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 1: Exploratory Data Analysis\n",
    "\n",
    "Let's perform some initial exploratory data analysis to examine and visualize potential trends in a COVID-19 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "covid_data = pd.read_csv('covid_data.csv')\n",
    "covid_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130f947",
   "metadata": {},
   "source": [
    "The data are at county granularity; each row corresponds to COVID-19 data from one U.S. county. Here are some highlights and data sources:\n",
    "\n",
    "* The first few columns encode county and state data; for example, check out the [FIPS](https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt) numeric encoding for U.S. counties.\n",
    "* The next 600 columns record daily COVID-19 cases in the county for the date range 1/22/2020 to 9/12/2021. COVID-19 case data are from CSSE at Johns Hopkins University [GitHub](https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv).\n",
    "* The next few columns include county populations from [U.S. census data](https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/totals/co-est2020.csv), the latest of which is 2020.\n",
    "* The last 5 columns record mask usage survey data on a 5-point scale from `NEVER` to `ALWAYS`. Data are collected in July 2020 from the New York Times [GitHub](https://github.com/nytimes/covid-19-data/blob/master/mask-use/mask-use-by-county.csv). Each column represents the proportion of population in that county who never/rarely/sometimes/frequently/always wear masks. Note, for a particular row, the numbers in those five columns sum up to $1$.\n",
    "\n",
    "We can use `covid_data.describe()` to see various statistics about the numerical features of the provided COVID-19 data. Do any particular statistics stand out to you? Which might be useful when modeling?\n",
    "\n",
    "**Note:** This is just food for thought as you start to explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3487eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "covid_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06776ec8",
   "metadata": {},
   "source": [
    "### Question 1a\n",
    "\n",
    "In this homework, we will use linear regression to predict **the number of COVID-19 cases  per capita on September 12th, 2021**. Define a column `'9/12/2021_cpc'` in `covid_data` corresponding to the number of cases per capita on September 12th, 2021. \n",
    "\n",
    "Note that we will **always** use the `'POPESTIMATE2020'` as the population of each county.\n",
    "\n",
    "*Hint*: The number of cases per capita should be the total number of cases in a county divided by the population of the county.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2787a6f3",
   "metadata": {},
   "source": [
    "### Question 1b\n",
    "\n",
    "Assign `mask_data` that has six columns from the original `covid_data` table: the five mask usage columns and the `9/12/2021_cpc` column.\n",
    "\n",
    "**Note**: You should make a **copy** of these columns using `df.copy()` ([link](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c56e7e",
   "metadata": {},
   "source": [
    "### Question 1c\n",
    "\n",
    "Our goal is to use county-wise mask usage data to predict the number of COVID-19 cases per capita on September 12th, 2021 (i.e., the column `9/12/2021_cpc`). But before modeling, let's do some EDA to explore the multicollinearality in these features, and then we will revisit this question in part 4. \n",
    "\n",
    "Create a visualization that shows the pairwise correlation between each combination of columns in `mask_data`. For 2-D visualizations, consider Seaborn's [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html). Remember to add a title to your plot.\n",
    "\n",
    "*Hint*: You should be plotting 36 values corresponding to the pairwise correlations of the six columns in `mask_data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a25b54",
   "metadata": {},
   "source": [
    "### Question 1d\n",
    "\n",
    "(1) Describe the trends and takeaways visible in the visualization of pairwise correlations you plotted in Question 2c. Specifically, how does the correlation between pairs of features (i.e. mask usage) look like? How does the correlation between mask usage and cases per capita look like?\n",
    "\n",
    "(2) If we are going to build a linear regression model (with an intercept term) using all five mask usage columns as features, what could be the problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079491b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 2: Creating a Preliminary COVID-19 Model\n",
    "\n",
    "This question will guide you through creating a linear regression model that will predict the number of COVID-19 cases per capita given various COVID-19 safety protocols that have been implemented. Then, we will investigate the bias, variance, and observational noise of this model in the next two questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ef547",
   "metadata": {},
   "source": [
    "### Question 2a\n",
    "\n",
    "Despite the problems we see previously, let's train a linear regression model with an intercept term, using Scikit-learn, to predict the number of COVID-19 cases per capita for September 12, 2021 using county-wise mask usage data from `mask_data`. Use `train_test_split` to evaluate your model's RMSE on a held-out test set with 33% of the COVID-19 data; call the resulting splits `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "\n",
    "Set the parameter `random_state` to 42 in your call to `train_test_split` to generate a reproducible data split ([documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test sets\n",
    "X = ...\n",
    "y = ...\n",
    "X_train, X_test, y_train, y_test = ..., ..., ..., ...\n",
    "\n",
    "# fit the linear model and make predictions\n",
    "...\n",
    "\n",
    "# compute RMSE on train and test sets\n",
    "train_rmse_cpc = ...\n",
    "test_rmse_cpc = ...\n",
    "\n",
    "train_rmse_cpc, test_rmse_cpc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7823ad",
   "metadata": {},
   "source": [
    "### Question 2b\n",
    "\n",
    "To visualize the model performance from part (a), let's make the following two visualizations: \n",
    "\n",
    "(1) the predicted values vs. observed values on the test set,\n",
    "\n",
    "(2) the residuals plot. (Note: in multiple linear regression, the residual plot has predicted values vs. residuals) \n",
    "\n",
    "Some notes:\n",
    "* We've used `plt.subplot` ([documentation](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html)) so that you can view both visualizations side-by-side. For example, `plt.subplot(121)` sets the plottable area to the first column of a 1x2 plot grid; you can then call Matplotlib and Seaborn functions to plot that area, before the next `plt.subplot(122)` area is set.\n",
    "* Remember to add a guiding line to both plots where $\\hat{y} = y$, i.e., where the residual is 0.\n",
    "* Remember to label your axes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce45870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))      # do not change this line\n",
    "\n",
    "\n",
    "plt.subplot(121)                # do not change this line\n",
    "# (1) predictions vs observations\n",
    "# Your code here\n",
    "\n",
    "\n",
    "plt.subplot(122)               # do not change this line\n",
    "# (2) residual plot\n",
    "# Your code here\n",
    "\n",
    "plt.tight_layout()             # do not change this line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185dd56",
   "metadata": {},
   "source": [
    "### Question 2c\n",
    "\n",
    "Describe what the plots in part (b) indicate about this linear model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0bb3b",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 3: Performing Multicollinearity Analysis\n",
    "\n",
    "This question will guide you through performing an analysis that can reveal potential multicollinearity in our features, which is unideal. In particular, we will use bootstrapping to get $95\\%$ confidence intervals on the fitted parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b26f95",
   "metadata": {},
   "source": [
    "### Question 3a\n",
    "\n",
    "Fill in the blanks below to implement the `bootstrap_sample` function, that returns $k$ randomly drawn samples from a dataset `data` of size $n$ with replacement, each of size $n$ (i.e. same size as the dataset). In other words, the returned object should be a Python list `samples` containing $k$ Pandas DataFrames, each of which have $n$ rows.\n",
    "\n",
    "*Hint*: Take a look at the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) for `df.sample`!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d7436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample(data, k):\n",
    "    \"\"\"\n",
    "    Performs bootstrap sampling on data to obtain k samples of size n.\n",
    "    \n",
    "    Arguments:\n",
    "        data - Dataset contained as a Pandas DataFrame \n",
    "        k - Number of randomly drawn samples\n",
    "    \n",
    "    Returns:\n",
    "        samples - List containing k Pandas DataFrames of size n each\n",
    "                  corresponding to each sample  \n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    return ...\n",
    "\n",
    "\n",
    "bootstrap_sample(mask_data, 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c545e",
   "metadata": {},
   "source": [
    "### Question 3b\n",
    "\n",
    "Using the function from the previous part, let's do the following:\n",
    "\n",
    "1. Generate 1000 bootstrapped samples from the original `mask_data` dataframe. \n",
    "2. Use Scikit-learn to fit a linear regression model (with an intercept term) to use the mask usage features to predict the `9/12/2021_cpc` response. \n",
    "3. Store each of the 1000 trained models in the Python list `models`.\n",
    "\n",
    "Note: You *should not* create any validation or testing sets in this subpart; you should create and fit a new linear model 1000 times; you should fit your model to the entire resampled dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "datasets = ...\n",
    "models = []\n",
    "...\n",
    "\n",
    "# These take up a lot of memory, so we should remove them!\n",
    "del datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754713cc",
   "metadata": {},
   "source": [
    "### Question 3c\n",
    "\n",
    "Fill in the blanks below in the `confidence_interval` function to generate a $95\\%$ confidence interval for each of our parameters $\\theta_i$, including the intercept term $\\theta_0$. All of the helper code to extract coefficients from our trained models has been implemented for you already.\n",
    "\n",
    "**Note**: \n",
    "- For a refresh on confidence intervals, refer to this link from the [Data 8 textbook](https://inferentialthinking.com/chapters/13/3/Confidence_Intervals.html). \n",
    "- To get the $i$th column from a 2D-array, you can use `2D_array[:, i]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coefs(models, include_intercept = True):\n",
    "    \"\"\"\n",
    "    NOTE: This function has already been implemented. You do not need to modify this!\n",
    "    \n",
    "    Extracts coefficients of all the linear regression models in MODELS, and returns\n",
    "    it as a NumPy array with one model's coefficients as each row.\n",
    "    \n",
    "    Arguments:\n",
    "        models - Contains k sklearn LinearRegression models, each with p + 1 coefficients\n",
    "        include_intercept - Whether to include intercept in returned coefficients\n",
    "    \n",
    "    Returns:\n",
    "        coef_array - Coefficients of all k models, each with p + 1 coefficients (if intercept\n",
    "                     enabled, otherwise p). Returned object is k x (p + 1) NumPy array.\n",
    "    \"\"\"\n",
    "    coef_array = np.zeros(shape = (len(models), len(models[0].coef_) + 1))\n",
    "    for i, m in enumerate(models):\n",
    "        coef_array[i, 0] = m.intercept_\n",
    "        coef_array[i, 1:] = m.coef_\n",
    "    if include_intercept:\n",
    "        return coef_array \n",
    "    return coef_array[:, 1:]\n",
    "\n",
    "def confidence_interval(coefs):\n",
    "    \"\"\"\n",
    "    Calculates confidence intervals for each theta_i based on coefficients of \n",
    "    bootstrapped models. Returns output as a list of confidence intervals.\n",
    "    \n",
    "    Arguments:\n",
    "        coefs - Output of extract_coefs, a k x (p + 1) or k x p NumPy array containing\n",
    "                coefficients of bootstrapped models\n",
    "    \n",
    "    Returns:\n",
    "        cis - Confidence intervals of each parameter theta_i in the form of a \n",
    "              list like this: [(0.5, 0.75), (0.2, 0.4), ...]\n",
    "    \"\"\"\n",
    "    cis = []\n",
    "    \n",
    "    # FILL IN CODE BELOW\n",
    "    for i in range(...):\n",
    "        theta_i_values = ...\n",
    "        theta_i_lower_ci, theta_i_upper_ci = np.percentile(...), np.percentile(...)\n",
    "        cis.append((theta_i_lower_ci, theta_i_upper_ci))\n",
    "    \n",
    "    return cis\n",
    "\n",
    "\n",
    "\n",
    "# compute confidence intervals\n",
    "model_coefs = extract_coefs(models)\n",
    "cis = confidence_interval(model_coefs)\n",
    "\n",
    "# pretty print in a table\n",
    "display(Markdown('#### Confidence Intervals:'))\n",
    "md_list = [\"|parameter|lower|upper|\",\n",
    "           \"----|----|----|\"]\n",
    "md_list += [fr\"|$\\theta_{i}$|{lci}|{uci}|\" for i, (lci, uci) in enumerate(cis)]\n",
    "display(Markdown('\\n'.join(md_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f472257c",
   "metadata": {},
   "source": [
    "### Question 3d\n",
    "\n",
    "Interpret the confidence intervals above for each of the $\\theta_i$, where $\\theta_0$ is the intercept term and the remaining $\\theta_i$'s are parameters corresponding to mask usage features. What does this indicate about our data and our model?\n",
    "\n",
    "Describe a reason why this could be happening.\n",
    "\n",
    "*Hint*: Take a look at the design matrix, heatmap, and response from Question 2!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
