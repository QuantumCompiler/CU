{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675cdc5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw03.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552e640",
   "metadata": {},
   "source": [
    "### Importing Libraries and Magic Commands\n",
    "\n",
    "In CSPB 3022, we will be using common Python libraries to help us process data. By convention, we import all libraries at the very top of the notebook. There are also a set of standard aliases that are used to shorten the library names. Below are some of the libraries that you may encounter throughout the course, along with their respective aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721febdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380021a2",
   "metadata": {},
   "source": [
    "<a id='verytop'></a>\n",
    "\n",
    "# Homework 3: Practicing with Pandas\n",
    "\n",
    "## Due on Gradescope\n",
    "\n",
    "\n",
    "### Detailed Submission Instructions Are Provided at the end of this Notebook\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity.  However a key step in learning and retention is **creating solutions on your own.**  \n",
    "\n",
    "Please see the **Course Syllabus for the Collaboration Policy**.\n",
    "\n",
    "On the other hand, the following are some **examples of things which would NOT usually be\n",
    "considered to be cheating**:\n",
    " - Working on a HW problem on your own first and then discussing with a classmate a particular part in the problem solution where you are stuck.  After clarifying any questions you should then continue to write your solution independently.\n",
    " - Asking someone (or searching online) how a particular construct in the language works.\n",
    " - Asking someone (or searching online) how to formulate a particular construct in the language.\n",
    " - Asking someone for help in finding an error in your program.  \n",
    " - Asking someone why a particular construct does not work as you expected in a given program.\n",
    "   \n",
    "\n",
    "To test whether you are truly doing your own work and retaining what you've learned you should be able to easily reproduce from scratch and explain a HW solution that was your own when asked in office hours by an Instructor or on a quiz/exam.   \n",
    "\n",
    "\n",
    "If you have difficulty in formulating the general solution to a problem on your own, or\n",
    "you have difficulty in translating that general solution into a program, it is advisable to see\n",
    "your instructor.\n",
    "\n",
    "We are here to help!  Visit HW Hours and/or post questions on Piazza!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d8a09d",
   "metadata": {},
   "source": [
    "If while completing this assignment you reference any websites other than those linked in this assignment or provided on Canvas please list those references here:\n",
    "\n",
    "**External references**:  *list any websites you referenced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b45ac0",
   "metadata": {},
   "source": [
    "## Grading\n",
    "Grading is broken down into autograded answers and manually graded answers. \n",
    "\n",
    "For autograded answers, the results of your code are compared to provided and/or hidden tests.\n",
    "\n",
    "For manually graded answers you must show and explain all steps.  Graders will evaluate how well you answered the question and/or fulfilled the requirements of the question.\n",
    "\n",
    "\n",
    "### Score breakdown\n",
    "\n",
    "\n",
    "\n",
    "Question | Points | Grading Type\n",
    "--- | --- | ---\n",
    "Question 1a | 5 | autograded\n",
    "Question 1b | 5 | autograded\n",
    "Question 1c | 5 | autograded\n",
    "Question 2 | 5 | autograded\n",
    "Question 3a | 5 | autograded\n",
    "Question 3b | 3 | manual\n",
    "Question 4ai | 4 | autograded\n",
    "Question 4aii | 1 | autograded\n",
    "Question 4bi | 4 | autograded\n",
    "Question 4bii | 1 | autograded\n",
    "Question 4c | 4 | autograded\n",
    "Question 4d | 6 | manual\n",
    "Question 4e | 2 | manual\n",
    "|Total | 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eec3bc",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaad965",
   "metadata": {},
   "source": [
    "### Question 1: Elections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451db535",
   "metadata": {},
   "source": [
    "**Review**: Let's start by reading in the election dataset from the pandas lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3368a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:15.205576Z",
     "start_time": "2020-09-16T20:55:15.194080Z"
    }
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "elections = pd.read_csv(\"data/elections.csv\")\n",
    "elections.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e143e4b1",
   "metadata": {},
   "source": [
    "As we saw, we can groupby a specific column, e.g. \"Party\". It turns out that using some syntax we didn't cover in lecture, we can print out the subframes that result. This isn't something you'll do for any practical purpose. However, it may help you get an understanding of what groupby is actually doing.\n",
    "\n",
    "An example is given below for elections since 1980."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492befea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:16.136582Z",
     "start_time": "2020-09-16T20:55:16.020654Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "for n, g in elections.query(\"Year >= 1980\").groupby(\"Party\"):\n",
    "    print(f\"Name: {n}\") # by the way this is an \"f string\", a relatively new and great feature of Python\n",
    "    display(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f4908",
   "metadata": {},
   "source": [
    "Recall that once we've formed groups, we can aggregate each sub-dataframe (a.k.a. group) into a single row using an aggregation function. For example, if we use `.agg(np.mean)` on the groups above, we get back a single DataFrame where each group has been replaced by a single row. In each column for that aggregate row, the value that appears is the average of all values in that group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86459430",
   "metadata": {},
   "outputs": [],
   "source": [
    "elections_after_1980 = elections[elections[\"Year\"] >= 1980][[\"Party\",\"Popular vote\", \"%\"]]\n",
    "\n",
    "elections_after_1980.groupby(\"Party\").agg(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7678ea00",
   "metadata": {},
   "source": [
    "Equivalently we can use one of the shorthand aggregation functions, e.g. `.mean()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6393b314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "elections_after_1980.groupby(\"Party\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522812cb",
   "metadata": {},
   "source": [
    "Note that the index of the dataframe returned by an `groupby.agg` call is no longer a set of numeric indices from 0 to N-1. Instead, we see that the index for the example above is now the `Party`. If we want to restore our DataFrame so that `Party` is a column rather than the index, we can use `reset_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df55047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "elections_after_1980.groupby(\"Party\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a1f0c2",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:** Notice that the code above consists of a series of chained method calls. This sort of code is very very common in Pandas programming and in data science in general. Such chained method calls can sometimes go many layers deep, in which case you might consider adding newlines between lines of code for clarity. For example, we could instead write the code above as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas method chaining\n",
    "(\n",
    "elections.query(\"Year >= 1980\")[[\"Party\",\"Popular vote\", \"%\"]].groupby(\"Party\") \n",
    "                               .mean()            ## computes the mean values by party\n",
    "                               .reset_index()     ## reset to a numerical index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c42e3b",
   "metadata": {},
   "source": [
    "Note that we have surrounded the entire call by a big set of parentheses so that Python doesn't complain about the indentation. An alternative is to use the \\ symbol to indicate to Python that your code continues on to the next line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f555ff6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pandas method chaining (alternative)\n",
    "elections.query(\"Year >= 1980\")[[\"Party\",\"Popular vote\", \"%\"]].groupby(\"Party\") \\\n",
    "                               .mean() \\\n",
    "                               .reset_index()     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d5ec9f",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:** You should NEVER solve problems like the one above using loops or list comprehensions. This is slow and also misses the entire point of this part of CSPB 3022. \n",
    "\n",
    "Before we continue, we'll print out the election dataset again for your convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "elections.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74df93",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 1a\n",
    "Using `groupby.agg` or one of the shorthand methods (`groupby.min`, `groupby.first`, etc.), create a DataFrame `best_result_percentage_only` showing the overall best result for every party, sorted in decreasing order. \n",
    "Your DataFrame should **include only parties which have earned at least 10% of the vote** in some election. \n",
    "\n",
    "For example, the first 3 rows of your DataFrame should be:\n",
    "\n",
    "|Party | %         |\n",
    "|------|------|\n",
    "|**Democratic**  | 61.344703 |\n",
    "|**Republican**  | 60.907806 |\n",
    "|**Democratic-Republican**   | 57.210122 |\n",
    "\n",
    "Note that the index is `Party`. In other words, don't use `reset_index`.\n",
    "\n",
    "\n",
    "A list of named `groupby.agg` shorthand methods is [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#aggregation) (you'll have to scroll down about one page).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5793e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:17.183136Z",
     "start_time": "2020-09-16T20:55:17.172696Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# put your code above this line\n",
    "best_result_percentage_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd907d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d790d20",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 1b  \n",
    "Repeat Question 1a. However, this time, your result should be a DataFrame called `best_result` that shows the overall best result for each party AND includes columns with the corresponding Year, Candidate, Popular Vote and Result.\n",
    "\n",
    "This question is trickier than Question 1a. Make sure to check the lecture slides if you're stuck! It's very easy to make a subtle mistake that shows Woodrow Wilson and Howard Taft both winning the 2020 election.\n",
    "\n",
    "Sort in descending order according to the best result.  \n",
    "\n",
    "For example, the first 3 rows of your table should be:\n",
    "\n",
    "|Party | Year | Candidate      | Popular Vote | Result | %         |\n",
    "|------|------|----------------|--------------|--------|-----------|\n",
    "|**Democratic**  | 1964 | Lyndon Johnson | 43127041      | win   | 61.344703 |\n",
    "|**Republican**  | 1972 | Richard Nixon | 47168710      | win   | 60.907806 |\n",
    "|**Democratic-Republican**  | 1824 | Andrew Jackson | 151271      | loss   | 57.210122 |\n",
    "\n",
    "Note that the index is `Party`. In other words, don't use `reset_index`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b671e90a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:18.356549Z",
     "start_time": "2020-09-16T20:55:18.350541Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# put your code above this line\n",
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0345de",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c78b7",
   "metadata": {},
   "source": [
    "Our DataFrame contains a number of parties which have never had a successful presidential run. For example, the 2020 elections included candiates from the Libertarian and Green parties, neither of which have elected a president."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7226be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "elections.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0566db05",
   "metadata": {},
   "source": [
    "Suppose we were conducting an analysis trying to focus our attention on parties that had elected a president. \n",
    "\n",
    "The most natural approach is to use `groupby.filter`. This is an incredibly powerful but subtle tool for filtering data.  \n",
    "\n",
    "See the Pandas `groupby.filter` [documentation](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.filter.html) for documentation on using `groupby.filter`.\n",
    "\n",
    "\n",
    "\n",
    "The code below accomplishes the task at hand. It does this by creating a function that returns True if and only if a sub-dataframe (a.k.a. group) contains at least one winner. This function in turn uses the [Pandas function \"any\"](https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecffa0a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:19.814724Z",
     "start_time": "2020-09-16T20:55:19.781171Z"
    }
   },
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "def at_least_one_candidate_in_the_frame_has_won(frame):\n",
    "    \"\"\"Returns df with rows only kept for parties that have\n",
    "    won at least one election\n",
    "    \"\"\"\n",
    "    return (frame[\"Result\"] == 'win').any()\n",
    "\n",
    "winners_only = (\n",
    "    elections\n",
    "        .groupby(\"Party\")\n",
    "        .filter(at_least_one_candidate_in_the_frame_has_won)\n",
    ")\n",
    "winners_only.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a09da3",
   "metadata": {},
   "source": [
    "Alternately we could have used a `lambda` function instead of explicitly defining a named function using `def`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc479cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell (alternative)\n",
    "winners_only = (\n",
    "    elections\n",
    "        .groupby(\"Party\")\n",
    "        .filter(lambda x : (x[\"Result\"] == \"win\").any())\n",
    ")\n",
    "winners_only.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ba0304",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "\n",
    "For the next question, you'll do a less restrictive filtering of the elections data.\n",
    "\n",
    "#### Question 1c\n",
    "\n",
    "Using `filter`, create a DataFrame `major_party_results_since_1988` that includes all election results starting in 1988, but only show a row if the Party it belongs to has earned at least 1% of the popular vote in ANY election since 1988.\n",
    "\n",
    "For example, in 1988, you should not include the `New Alliance` candidate, since this party has not earned 1% of the vote since 1988. However, you should include the `Libertarian` candidate from 1988 despite only having 0.47 percent of the vote in 1988, because in 2016 and 2020, the Libertarian candidates Gary Johnson and Jo Jorgensen exceeded 1% of the vote.\n",
    "\n",
    "For example, the first three rows of the table you generate should look like:\n",
    "\n",
    "|     |   Year | Candidate         | Party       |   Popular vote | Result   |         % |\n",
    "|----:|-------:|:------------------|:------------|---------------:|:---------|----------:|\n",
    "| 135 |   1988 | George H. W. Bush | Republican  |       48886597 | win      | 53.5188   |\n",
    "| 137 |   1988 | Michael Dukakis   | Democratic  |       41809074 | loss     | 45.7707   |\n",
    "| 138 |   1988 | Ron Paul          | Libertarian |         431750 | loss     |  0.47266  |\n",
    "\n",
    "*Hint*: The following questions might help you construct your solution. One of the lines should be identical to the `filter` examples shown above.\n",
    "\n",
    "1) How can we **only** keep rows in the data that are after 1988?\n",
    "2) What column should we `groupby` to filter out parties that have earned at least 1% of the popular vote in ANY election since 1988?\n",
    "3) How can we write an aggregation function that takes a subframe (or sub-DataFrame) and returns whether at least 1% of the vote has been earned in that subframe? This may give you a hint about the second question!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ac3d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T20:55:21.762599Z",
     "start_time": "2020-09-16T20:55:21.743430Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "\n",
    "\n",
    "# put your code above this line\n",
    "\n",
    "major_party_results_since_1988.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba852de2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfbce43",
   "metadata": {},
   "source": [
    "Pandas provides special purpose functions for working with specific common data types such as strings and dates. For example, the code below provides the length of every Candidate's name from our elections dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5125ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "elections[\"Candidate\"].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef5799",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Using `.str.split` create a new DataFrame called `elections_with_first_name` with a new column `First Name` that is equal to the Candidate's first name.\n",
    "\n",
    "See the Pandas `str` [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html) for documentation on using `str.split`.\n",
    "\n",
    "Hint: You will need to use `[0]` somewhere in your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de839199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T03:07:32.775469Z",
     "start_time": "2020-09-16T03:07:32.769402Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# put your code above this line\n",
    "elections_with_first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339678d5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3453801",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "babyname_dataset",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### QUESTION 3: Babynames Dataset\n",
    "\n",
    "We will now download data from the United States Social Security office containing the number of registered names broken down by **year**, **sex**, and **name**. This is often called the Baby Names Data as social security numbers (SSNs) are typically given at birth.\n",
    "\n",
    "Reading from [SSN Office description](https://www.ssa.gov/oact/babynames/background.html), bolded for readability: \n",
    "\n",
    "\n",
    "> All names are from Social Security card applications for **births that occurred in the United States** after 1879. **Note that many people born before 1937 never applied** for a Social Security card, so their names are not included in our data. For others who did apply, our records may not show the place of birth, and again their names are not included in our data.\n",
    "\n",
    "> **To safeguard privacy, we exclude** from our tabulated lists of names those that would indicate, or would allow the ability to determine, **names with fewer than 5 occurrences** in any geographic area. If a name has less than 5 occurrences for a year of birth in any state, the sum of the state counts for that year will be less than the national count.\n",
    "\n",
    "> All data are from a **100% sample** of our records on Social Security card applications as of March 2023.\n",
    "\n",
    "\n",
    "First let's run the following cells to build the DataFrame `baby_names`.\n",
    "\n",
    "The cells below download the data from the web and extract the data into a DataFrame. There should be a total of 6215834 records.\n",
    "\n",
    "The code shown here is outside of the scope of CSCI 3022, but you're encouraged to dig into it if you are interested!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013988ad",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "fetch_and_cache",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### `fetch_and_cache` Helper\n",
    "\n",
    "The following function downloads and caches data in the `data/` directory and returns the `Path` to the downloaded file. The cell below the function describes how it works. You are not expected to understand this code, but you may find it useful as a reference as a practitioner of data science after the course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1646d279",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "fetch_and_cache_code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "def fetch_and_cache(data_url, file, data_dir=\"data\", force=False):\n",
    "    \"\"\"\n",
    "    Download and cache a url and return the file object.\n",
    "    \n",
    "    data_url: the web address to download\n",
    "    file: the file in which to save the results.\n",
    "    data_dir: (default=\"data\") the location to save the data\n",
    "    force: if true the file is always re-downloaded \n",
    "    \n",
    "    return: The pathlib.Path to the file.\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    file_path = data_dir/Path(file)\n",
    "    if force and file_path.exists():\n",
    "        file_path.unlink()\n",
    "    if force or not file_path.exists():\n",
    "        print('Downloading...', end=' ')\n",
    "        resp = requests.get(data_url)\n",
    "        with file_path.open('wb') as f:\n",
    "            f.write(resp.content)\n",
    "        print('Done!')\n",
    "    else:\n",
    "        import time \n",
    "        created = time.ctime(file_path.stat().st_ctime)\n",
    "        print(\"Using cached version downloaded at\", created)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3296ad",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-18d54d536c23da04",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In Python, a `Path` object represents the filesystem paths to files (and other resources). The `pathlib` module is effective for writing code that works on different operating systems and filesystems. \n",
    "\n",
    "To check if a file exists at a path, use `.exists()`. To create a directory for a path, use `.mkdir()`. To remove a file that might be a [symbolic link](https://en.wikipedia.org/wiki/Symbolic_link), use `.unlink()`. \n",
    "\n",
    "This function creates a path to a directory that will contain data files. It ensures that the directory exists (which is required to write files in that directory), then proceeds to download the file based on its URL.\n",
    "\n",
    "The benefit of this function is that not only can you force when you want a new file to be downloaded using the `force` parameter, but in cases when you don't need the file to be re-downloaded, you can use the cached version and save download time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be165664",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "download_data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Below we use `fetch_and_cache` to download the `namesbystate.zip` zip file, which is a compressed directory of CSV files. \n",
    "\n",
    "**This might take a little while! Consider stretching.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688ecc4",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "download_data_code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data_url = 'https://www.ssa.gov/oact/babynames/state/namesbystate.zip'\n",
    "namesbystate_path = fetch_and_cache(data_url, 'namesbystate.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbcba4b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "build_df",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The following cell builds the final full `baby_names` DataFrame. It first builds one DataFrame per state, because that's how the data are stored in the zip file. Here is documentation for [pd.concat](https://pandas.pydata.org/pandas-docs/version/1.2/reference/api/pandas.concat.html) if you want to know more about its functionality. As before, you are not expected to understand this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cefbbde",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "build_df_code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zf = zipfile.ZipFile(namesbystate_path, 'r')\n",
    "\n",
    "column_labels = ['State', 'Sex', 'Year', 'Name', 'Count']\n",
    "\n",
    "def load_dataframe_from_zip(zf, f):\n",
    "    with zf.open(f) as fh: \n",
    "        return pd.read_csv(fh, header=None, names=column_labels)\n",
    "\n",
    "states = [\n",
    "    load_dataframe_from_zip(zf, f)\n",
    "    for f in sorted(zf.filelist, key=lambda x:x.filename) \n",
    "    if f.filename.endswith('.TXT')\n",
    "]\n",
    "\n",
    "baby_names = states[0]\n",
    "for state_df in states[1:]:\n",
    "    baby_names = pd.concat([baby_names, state_df])\n",
    "baby_names = baby_names.reset_index().iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56735299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baby_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d76f9af",
   "metadata": {},
   "source": [
    "The code below creates a table with the frequency of all names from 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7acd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "baby_names_2020 = (\n",
    "    baby_names.query('Year == 2020')\n",
    "              .groupby(\"Name\")\n",
    "              .sum()[[\"Count\"]]\n",
    "              .reset_index()\n",
    ")\n",
    "baby_names_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc658ae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 3a). \n",
    "Using the `pd.merge` function described in lecture, combine the `baby_names_2020` table with the `elections_with_first_name` table you created earlier to form `presidential_candidates_and_name_popularity`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c03a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "# put your code above this line\n",
    "\n",
    "presidential_candidates_and_name_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190fe78",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254faefc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 3b).  \n",
    "\n",
    "i).  Which historical presidential candidate first name was the most popular in 2020? \n",
    "\n",
    "ii).  What 3 historical presidential candidate first names were tied for the least popular in 2020 according to this presidential_candidates_and_name_popularity table? \n",
    "\n",
    "Note: Here you'll observe a common problem in data science -- one of the least popular names is actually due to the fact that one recent president was so commonly known by his nickname that he appears named as such in the database from which you pulled election results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5f59db-bf14-403f-83b1-8256827a9438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# put your code to calculate the most popular first name above this line, and output the first name\n",
    "most_popular_firstname\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65723407-6d5d-4dbe-b52a-40bffebe1843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# put your code to calculate a series with the least popular names above this line\n",
    "least_popular_firstnames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6aeac6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### QUESTION 4: Evidence for Money Ball\n",
    "\n",
    "In the book [MoneyBall](https://en.wikipedia.org/wiki/Moneyball), Michael Lewis documented the introduction of statistics and data science in selecting players for the Oakland A's. in this problem, we're going to use [Sean Lahman's Baseball Database](http://seanlahman.com/baseball-archive/statistics) which contains the \"complete batting and pitching statistics from 1871 to 2013, plus fielding statistics, standings, team stats, managerial records, post-season data, and more. For more details, please [read the documentation](http://seanlahman.com/files/database/readme2012.txt).\"\n",
    "\n",
    "We're going to use two data sets, `teams.csv` and `salaries.csv`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94497ea4",
   "metadata": {},
   "source": [
    "\n",
    "Read in the `teams.csv` data into a DataFrame and the `salaries.csv` into another DataFrame and look at the first 5 rows of each. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c346e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df=pd.read_csv(\"data/teams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_df=pd.read_csv(\"data/salaries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc703856",
   "metadata": {},
   "source": [
    "Both files include columns `yearID` and `teamID`. \n",
    "\n",
    "The `teamID` field is a categorical field indicating the team names. \n",
    "\n",
    "The `yearID` field is a numeric field indicating the year for the data in that row. \n",
    "\n",
    "The `teams.csv` file also contains a field `W`, which indicates the total *wins* for that team in that year. \n",
    "\n",
    "The `salaries.csv` file contains the salary of individual players. Each player is listed on a distinct line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3bcf5b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 4ai)- Checking the number of wins in 1998\n",
    "\n",
    "\n",
    "Create a Dataframe `w1998` with index `teamID` and columns `name` and `wins` (the total number of wins per team in 1998). The team names in the index should be sorted alphabetically from ANA to TOR. \n",
    "\n",
    "For example, the first 3 rows of your DataFrame should be:\n",
    "\n",
    "|teamID | name         |wins |\n",
    "|------|------|--------|\n",
    "|**ANA**  | Anaheim Angels |85|\n",
    "|**ARI**  | Arizona Diamondbacks | 65|\n",
    "|**ATL**   | Atlanta Braves| 106|\n",
    "\n",
    "Be sure to rename the \"W\" column to \"wins\".\n",
    "\n",
    "Note that the index is `teamID`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b9d39",
   "metadata": {
    "nbgrader": {
     "checksum": "c765b3cecfb8d8582dd862e478093940",
     "grade": false,
     "grade_id": "cell-d660242b8519ecc2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "...\n",
    "# put your code above this line\n",
    "\n",
    "\n",
    "\n",
    "w1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db927ef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93779ae2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "#### QUESTION 4aii).\n",
    "\n",
    "How many games did the Oakland A's win in 1998?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a506b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oakwins= ...\n",
    "oakwins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a3b69",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4aii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8579ec67",
   "metadata": {},
   "source": [
    "Run the code below to produce a bar plot showing each team's total wins in 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1998.plot(kind='bar', figsize=(8,4)).set(ylabel='Wins', xlabel = 'Team');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c1401b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 4bi - Examining the payroll in 1998\n",
    "\n",
    "\n",
    "\n",
    "Create a dataframe `p1998` with index `teamID` and column `payroll` (the total salary per team in 1998). \n",
    "\n",
    "The team names in the index should be sorted alphabetically from ANA to TOR.\n",
    "\n",
    "For example, the first 3 rows of your DataFrame should be:\n",
    "\n",
    "|teamID | payroll         |\n",
    "|------|------|\n",
    "|**ANA**  | 41281000|\n",
    "|**ARI**  |  32347000|\n",
    "|**ATL**   | 61186000|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd3a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "...\n",
    "# end your code\n",
    "\n",
    "\n",
    "\n",
    "p1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdf2eca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4bi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf58b7d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 4bii:\n",
    "\n",
    "What was the Oakland A's payroll in 1998?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7ca39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "o_payroll = ...\n",
    "\n",
    "o_payroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca534ed",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4bii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b21dd6",
   "metadata": {},
   "source": [
    "#### QUESTION 4c:   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfbd374",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "Merge your dataframes from parts 4a and 4b to create a new dataframe called `df_1998` with the following columns:\n",
    "\n",
    "`teamID`, `name` `wins` (total number of wins per team in 1998) and `payroll` (total team payroll in 1998)\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b2ae21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "...\n",
    "# end your code\n",
    "\n",
    "df_1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94364a7f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9407a15",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 4di).  What's up with Oakland? \n",
    "\n",
    "\n",
    "In this problem, you're going to produce scatter plots to confirm the intuition that the data science approach that Oakland adopted changed their efficiency (wins per dollar spent).\n",
    "\n",
    "\n",
    "Run the code below to produce a [scatter plot](http://pandas.pydata.org/pandas-docs/stable/visualization.html#scatter-plot) of the payroll (y-axis) *vs* the number of Wins (x-axis) for all teams during the year 1998, using your dataframe `df_1998`. Notice the code below also highlights the datapoint for Oakland in red.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d6f811",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_1998.plot.scatter('wins', 'payroll')\n",
    "\n",
    "plt.title('Year 1998')\n",
    "plt.plot(df_1998.loc['OAK','wins'],df_1998.loc['OAK','payroll'], 'ro')\n",
    "plt.xlim(0,110)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab319331",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4dii).\n",
    "\n",
    "Create two more of these scatterplots (one for 2003 and one for 2013) of wins vs payroll for all teams, and highlight Oakland in red. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70adf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code for 2003 here:\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed0b0a-14e3-4ac3-a83d-2db8caec72b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code for 2013 here:\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245acd6a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### QUESTION 4e). \n",
    "\n",
    "Examining your scatterplots above, what was the effect of introducing statistics and data science in selecting players for the Oakland A's? (i.e. comment on what trend you notice from the graphs regarding the Oakland A's between 1998, 2003 and 2013).      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab89e0a7",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f74f72e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/><br/>\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Congratulations! You have finished Homework 3!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc31acf9",
   "metadata": {},
   "source": [
    "If you discussed this assignment with any other students in the class (in a manner that is acceptable as described by the Collaboration policy above) please **include their names** here:\n",
    "\n",
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46739932",
   "metadata": {},
   "source": [
    "### Submission Instructions\n",
    "\n",
    "Before proceeding any further, **save this notebook.**\n",
    "\n",
    "After running the `grader.export()` cell provided below, **2 files will be created**: a zip file and pdf file.  You can download them using the links provided below OR by finding them in the same folder where this juptyer notebook resides in your JuptyerHub.\n",
    "\n",
    "To receive credit on this assignment, **you must submit BOTH of these files\n",
    "to their respective Gradescope portals:** \n",
    "\n",
    "* **Homework 3 Autograded**: Submit the zip file that is output by the `grader.export()` cell below to the HW1 Autograded assignment in Gradescope.\n",
    "\n",
    "* **Homework 3 Manually Graded**: Submit your hw01.PDF to the HW1 Manually Graded assignment in Gradescope.  \n",
    "\n",
    "\n",
    "**You are responsible for ensuring your submission follows our requirements. We will not be granting regrade requests nor extensions to submissions that don't follow instructions.** If you encounter any difficulties with submission, please don't hesitate to reach out to the instructor prior to the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338fc541",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "AFTER running the cell below, click on <a href='hw03.pdf' download>this link to download the PDF </a> to upload to Gradescope.  There will be a separate link that appears after running the cell below with a link to download the zip file to upload to Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c310be",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0752c64",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(best_result_percentage_only) == 15\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(best_result_percentage_only.query('Party == \"Independent\"').loc[\"Independent\",\"%\"],18.95629754)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(best_result_percentage_only.iloc[0,0],61.34470329)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert best_result.shape == (15,5)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert (best_result[\"Popular vote\"].sum() ==135020916)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert (best_result.loc[\"Democratic\", \"Candidate\"]  == 'Lyndon Johnson')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (major_party_results_since_1988.shape == (40,6))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(major_party_results_since_1988[\"%\"].min(),0.098088334)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert (major_party_results_since_1988[\"Candidate\"].iloc[0] == 'George H. W. Bush')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> #TEST\n>>> assert (elections_with_first_name.shape == (182, 7))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert (elections_with_first_name[elections_with_first_name[\"Candidate\"] == \"Andrew Jackson\"].iloc[0][\"First Name\"] == 'Andrew')\n>>> \n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert (elections_with_first_name[elections_with_first_name[\"Candidate\"] == \"Jo Jorgensen\"].iloc[0][\"First Name\"] == 'Jo')\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (presidential_candidates_and_name_popularity.shape == (154,9))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert (presidential_candidates_and_name_popularity[presidential_candidates_and_name_popularity[\"Candidate\"] == \"Andrew Jackson\"].iloc[0][\"Name\"] == 'Andrew')\n>>> \n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert presidential_candidates_and_name_popularity[presidential_candidates_and_name_popularity[\"Candidate\"] == \"Jo Jorgensen\"].iloc[0][\"Count\"] == 6\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4ai": {
     "name": "q4ai",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (w1998.shape == (30,2)) \n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert (w1998[\"wins\"]['ANA'] == 85)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert (w1998[\"wins\"]['TOR'] == 88)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert (w1998[\"wins\"].sum() == 2430)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4aii": {
     "name": "q4aii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert oakwins == 74\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4bi": {
     "name": "q4bi",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> #TEST\n>>> assert (p1998.shape == (30,1))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> #TEST\n>>> assert (p1998[\"payroll\"]['LAN'] == 48820000)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> #TEST\n>>> assert (p1998[\"payroll\"][-1] == 51376000)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> #TEST\n>>> assert (p1998[\"payroll\"].sum() == 1278282871)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4bii": {
     "name": "q4bii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> #TEST\n>>> assert (o_payroll == 21303000)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4c": {
     "name": "q4c",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> #TEST \n>>> assert df_1998.loc[\"SEA\",\"name\"]=='Seattle Mariners'\n>>> \n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> #TEST \n>>> \n>>> assert (df_1998[\"wins\"].sum()==2430)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> #TEST\n>>> \n>>> assert df_1998.loc[\"CIN\",\"payroll\"]==23005000\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
