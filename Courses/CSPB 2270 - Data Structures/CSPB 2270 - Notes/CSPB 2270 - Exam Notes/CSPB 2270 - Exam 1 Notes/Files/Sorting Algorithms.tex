\section*{Sorting Algorithms}

\subsection*{Overview}

Sorting algorithms are fundamental algorithms used to arrange elements in a specific order, typically in ascending or descending order. There are various sorting algorithms available, each with its 
own characteristics and performance trade-offs. Some popular sorting algorithms include bubble sort, insertion sort, selection sort, merge sort, quicksort, and heapsort. These algorithms employ different 
techniques, such as comparison-based sorting, divide-and-conquer, or the use of auxiliary data structures, to efficiently sort elements. The choice of sorting algorithm depends on factors such as the size 
of the data, the desired time complexity, and the nature of the data being sorted. Efficient sorting algorithms have a significant impact on the performance of applications that require ordered data.

\subsection*{Types of Sorting Algorithms}

There are a multitude of different types of sorting algorithms. Below is a table that lists the sorting algorithms with a brief description, the best, average, and worst case time complexity as well as the
worst case data sequence of each algorithm:

\begin{center}
    \begin{tabular}[ht]{|c|p{5cm}|c|c|c|c|}
        \hline \textbf{Algorithm} & \multicolumn{1}{|c|}{\textbf{Description}} & \textbf{$\Omega(n)$} & \textbf{$\Theta(n)$} & \textbf{$\mathcal{O}(n)$} & \textbf{Worst Data Sequence} \\ \hline
        \textbf{Bubble Sort} & \footnotesize{Bubble sort is a simple comparison-based sorting algorithm that repeatedly swaps adjacent elements if they are in the wrong order.} & $\Omega(n^2)$ & $\Theta(n^2)$ & $\mathcal{O}(n^2)$ & Reverse Order \\ \hline
        \textbf{Insertion Sort} & \footnotesize{Insertion sort is an efficient comparison-based sorting algorithm that builds the final sorted array one element at a time.} & $\Omega(n)$ & $\Theta(n^2)$ & $\mathcal{O}(n^2)$ & Reverse Order \\ \hline
        \textbf{Merge Sort} & \footnotesize{Merge sort is a divide-and-conquer algorithm that recursively divides the input array into smaller subarrays, sorts them, and then merges them to produce a sorted array.} & $\Omega(n\log{(n)})$ & $\Theta(n\log{(n)})$ & $\mathcal{O}(n\log{(n)})$ & Any \\ \hline
        \textbf{Quick Sort} & \footnotesize{ Quick sort is a divide-and-conquer algorithm that selects a pivot element and partitions the array into two subarrays, one with elements less than the pivot and the other with elements greater than the pivot.} & $\Omega(n)$ & $\Theta(n^2)$ & $\mathcal{O}(n^2)$ & Reverse Order \\ \hline
        \textbf{Radix Sort} & \footnotesize{Radix sort is a non-comparative sorting algorithm that sorts elements based on their digits or bits.} & $\Omega(n)$ & $\Theta(d(n+b))$ & $\mathcal{O}(d^2(n+b))$ & Different Digits \\ \hline
        \textbf{Selection Sort} & \footnotesize{Selection sort is a simple comparison-based sorting algorithm that works by dividing the input list into two parts: a sorted sublist and an unsorted sublist.} & $\Omega(n)$ & $\Theta(n^2)$ & $\mathcal{O}(n^2)$ & Reverse Order \\ \hline
        \textbf{Shell Sort} & \footnotesize{Shell sort is an in-place comparison-based sorting algorithm that is an extension of the insertion sort algorithm.} & $\Omega(n\log{(n)})$ & $\Theta(n^{3/2})$ & $\mathcal{O}(n^2)$ & Reverse Order \\ \hline
    \end{tabular}
\end{center}

\subsection*{Bubble Sort Algorithm}

\subsubsection*{Overview}

The bubble sort is a simple sorting algorithm that works by repeatedly comparing adjacent elements in an data set and swapping them if they are in the wrong order. The algorithm starts at the beginning of the data set and compares the first two elements. If the first element is greater than the second element, they are swapped. The algorithm then moves on to the next 
two elements and repeats the process. This continues until the end of the data set is reached. At this point, the largest element in the data set will be in the last position. The algorithm then starts again at the beginning of the data set and repeats the process. This time, the second largest element will be moved to the second-to-last position, and so on. The 
algorithm continues until all of the elements in the data set are sorted in ascending order.

\begin{highlight}[Bubble Sort Algorithm]

Below is the bubble sort algorithm in the context of C++:

\begin{code}
/*  bubblesort - Algorithm that sorts elements utilizing the bubble sort algorithm
*   Input:
*     data - Vector of integers that is passed by reference that is to be sorted
*   Algorithm:
*     * Begin by iterating through the vector "data"
*     * Compare adjacent elements of the vector at the current index
*     * Check to see if the next element in the vector is greater than that of 
*       the current element
*       * If it is, swap them, otherwise, move on to the next element
*   Output:
*     This function does not return a value, it sorts the elements in "data" 
*     using a bubble sort algorithm
*/
void Sorting::bubblesort(vector<int>& data){
// Iterate through the vector "data"
for (int i = 0; i < data.size() - 1; i++) {
    // Compare adjacent elements in the vector
    for (int j = 0; j < data.size() - i - 1; j++) {
        // Check to see if next element in vector is greater than that of the 
        // current element
        if (data.at(j) > data.at(j+1)) {
            // Create a temporary integer value for that of the current element
            int temp_val = data.at(j);
            // Assign the current element with that of the next element
            data.at(j) = data.at(j+1);
            // Assign the next element with that of the current element
            data.at(j+1) = temp_val;
        }
        else {}
        }
    }
}
\end{code}

The bubble sort algorithm is a relatively inefficient sorting algorithm when discussing runtime complexity. The runtime complexity of the bubble sort algorithm is as follows:

\begin{center}
    \begin{tabular}{|c|c|c|}
        \hline \textbf{Best Case $\Omega(n)$} & \textbf{Average Case $\Theta(n)$} & \textbf{Worst Case $\mathcal{O}(n)$} \\ \hline
        $\Omega(n)$ & $\Theta(n^2)$ & $\mathcal{O}(n^2)$ \\ \hline
    \end{tabular}
\end{center}

\noindent At its best, the bubble sort algorithm will run at a linear runtime complexity. In the average and worst case, the bubble sort algorithm will run at a quadratic runtime complexity. These runtime complexities are not considered great, but the given the simplicity of the algorithm it is rather efficient.

\end{highlight}

\subsection*{Merge Sort Algorithm}

\subsubsection*{Overview}

The merge sort algorithm is a divide-and-conquer algorithm for sorting a data set. This algorithm sorts a data set by recursively breaking it down into smaller and smaller sub-data set until they are sorted. Once the sub-data sets have been sorted, they are sorted back together into one final sub-data set. The merge sort algorithm utilizes
an auxiliary data-set (A temporary data-set) to store the sorted elements of the original data set. This auxiliary data-set is then copied back to the original data set. Similar to the quick sort algorithm, the merge sort algorithm requires the use of a separate algorithm in its implementation.

The algorithm that is used in the merge sort algorithm is the merge algorithm. This algorithm is responsible for taking two data sets and combing them into one data set. The merge algorithm can be seen below:

\begin{highlight}[Merge Algorithm]
Below is an example of the merge algorithm in the context of C++:

\begin{code}
/*  merge - Merges two vectors into one final vector
*   Input:
*     left - Vector of integers that is passed by reference that is to be inserted 
*            into the result vector
*     right - Vector of integers that is passed by reference that is to be inserted 
*             into the result vector
*     result - Vector of integers that is passed by reference 
*   Algorithm:
*     * Begin by calculating the size that is needed for the merged vector
*     * Set the positions of each vector that is going to be traversed through
*     * Create a temporary vector that will hold the merged values
*     * Iterate through the elements in the left and right vectors, copy the values 
*       into the mergedNumbers vector
*     * Increment the merge position
*     * Merge the left and right vectors into the mergedNumbers vector
*     * Copy the elements from the mergedNumbers vector into the result vector
*   Output:
*     This function does not return a value, it merges two vectors into one, called 
*     result
*/
void Sorting::merge(vector<int>& left, vector<int>& right, vector<int>& result) {
    // Calculate the size of the needed vector for the merged vector
    int mergedSize = left.size() + right.size();
    // Set the positions of each vector
    int mergePos = 0;
    int leftPos = 0;
    int rightPos = 0;
    // Create a temporary vector that will hold the merged values
    vector<int> mergedNumbers(mergedSize);
    // Continue while loop as long as there are elements left in each vector to 
    // be merged
    while (leftPos < left.size() && rightPos < right.size()) {
    // Insert the element in the left vector into the merged vector if it is less 
    // than that of the right vector
        if (left.at(leftPos) <= right.at(rightPos)) {
            mergedNumbers.at(mergePos) = left.at(leftPos);
            ++leftPos;
        }
        // Insert the element in the right vector into the merged vector if it is 
        // greater than that of the left vector
        else {
            mergedNumbers.at(mergePos) = right.at(rightPos);
            ++rightPos;
        }
        // Increment the merge position
        ++mergePos;
    }
    // Merge the left vector into the mergedNumbers vector
    while (leftPos < left.size()) {
        mergedNumbers.at(mergePos) = left.at(leftPos);
        ++leftPos;
        ++mergePos;
    }
    // Merge the right vector into the mergedNumbers vector
    while (rightPos < right.size()) {
        mergedNumbers.at(mergePos) = right.at(rightPos);
        ++rightPos;
        ++mergePos;
    }
    // Copy the elements from the mergedNumbers vector into the result vector
    for (mergePos = 0; mergePos < mergedSize; ++mergePos) {
        result.push_back(mergedNumbers.at(mergePos));
    }
}
\end{code}

\noindent The main responsibility of the above algorithm is to sort the elements of the two data sets, insert them into the auxiliary data set, and then copy that auxiliary data set back to the original data set. The general procedure of this algorithm can be explained below:

\begin{itemize}
    \item First calculate the needed size of the auxiliary data set and initialize the indexes of the left, right, and auxiliary data set
    \item The sub-data sets are then traversed through where the elements of the left and right sub-data sets are compared, after the comparison, the appropriate element is inserted into the auxiliary data set
    \item The above procedure is repeated until the index of either the left or right sub-data set reaches the back of the respective data set
    \item The remaining elements of the left and right sub-data sets are then added to auxiliary data set
    \item The auxiliary data set is then copied back to the resultant data set
    \item This process will repeat until the left and right sub-data sets are sorted
\end{itemize}

\noindent The merge algorithm is where the sorting of the merge sort algorithm occurs as well as where the merging of two sub-data sets occurs. The recursive nature of the merge algorithm will sort each halves of the original data set. 

\end{highlight}

The next algorithm is the implementation of the merge sort algorithm. The merge algorithm is responsible for creating recursive calls to the input data set so that it can be sorted in a timely manner. This algorithm can be seen below:

\begin{highlight}[Merge Sort Algorithm]
Below is an example of the merge sort algorithm in the context of C++:

\begin{code}
/*  mergesort - Uses the merge sort algorithm to sort elements in a vector
*   Input:
*     data - Vector of integers that is passed by reference that is going to be 
*             sorted
*   Algorithm:
*     * First check to see if the vector is empty or has one element
*     * Proceed to calculate the mid point of the vector
*     * Create a vector for the left and right half
*     * Recursively call the mergesort method on the left and right halves of 
*       the vector
*     * Merge the two vectors into one by copying the results to data
*   Output:
*     This function does not return a value, it sorts elements from a vector
*/
void Sorting::mergesort(vector<int>& data){
    // The vector is empty or only has one element
    if (data.size() <= 1) {
        return;
    }
    // The vector is greater than 1
    else {
        // Calculate the midpoint of the vector
        int midPoint = data.size() / 2;
        // Create a left half of the vector
        vector<int> leftHalf(data.begin(), data.begin() + midPoint);
        // Create a right half of the vector
        vector<int> rightHalf(data.begin() + midPoint, data.end());
        // Merge the left and right half of the vector, recursively
        mergesort(leftHalf);
        mergesort(rightHalf);
        // Create an empty vector
        vector<int> result;
        // Call the merge method and merge the two halves together
        merge(leftHalf, rightHalf, result);
        // Copy the results to data
        data = result;
    }
}
\end{code}

This algorithm takes an input data set and recursively splits the input data set until it reaches a size of one. Once the sub-data set reaches a size of one, it then gets passed in as an input parameter into the merge algorithm so that it can eventually be copied back to the original data set that is passed into the algorithm. The general procedure for how this data set works is the following:

\begin{itemize}
    \item The original data set that is passed into the algorithm is first checked if the data set is of size one, if it is, then the data set is returned, otherwise it continues on to the else block statement
    \item The midpoint of the data set is then calculated such that it can be split into two halves
    \item A left and right data set is then created to represent each have of the split data data set
    \item These sub-data sets are recursively fed into the function until the returned data set is of size one
    \item Once the returned sub-data set is of size one, it is fed into the merge algorithm so that the two sub-data sets can be combined into one data set
    \item The above process is repeated until the algorithm no longer merges two halves together, indicating that the data set has been sorted
\end{itemize}

\noindent This algorithm effectively splits an input data set until the returned data set is of size one. Once this happens, the merge algorithm then effectively merges two separate sub-data sets in a manner that they will be sorted. This process repeats over and over until all elements from the original data set have been sorted.

Similar to the quick sort algorithm, the merge sort algorithm is a highly efficient algorithm. Its recursive nature allows for less complex runtimes which makes it an optimal choice for sorting elements. The runtime complexities of this algorithm can be seen below:

\begin{center}
    \begin{tabular}{|c|c|c|}
        \hline \textbf{Best Case $\Omega(n)$} & \textbf{Average Case $\Theta(n)$} & \textbf{Worst Case $\mathcal{O}(n)$} \\ \hline
        $\Omega(n\log{(n)})$ & $\Theta(n\log{(n)})$ & $\mathcal{O}(n\log{(n)})$ \\ \hline
    \end{tabular}
\end{center}

\noindent Unlike the quick sort algorithm, the best case runtime complexity for the merge sort algorithm occurs when the list is already sorted. Because of nature of the merge sort algorithm, if the list is already sorted then it typically will only have to make $n$ comparisons when sorting the list. On the contrary, the worst case time complexity
for the merge sort algorithm occurs when the data set is sorted in reverse order. This is due to the splitting of the data sets and the recursive nature of the algorithm. 

On the contrary, the space complexity of the merge sort algorithm tends to be of the order $n$, $\mathcal{O}(n)$. This is because each time the recursive function is called it has to occupy memory. If the merge sort algorithm uses the `divide and conquer in place' strategy, where the sorted halves of the data set are stored in the original data set, 
the space complexity will decrease.
\end{highlight}

\subsection*{Quick Sort Algorithm}

\subsubsection*{Overview}

The quick sort algorithm is a divide-and-conquer algorithm for sorting a data set. This algorithm works by repeatedly partitioning the data set around a pivot element, and then recursively sorting the two sub-data sets
created by the partition. The pivot element that is chosen for this algorithm is typically the middle element of the data set, but it is not necessarily required for the algorithm to work. When the partitioning of elements
occurs, elements that are smaller than the pivot are moved to the left of the pivot. On the contrary, the elements that are larger than the pivot move to the right of the pivot. Once this partition is completed, the two
sub-data sets are recursively sorted. The quick sort algorithm is often regarded as a very efficient sorting algorithm and works well on large data sets.

The quick sort algorithm requires a separate algorithm than the main algorithm for it to operate correctly. The secondary algorithm that is required is the `quicksort\_partition' algorithm. The primary role of this algorithm
is to iterate through the vector and partition it so that elements can be sorted in a manner that is appropriate. This algorithm can be seen below.

\begin{highlight}[Quick Sort Partition Algorithm]

Below is the quick sort partition algorithm in the context of C++:

\begin{code}
/*  quicksort_partition - Determines the pivot point inside a given vector and 
*                         returns the updated highest index value
*   Input:
*     data - Vector of integers that is passed by reference where the pivot 
*            index is being found
*     low_idx - Integer value that represents the lower index of the vector 
*               for where we will search through
*     high_idx - Integer value that represents the higher index of the vector 
*               for where we will search through
*   Algorithm:
*     * Find the middle index of "data" and assign it to "mid_idx"
*     * Find the pivot value by looking at the value in the "data" vector at 
*       the middle index "mid_idx"
*     * Traverse through the vector by incrementing "low_idx" until a value 
*       is greater than or equal to that of the pivot
*     * Traverse through the vector by decrementing "high_idx" until a value 
*       is less than or equal to that of the pivot
*     * If the lower index value "low_idx" is greater than or equal to that 
*       of the higher index "high_idx", then we exit the while loop
*     * If the lower index is less than the higher index, then we do the 
*       following:
*       * Create a temporary integer "temp_val" for the value in "data" at 
*         the "low_idx" element location
*       * Swap the value that is found on the left side of the pivot with the 
*         value that is on the right side of the pivot
*       * Assign the value "temp_val" to that of the value at "high_idx" in 
*         the "data" array
*       * Increment the lower index by one and decrement the higher index by 
*         one
*   Output:
*     high_idx - Integer value that represents the updated higher index value 
*                of our vector that we are searching through
*/
int Sorting::quicksort_partition(vector<int>& data, int low_idx, int high_idx){
    // Define variables to track elements in the "data" vector
    int mid_idx = low_idx + (high_idx - low_idx) / 2;
    int pivot = data.at(mid_idx);
    bool finished = false;
    // Begin traversing through the vector
    while (!finished) {
    // Increment lower index until value greater than or equal to that of the 
    // pivot is found
    while (data.at(low_idx) < pivot) {
        low_idx += 1;
    }
    // Dectrement hihger index until value less than or equal to that of the 
    // pivot is found
    while (pivot < data.at(high_idx)) {
        high_idx -= 1;
    }
    // If no elements remain, then exit the loop
    if (low_idx >= high_idx) {
        finished = true;
    }
    // Begin the process of swapping values
    else {
        // Keep track of the current value at the lower index
        int temp_val = data.at(low_idx);
        // Swap the values of lower and higher indexes
        data.at(low_idx) = data.at(high_idx);
        data.at(high_idx) = temp_val;
        // Increment and decrement index values
        low_idx += 1;
        high_idx -= 1;
        }
    }
    return high_idx;
}
\end{code}

The general method for how this algorithm works is the following:

\begin{itemize}
    \item The function calculates the middle index of the `data' vector
    \item This function then sets the pivot element at the element of the middle index
    \item We then iterate through the the data set until we find a value on the left side of the pivot that is either greater than or equal to that of the pivot value
    \item After this, we iterate through the data set until we find a value on the right side of the pivot that is less than or equal to that of the pivot value
    \item We then check to see if the two sub-vectors (The values to left and right of the pivot) are sorted with the `if (low\_idx $\geq$ high\_idx)' statement
    \begin{itemize}
        \item If this statement evaluates to true, we exit the while loop
        \item If this statement is false, we swap the values of the lower index with that of the value at the higher index, and proceed to continue partitioning the data set
    \end{itemize}
    \item The above process will repeat until the the previous if statement evaluates to true
    \item `high\_idx' is returned from the partition algorithm to represent the index where elements to the left of it are less than or equal to it as well as the elements to the right of it are greater than or equal to it
\end{itemize}

\noindent The above algorithm correctly places the elements that are less than that of the pivot to the left of it and the values that are greater than or equal to that of the pivot
to the right of it. This process repeats itself until the condition previously mentioned is achieved. Once this condition is met, then we recursively sort the elements on the left and right of the pivot.

\end{highlight}

The next algorithm, which is the implementation of the quick sort algorithm, recursively sorts the sub-data sets that are created with the partitioning algorithm. This is done
by making recursive calls to itself while utilizing the `quicksort\_partition' algorithm to partition the left and right sub data sets of the data set. This algorithm can be seen below.

\begin{highlight}[Quick Sort Algorithm]
Below is the quick sort algorithm in the context of C++:

\begin{code}
/*  quicksort - Algorithm that sorts elements in a vector for a given low and high 
*               index
*   Input:
*     data - Vector of integers passed by reference that are to be sorted
*     low_idx - Integer value that represents the lower index of the vector that 
*               is to be sorted
*     high_idx - Integer value that represents the higher index of the vector that 
*               is to be sorted
*   Algorithm:
*     * If the lower index is greater than or equal to that of the higher index, 
*       then stop execution
*     * Otherwise, find the pivot point with "quicksort_partition" and assign this 
*       as the upper index of the lower partition
*     * Recursively call the algorithm to sort the lower end of the partitioned 
*       vector
*     * Recursively call the algorithm to sort the higher end of the partitioned 
*       vector
*   Output:
*     This function does not return a value, it modifies the "data" vector
*/
void Sorting::quicksort(vector<int>& data, int low_idx, int high_idx){
    // Check to see if the lower index is greater than or equal to that of higher index
    if (low_idx >= high_idx) {
        return;
    }
    else {
        // Determine the pivot point of the current vector
        int low_end_idx = quicksort_partition(data, low_idx, high_idx);
        // Recursively sort the lower half of the vector
        quicksort(data, low_idx, low_end_idx);
        // Recursively sort the higher half of the vector
        quicksort(data, low_end_idx + 1, high_idx);
    }
}
\end{code}

The general method for how this algorithm works is the following:

\begin{itemize}
    \item First check to see if their is only one element in the data set that is being sorted, otherwise continue to the next logic block
    \item If the data set is greater in size than one element, then we partition the data set such that it will have a lower half and upper half that can be sorted after
    \item The function then proceeds to finding the partition point (The point where elements to the left of it are less than it and the elements to the right are greater than or equal to it) with the `quicksort\_partition' algorithm
    \item After the partition point has been found, the algorithm proceeds to recursively sort the left and right halves of the data set that are set with the help of the partition point until the partition reaches size one
\end{itemize}

\noindent The goal of the quick sort algorithm is to partition a data set to the point such that the elements to the left of the pivot are less than or equal to the pivot and the elements to the right of the pivot point are greater than or equal to that of the pivot. This process will repeat until the data set that is being partitioned is of size one.
After the data set has been partitioned, it is sorted recursively with a call to `quicksort'.

The quick sort algorithm is a very efficient algorithm for data sets of all sizes. Its recursive nature allows for different sizes of data sets to be sorted efficiently in a timely matter implicating that it is a optimal choice for a sorting algorithm. The runtime complexity of the quick sort algorithm is as follows:

\begin{center}
    \begin{tabular}{|c|c|c|}
        \hline \textbf{Best Case $\Omega(n)$} & \textbf{Average Case $\Theta(n)$} & \textbf{Worst Case $\mathcal{O}(n)$} \\ \hline
        $\Omega(n\log{(n)})$ & $\Theta(n\log{(n)})$ & $\mathcal{O}(n^2)$ \\ \hline
    \end{tabular}
\end{center}

\noindent The quick sort algorithm typically will have a runtime complexity of $\Theta(n\log{(n)})$ with the worst runtime complexity of $\mathcal{O}(n^2)$. The worst case runtime complexity occurs when the data set that is being fed into the algorithm is sorted in reverse order.
\end{highlight}

\clearpage